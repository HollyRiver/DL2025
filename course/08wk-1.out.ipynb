{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 08wk-1: (합성곱신경망) – MNIST, CIFAR10, XAI란?\n",
        "\n",
        "최규빈  \n",
        "2025-04-23\n",
        "\n",
        "<a href=\"https://colab.research.google.com/github/guebin/DL2025/blob/main/posts/08wk-1.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" style=\"text-align: left\"></a>\n",
        "\n",
        "# 1. 강의영상\n",
        "\n",
        "<https://youtu.be/playlist?list=PLQqh36zP38-yoX-Rtq9TPcvAawZfu6iZx&si=DD64EseytgR75zIz>\n",
        "\n",
        "# 2. Imports"
      ],
      "id": "21ffaebe-ae03-4bc0-a20e-552706e8b288"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt"
      ],
      "id": "94cf31c0-2cee-4a18-82da-3380f21e28f1"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.rcParams['figure.figsize'] = (4.5, 3.0)"
      ],
      "id": "7e051a46-f5b5-4bdd-b236-6f6b9c62d7ed"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# CNN \n",
        "# net = 2d --> 1d\n",
        "# 1d: (linr -> relu)\n",
        "# 2d: (conv -> relu -> mp) "
      ],
      "id": "32b497c2-3d41-4aa1-99c2-d3e7e4d972bd"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 3. MNIST"
      ],
      "id": "5b9887c3-9c59-4f99-9fc5-5797ba9b8115"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100.0%\n",
            "100.0%\n",
            "100.0%\n",
            "100.0%"
          ]
        }
      ],
      "source": [
        "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True,transform=torchvision.transforms.ToTensor())\n",
        "test_dataset = torchvision.datasets.MNIST(root='./data', train=False, download=True,transform=torchvision.transforms.ToTensor())\n",
        "X,y = next(iter(torch.utils.data.DataLoader(train_dataset,batch_size=6000,shuffle=True)))\n",
        "XX,yy = next(iter(torch.utils.data.DataLoader(train_dataset,batch_size=1000,shuffle=True)))"
      ],
      "id": "3e8ec5b1-d78d-4696-8bf5-b26c3d2e7eec"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "net = torch.nn.Sequential(\n",
        "    torch.nn.Conv2d(1,32,kernel_size=5),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.MaxPool2d(kernel_size=2),\n",
        "    torch.nn.Conv2d(32,32,kernel_size=3),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Flatten(),\n",
        "    #---#\n",
        "    torch.nn.Linear(3200,10)\n",
        ")\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "optimizr = torch.optim.Adam(net.parameters())\n",
        "#---#\n",
        "net.to(\"cuda:0\")\n",
        "X = X.to(\"cuda:0\")\n",
        "y = y.to(\"cuda:0\")\n",
        "XX = XX.to(\"cuda:0\")\n",
        "yy = yy.to(\"cuda:0\")\n",
        "#---#\n",
        "for epoc in range(100):\n",
        "    #1\n",
        "    netout = net(X)\n",
        "    #2\n",
        "    loss = loss_fn(netout,y)\n",
        "    #3\n",
        "    loss.backward()\n",
        "    #4 \n",
        "    optimizr.step()\n",
        "    optimizr.zero_grad()"
      ],
      "id": "3e591dce-9fdc-4f52-9054-9dcca8031a52"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "(net(X).argmax(axis=1) == y).float().mean()"
      ],
      "id": "addb1431-ad1b-49d8-929d-c4c72d9dd46e"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "(net(XX).argmax(axis=1) == yy).float().mean()"
      ],
      "id": "79eed0fc-3b22-4817-b83f-85000fa2de78"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "id": "c6c374d2-2f4a-4b50-b9c0-daa2ba491ac4"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 4. CIFAR10"
      ],
      "id": "e2f7d70c-7929-4259-a5e4-9beee8842b7f"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100.0%"
          ]
        }
      ],
      "source": [
        "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True,transform=torchvision.transforms.ToTensor())\n",
        "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True,transform=torchvision.transforms.ToTensor())\n",
        "X,y = next(iter(torch.utils.data.DataLoader(train_dataset,batch_size=10000,shuffle=True)))\n",
        "XX,yy = next(iter(torch.utils.data.DataLoader(train_dataset,batch_size=2000,shuffle=True)))"
      ],
      "id": "876bf56a-a932-420a-8dff-f50514577a72"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## A. 직접설계"
      ],
      "id": "fce5e4ea-0627-47f3-8b45-d9127135b586"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "net = torch.nn.Sequential(\n",
        "    torch.nn.Conv2d(3,32,kernel_size=5),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.MaxPool2d(kernel_size=2),\n",
        "    torch.nn.Conv2d(32,32,kernel_size=3),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Flatten(),\n",
        "    #---#\n",
        "    torch.nn.Linear(4608,10)\n",
        ")\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "optimizr = torch.optim.Adam(net.parameters())\n",
        "#---#\n",
        "net.to(\"cuda:0\")\n",
        "X = X.to(\"cuda:0\")\n",
        "y = y.to(\"cuda:0\")\n",
        "XX = XX.to(\"cuda:0\")\n",
        "yy = yy.to(\"cuda:0\")\n",
        "#---#\n",
        "for epoc in range(500):\n",
        "    #1\n",
        "    netout = net(X)\n",
        "    #2\n",
        "    loss = loss_fn(netout,y)\n",
        "    #3\n",
        "    loss.backward()\n",
        "    #4 \n",
        "    optimizr.step()\n",
        "    optimizr.zero_grad()"
      ],
      "id": "a63c9951-e0aa-4a89-ae8a-d6339a315345"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "(net(X).argmax(axis=1) == y).float().mean()"
      ],
      "id": "2c7812e9-f130-4301-a1d8-16e8bebdab07"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "(net(XX).argmax(axis=1) == yy).float().mean()"
      ],
      "id": "82b4bb58-0037-4114-a7a6-8a3c9dcf032f"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-   표현력자체에 문제가 있어보임"
      ],
      "id": "eb2fbb70-2093-457d-8343-50b2218e5794"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "id": "c9f4b803-fdc2-4085-abc2-44f59bf44a82"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## B. 알렉스넷?\n",
        "\n",
        "![](https://upload.wikimedia.org/wikipedia/commons/thumb/c/cc/Comparison_image_neural_networks.svg/960px-Comparison_image_neural_networks.svg.png)"
      ],
      "id": "ab6f910c-c091-45f6-bfc1-ea31b11ba456"
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "img = torch.zeros(1,3*224*224).reshape(1,3,224,224)\n",
        "img.shape"
      ],
      "id": "a434dae6-0bb9-4aee-82bb-635a74ef7b74"
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "net = torch.nn.Sequential(\n",
        "    torch.nn.Conv2d(3,96,kernel_size=(11,11),stride=4),\n",
        "    torch.nn.ReLU(),    \n",
        "    torch.nn.MaxPool2d((3,3),stride=2), # default stride는 3\n",
        "    torch.nn.Conv2d(96,256,kernel_size=(5,5),padding=2),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.MaxPool2d((3,3),stride=2), # default stride는 3\n",
        "    torch.nn.Conv2d(256,384,kernel_size=(3,3),padding=1),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Conv2d(384,384,kernel_size=(3,3),padding=1),\n",
        "    torch.nn.ReLU(),    \n",
        "    torch.nn.Conv2d(384,256,kernel_size=(3,3),padding=1),\n",
        "    torch.nn.ReLU(),    \n",
        "    torch.nn.MaxPool2d((3,3),stride=2),\n",
        "    torch.nn.Flatten(),\n",
        "    torch.nn.Linear(6400,4096),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Dropout(0.5),\n",
        "    torch.nn.Linear(4096,4096),        \n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Dropout(0.5),    \n",
        "    torch.nn.Linear(4096,1000),\n",
        ")"
      ],
      "id": "bdd5f796-6695-480b-8ed6-df39a04ea845"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## C. 알렉스넷으로 ImageNet 적합"
      ],
      "id": "2e620364-4b33-4def-87d5-6daf2c183ebc"
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "net[-1] = torch.nn.Linear(4096,10)"
      ],
      "id": "d1bdd05a-983c-49cf-8744-53d66a8cde67"
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "img = torch.randn(1,3,32,32)"
      ],
      "id": "f3da9a06-0a65-409c-b7a5-0dfb0d32709c"
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "net(img)"
      ],
      "id": "85102866-e15c-4631-810d-8930776d662a"
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "net[:5](img).shape"
      ],
      "id": "be13c5e5-9740-4944-9b5d-28f60f101536"
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "net[5]"
      ],
      "id": "9a79108d-e1cb-4d88-9a8b-45191123e300"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "실패 ㅠㅠ\n",
        "\n",
        "## D. renset18\n",
        "\n",
        "`-` res: <https://arxiv.org/pdf/1512.03385>"
      ],
      "id": "c53d42b1-84c3-4bfa-9169-27f43c2e1e30"
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "net = torchvision.models.resnet18()\n",
        "# net "
      ],
      "id": "b06789ab-b33e-44f6-9fe5-92cedf343eee"
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "net.fc = torch.nn.Linear(512,10)"
      ],
      "id": "e6118b8b-f5fb-4747-b593-748d5804d0b0"
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "optimizr = torch.optim.Adam(net.parameters())\n",
        "#---#\n",
        "net.to(\"cuda:0\")\n",
        "X = X.to(\"cuda:0\")\n",
        "y = y.to(\"cuda:0\")\n",
        "XX = XX.to(\"cuda:0\")\n",
        "yy = yy.to(\"cuda:0\")\n",
        "#---#\n",
        "for epoc in range(500):\n",
        "    #1\n",
        "    netout = net(X)\n",
        "    #2\n",
        "    loss = loss_fn(netout,y)\n",
        "    #3\n",
        "    loss.backward()\n",
        "    #4 \n",
        "    optimizr.step()\n",
        "    optimizr.zero_grad()"
      ],
      "id": "a1c6c4f9-7ca7-47b1-8811-3f0a688f2d58"
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1., device='cuda:0')\n",
            "tensor(0.5930, device='cuda:0')"
          ]
        }
      ],
      "source": [
        "net.eval()\n",
        "print((net(X).argmax(axis=1) == y).float().mean())\n",
        "print((net(XX).argmax(axis=1) == yy).float().mean())"
      ],
      "id": "cbc4d1e5-7085-459f-bdad-de4f40b3655d"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-   오버피팅이 있어보긴하지만 표현력자체는 올라감"
      ],
      "id": "9815e74a-1a08-46ef-bbda-2c1a29596506"
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "id": "8efb6544-fc12-4706-89b7-49ee01f3dcc1"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## E. resnet18, pretrained=True\n",
        "\n",
        "`-` 아이디어: 하나를 잘하는 모델은 다른것도 잘하지 않을까? \\<– transfer\n",
        "learning"
      ],
      "id": "9d2d3939-99a9-4a98-ae2e-d9fce8913919"
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/home/cgb3/anaconda3/envs/dl2025/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/home/cgb3/anaconda3/envs/dl2025/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)"
          ]
        }
      ],
      "source": [
        "net = torchvision.models.resnet18(pretrained=True) # 아키텍처 + 학습된 가중치까지 \n",
        "net.fc = torch.nn.Linear(512,10)"
      ],
      "id": "1adf2e13-49d4-4ba9-88ac-a9d726ccc8c0"
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "optimizr = torch.optim.Adam(net.parameters())\n",
        "#---#\n",
        "net.to(\"cuda:0\")\n",
        "X = X.to(\"cuda:0\")\n",
        "y = y.to(\"cuda:0\")\n",
        "XX = XX.to(\"cuda:0\")\n",
        "yy = yy.to(\"cuda:0\")\n",
        "#---#\n",
        "for epoc in range(500):\n",
        "    #1\n",
        "    netout = net(X)\n",
        "    #2\n",
        "    loss = loss_fn(netout,y)\n",
        "    #3\n",
        "    loss.backward()\n",
        "    #4 \n",
        "    optimizr.step()\n",
        "    optimizr.zero_grad()"
      ],
      "id": "3d3816c2-d1d7-4c8e-9f74-094ffd5432db"
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1., device='cuda:0')\n",
            "tensor(0.8050, device='cuda:0')"
          ]
        }
      ],
      "source": [
        "net.eval()\n",
        "print((net(X).argmax(axis=1) == y).float().mean())\n",
        "print((net(XX).argmax(axis=1) == yy).float().mean())"
      ],
      "id": "b6ec00a2-fa37-452e-b5ca-ac8e516ef7f6"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-   잘함 (오버피팅은 여전히 있음)"
      ],
      "id": "5b6e12b8-aa4d-44d3-8599-432f7c5e5652"
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "id": "f05922b6-7336-4f87-99e5-f2f312e31900"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 5. XAI 란?\n",
        "\n",
        "<https://brunch.co.kr/@hvnpoet/140>"
      ],
      "id": "f5b971a6-58c2-44e1-8f52-b85c627a90a9"
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3 (ipykernel)",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "codemirror_mode": {
        "name": "ipython",
        "version": "3"
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.21"
    }
  }
}