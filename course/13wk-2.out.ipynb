{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60f02796-10bb-43d5-9060-afddbd00b4ef",
   "metadata": {},
   "source": [
    "# 13wk-2: (강화학습) – Bandit 환경 설계 및 풀이, 4x4 Grid World 게임설명\n",
    "\n",
    "및 구현\n",
    "\n",
    "최규빈  \n",
    "2025-06-02\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/guebin/DL2025/blob/main/posts/13wk-2.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" style=\"text-align: left\"></a>\n",
    "\n",
    "# 1. 강의영상"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "9c489bd1-72a5-415b-8b4c-1b1aeeb655b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# {{<video https://youtu.be/playlist?list=PLQqh36zP38-zEjn2m8H8hMCHsQK8udE27&si=Sy-lnw4Kq56SRggu >}}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9859153c-95f4-4fa9-91db-d84a13213430",
   "metadata": {},
   "source": [
    "# 2. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3857ad14-f8de-4973-ae86-7adb7fd1af6f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "#---#\n",
    "import numpy as np\n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "import IPython"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a52191-a1f8-474b-9a62-cf1ea2b7b03e",
   "metadata": {},
   "source": [
    "# 3. Bandit 환경 설계 및 풀이\n",
    "\n",
    "## A. 대충 개념만 실습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f58ccc61-bdef-4708-aabb-ff427cd89d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "action_space = [0,1] \n",
    "actions_deque = collections.deque(maxlen=500)\n",
    "rewards_deque =  collections.deque(maxlen=500)\n",
    "#---#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d6ab7a7-f7b1-48ef-adf0-072459dec4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(10):\n",
    "    action = np.random.choice(action_space)\n",
    "    if action == 1:\n",
    "        reward = 10 \n",
    "    else:\n",
    "        reward = 1\n",
    "    actions_deque.append(action)\n",
    "    rewards_deque.append(reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4908cf64-ea61-4430-a526-5154fbca0b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "actions_deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0de137ca-a78b-4522-a56c-d391d0bc37b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards_deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1cfb5c3a-5c72-42a0-86a0-e48e9ad8f537",
   "metadata": {},
   "outputs": [],
   "source": [
    "actions_numpy = np.array(actions_deque)\n",
    "rewards_numpy = np.array(rewards_deque)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0fcadb60-bf36-4c5d-8f08-dcf890f26ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "q0 = rewards_numpy[actions_numpy == 0].mean()\n",
    "q1 = rewards_numpy[actions_numpy == 1].mean()\n",
    "q_table = np.array([q0,q1])\n",
    "q_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ba6499e-e137-45b6-8318-9f647c889585",
   "metadata": {},
   "outputs": [],
   "source": [
    "action = q_table.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ca81468-2ff7-454a-9fd9-c90abcfb30ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(5):\n",
    "    action = q_table.argmax()\n",
    "    if action == 1:\n",
    "        reward = 10 \n",
    "    else:\n",
    "        reward = 1\n",
    "    actions_deque.append(action)\n",
    "    rewards_deque.append(reward)\n",
    "    actions_numpy = np.array(actions_deque)\n",
    "    rewards_numpy = np.array(rewards_deque)    \n",
    "    q0 = rewards_numpy[actions_numpy == 0].mean()\n",
    "    q1 = rewards_numpy[actions_numpy == 1].mean()\n",
    "    q_table = np.array([q0,q1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "32e2d548-1c32-4aa2-b201-ac7b3ac6f9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "actions_numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6322c32b-dda3-4f74-bfc4-3f938eb78aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards_numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b07ab74a-8bf1-43fc-a02a-8afcc6497afc",
   "metadata": {},
   "source": [
    "## B. 클래스를 이용한 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ecadad99-7cb3-468f-9fd1-f7a1c90d6198",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bandit:\n",
    "    def __init__(self):\n",
    "        self.reward = None \n",
    "    def step(self,action):\n",
    "        if action == 0:\n",
    "            self.reward = 1\n",
    "        else: \n",
    "            self.reward = 10 \n",
    "        return self.reward "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ab591669-92e9-40c6-8831-ed5cd9481b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self):\n",
    "        pass \n",
    "    def act(self):\n",
    "        # 만약에 경험이 20보다 작음 --> 랜덤액션 \n",
    "        # 경험이 20보다 크면 --> action = q_tabel.argmax()\n",
    "        pass \n",
    "    def save_experience(self):\n",
    "        # 데이터 저장 \n",
    "        pass \n",
    "    def learn(self):\n",
    "        # q_table 을 업데이트하는 과정 \n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563fe0d3-107e-49f3-a47e-7787f9edec7f",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1236cf3a-77d0-4b28-bf06-d756b58394f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self):\n",
    "        self.n_experiences = 0 \n",
    "        self.action_space = [0,1]\n",
    "        self.action = None\n",
    "        self.reward = None \n",
    "        self.q_table = None \n",
    "        self.actions = collections.deque(maxlen=500)\n",
    "        self.rewards = collections.deque(maxlen=500)\n",
    "    def act(self):\n",
    "        if self.n_experiences < 20:\n",
    "            self.action = np.random.choice(self.action_space)\n",
    "        else: \n",
    "            self.action = self.q_table.argmax()\n",
    "        print(f\"버튼{self.action}누름!\")\n",
    "    def save_experience(self):\n",
    "        self.actions.append(self.action)\n",
    "        self.rewards.append(self.reward)\n",
    "        self.n_experiences = self.n_experiences + 1 \n",
    "    def learn(self):\n",
    "        if self.n_experiences < 20:\n",
    "            pass\n",
    "        else: \n",
    "            actions = np.array(self.actions)\n",
    "            rewards = np.array(self.rewards)\n",
    "            q0 = rewards[actions==0].mean()\n",
    "            q1 = rewards[actions==1].mean()\n",
    "            self.q_table = np.array([q0,q1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b6715628-7443-4746-9b5e-6560585386f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = Bandit()\n",
    "player = Agent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "dbd8b650-d610-4cad-90fe-4cbec4e27f90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "버튼1누름!\n",
      "버튼1누름!\n",
      "버튼0누름!\n",
      "버튼1누름!\n",
      "버튼0누름!\n",
      "버튼1누름!\n",
      "버튼0누름!\n",
      "버튼1누름!\n",
      "버튼0누름!\n",
      "버튼1누름!\n",
      "버튼1누름!\n",
      "버튼1누름!\n",
      "버튼0누름!\n",
      "버튼1누름!\n",
      "버튼1누름!\n",
      "버튼0누름!\n",
      "버튼1누름!\n",
      "버튼1누름!\n",
      "버튼1누름!\n",
      "버튼0누름!\n",
      "버튼1누름!\n",
      "버튼1누름!\n",
      "버튼1누름!\n",
      "버튼1누름!\n",
      "버튼1누름!\n",
      "버튼1누름!\n",
      "버튼1누름!\n",
      "버튼1누름!\n",
      "버튼1누름!\n",
      "버튼1누름!\n",
      "버튼1누름!\n",
      "버튼1누름!\n",
      "버튼1누름!\n",
      "버튼1누름!\n",
      "버튼1누름!\n",
      "버튼1누름!\n",
      "---\n",
      "36번만에 게임클리어"
     ]
    }
   ],
   "source": [
    "for _ in range(50):\n",
    "    # step1 : agent --> env \n",
    "    player.act()\n",
    "    # step2: agnet <-- env \n",
    "    player.reward = env.step(player.action)\n",
    "    # step3: agent: update (save + learn) \n",
    "    player.save_experience() \n",
    "    player.learn()\n",
    "    #----#\n",
    "    if player.n_experiences < 20: \n",
    "        pass \n",
    "    else: \n",
    "        recent_rewards = np.array(player.rewards)[-20:]\n",
    "        if recent_rewards.mean() > 9.5:\n",
    "            print(\"---\")\n",
    "            print(f\"{player.n_experiences}번만에 게임클리어\")\n",
    "            break "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f92ef37-c522-4085-9e04-3fa55a16eef1",
   "metadata": {},
   "source": [
    "# 3. 예비학습: `gym.spaces`\n",
    "\n",
    "ref: <https://gymnasium.farama.org/>\n",
    "\n",
    "`-` 예시1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a4659ed6-45f7-4553-9221-050a362f9105",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "action_space = gym.spaces.Discrete(4) \n",
    "action_space "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f1c07638-97b4-42c2-a090-d0c0afc90c05",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "[action_space.sample() for _ in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a41cd503-e7e5-4914-a16d-f82a660b7685",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "0 in action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "57bc3c58-2c8f-44b7-9509-98b8c7cda86f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "4 in action_space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c7ee74c-4fa3-45d3-a205-15d7836df3b9",
   "metadata": {},
   "source": [
    "`-` 예시2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a353fb16-f934-4c27-a91d-7d1b80808848",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "state_space = gym.spaces.MultiDiscrete([4,4])\n",
    "state_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "66d65602-fbc5-4faf-aae9-277b0fe23b2b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "[state_space.sample() for _ in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "93050a8d-175f-473d-b9b1-78f88d910109",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array([0,1]) in state_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "09f27265-17d9-4025-957f-f5a893e4612f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.array([3,3]) in state_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "887259ee-582b-4e33-9f03-23af74983c2d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.array([3,4]) in state_space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17caa266-e348-4d71-9706-006aa15e866d",
   "metadata": {},
   "source": [
    "# 4. 4x4 Grid World 게임 설명\n",
    "\n",
    "## A. 게임설명\n",
    "\n",
    "`-` 문제설명: 4x4 그리드월드에서 상하좌우로 움직이는 에이전트가 목표점에\n",
    "도달하도록 하는 게임\n",
    "\n",
    "-   백문이 불여일견:\n",
    "    <https://claude.ai/public/artifacts/76e13820-2b51-4e7e-a514-00190de17c45>\n",
    "    (출처: 클로드)\n",
    "\n",
    "`-` GridWorld에서 사용되는 주요변수\n",
    "\n",
    "1.  **`State`**: 각 격자 셀이 하나의 상태이며, 에이전트는 이러한 상태 중\n",
    "    하나에 있을 수 있음.\n",
    "2.  **`Action`**: 에이전트는 현재상태에서 다음상태로 이동하기 위해\n",
    "    상,하,좌,우 중 하나의 행동을 취할 수 있음.\n",
    "3.  **`Reward`**: 에이전트가 현재상태에서 특정 action을 하면 얻어지는\n",
    "    보상.\n",
    "4.  **`Terminated`**: 하나의 에피소드가 종료되었음을 나타내는 상태.\n",
    "\n",
    "## B. 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "cd24d391-44ae-4d8b-ba8e-fc7ada7e2417",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def show(states):\n",
    "    fig = plt.Figure()\n",
    "    ax = fig.subplots()\n",
    "    ax.matshow(np.zeros([4,4]), cmap='bwr',alpha=0.0)\n",
    "    sc = ax.scatter(0, 0, color='red', s=500)  \n",
    "    ax.text(0, 0, 'start', ha='center', va='center')\n",
    "    ax.text(3, 3, 'end', ha='center', va='center')\n",
    "    # Adding grid lines to the plot\n",
    "    ax.set_xticks(np.arange(-.5, 4, 1), minor=True)\n",
    "    ax.set_yticks(np.arange(-.5, 4, 1), minor=True)\n",
    "    ax.grid(which='minor', color='black', linestyle='-', linewidth=2)\n",
    "    state_space = gym.spaces.MultiDiscrete([4,4])\n",
    "    def update(t):\n",
    "        if states[t] in state_space:\n",
    "            s1,s2 = states[t]\n",
    "            states[t] = [s2,s1]\n",
    "            sc.set_offsets(states[t])\n",
    "        else:\n",
    "            s1,s2 = states[t]\n",
    "            s1 = s1 + 0.5 if s1 < 0 else (s1 - 0.5 if s1 > 3 else s1)\n",
    "            s2 = s2 + 0.5 if s2 < 0 else (s2 - 0.5 if s2 > 3 else s2)\n",
    "            states[t] = [s2,s1]       \n",
    "            sc.set_offsets(states[t])\n",
    "    ani = FuncAnimation(fig,update,frames=len(states))\n",
    "    display(IPython.display.HTML(ani.to_jshtml()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "63d26411-c40f-4522-8ad0-4510b7b7f1d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "show([[0,0],[1,0],[2,0],[3,0],[4,0]]) # show 사용방법"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50212999-8bab-40b7-bc3d-098602e7287e",
   "metadata": {},
   "source": [
    "# 5. 4x4 Grid World 환경 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "8d3e8992-67e8-422c-81e8-d416f3130aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GridWorld:\n",
    "    def __init__(self):\n",
    "        self.a2d = {\n",
    "            0: np.array([0,1]), # →\n",
    "            1: np.array([0,-1]), # ←  \n",
    "            2: np.array([1,0]),  # ↓\n",
    "            3: np.array([-1,0])  # ↑\n",
    "        }\n",
    "        self.state = np.array([0,0])\n",
    "        self.state_space = gym.spaces.MultiDiscrete([4,4])\n",
    "        self.terminated = False \n",
    "        self.reward = None \n",
    "    def reset(self):\n",
    "        self.state = np.array([0,0])\n",
    "        self.reward = None \n",
    "        self.terminated = False\n",
    "    def step(self,action):\n",
    "        self.state = self.state + self.a2d[action]\n",
    "        s1,s2 = self.state \n",
    "        if (s1==3) and (s2==3):\n",
    "            self.reward = 100\n",
    "            self.terminated = True \n",
    "        elif self.state in self.state_space:\n",
    "            self.reward = -1 \n",
    "            self.terminated = False\n",
    "        else: \n",
    "            self.reward = -10 \n",
    "            self.terminated = True \n",
    "        print(\n",
    "            f\"action = {action}\\t\"\n",
    "            f\"state = {self.state - self.a2d[action]} -> {self.state}\\t\"\n",
    "            f\"reward = {self.reward}\\t\"\n",
    "            f\"termiated = {self.terminated}\"\n",
    "        )\n",
    "        return self.state, self.reward, self.terminated\n",
    "    def reset(self):\n",
    "        self.terminated = False \n",
    "        self.state = np.array([0,0])\n",
    "        return self.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "d15b6bfe-9ab2-4ab2-939b-dab3333921e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = GridWorld()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "a9f5b936-676d-4ad9-81dc-9c36dd3cfc58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action = 2  state = [0 0] -> [1 0]  reward = -1 termiated = False\n",
      "action = 1  state = [1 0] -> [ 1 -1]    reward = -10    termiated = True\n",
      "action = 3  state = [0 0] -> [-1  0]    reward = -10    termiated = True\n",
      "action = 0  state = [0 0] -> [0 1]  reward = -1 termiated = False\n",
      "action = 2  state = [0 1] -> [1 1]  reward = -1 termiated = False\n",
      "action = 3  state = [1 1] -> [0 1]  reward = -1 termiated = False\n",
      "action = 2  state = [0 1] -> [1 1]  reward = -1 termiated = False\n",
      "action = 1  state = [1 1] -> [1 0]  reward = -1 termiated = False\n",
      "action = 2  state = [1 0] -> [2 0]  reward = -1 termiated = False\n",
      "action = 0  state = [2 0] -> [2 1]  reward = -1 termiated = False"
     ]
    }
   ],
   "source": [
    "for t in range(10):\n",
    "    action = action_space.sample()\n",
    "    env.step(action)\n",
    "    if env.terminated:\n",
    "        env.state = env.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13baac13-5ba1-43dc-9cf3-acf7b0960c90",
   "metadata": {},
   "source": [
    "# 6. “에이전트 $\\Leftrightarrow$ 환경” 상호작용 구현\n",
    "\n",
    "`-` 우리가 구현하고 싶은 기능\n",
    "\n",
    "-   `.act()`: 액션을 결정 –\\> 여기서는 그냥 랜덤액션\n",
    "-   `.save_experience()`: 데이터를 저장 –\\> 여기에 일단 초점을 맞추자\n",
    "-   `.learn()`: 데이터로에서 학습 –\\> 패스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "0a30dc5e-e602-44fe-b884-29fa7ae6a430",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomAgent:\n",
    "    def __init__(self):\n",
    "        self.n_experiences = 0 \n",
    "        self.action_space = gym.spaces.Discrete(4)\n",
    "        #---#\n",
    "        self.state = None \n",
    "        self.action = None\n",
    "        self.reward = None \n",
    "        self.next_state = None \n",
    "        self.termiated = None\n",
    "        #---#\n",
    "        self.states = collections.deque(maxlen=500)\n",
    "        self.actions = collections.deque(maxlen=500)\n",
    "        self.rewards = collections.deque(maxlen=500)\n",
    "        self.next_states = collections.deque(maxlen=500)\n",
    "        self.terminations = collections.deque(maxlen=500)\n",
    "        #---#\n",
    "        #self.q_table = None \n",
    "    def act(self):\n",
    "        self.action = self.action_space.sample()\n",
    "    def save_experience(self):\n",
    "        self.states.append(self.state)\n",
    "        self.actions.append(self.action)        \n",
    "        self.rewards.append(self.reward)\n",
    "        self.next_states.append(self.next_state)\n",
    "        self.terminations.append(self.termiated)\n",
    "        self.n_experiences = self.n_experiences + 1 \n",
    "    def learn(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "f91c3cdf-f134-427a-b341-599e5bba1f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "player = RandomAgent()\n",
    "env = GridWorld()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "0b565c60-b029-427e-9c63-2c7e3c2e1b57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action = 2  state = [0 0] -> [1 0]  reward = -1 termiated = False\n",
      "action = 1  state = [1 0] -> [ 1 -1]    reward = -10    termiated = True"
     ]
    }
   ],
   "source": [
    "for _ in range(50):\n",
    "    # step1 : agent --> env \n",
    "    player.act()\n",
    "    # step2: agnet <-- env \n",
    "    player.next_state, player.reward, player.terminated = env.step(player.action)\n",
    "    # step3: agent: update (save + learn) \n",
    "    player.save_experience() \n",
    "    player.learn()\n",
    "    # step4: prepare next iterations \n",
    "    player.state = player.next_state\n",
    "    if env.terminated:\n",
    "        player.state = env.reset()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "d5dedcb4-b0e2-4df4-8dc2-7bda11434756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action = 3  state = [0 0] -> [-1  0]    reward = -10    termiated = True\n",
      "---에피소드1종료---\n",
      "action = 2  state = [0 0] -> [1 0]  reward = -1 termiated = False\n",
      "action = 0  state = [1 0] -> [1 1]  reward = -1 termiated = False\n",
      "action = 1  state = [1 1] -> [1 0]  reward = -1 termiated = False\n",
      "action = 1  state = [1 0] -> [ 1 -1]    reward = -10    termiated = True\n",
      "---에피소드2종료---\n",
      "action = 3  state = [0 0] -> [-1  0]    reward = -10    termiated = True\n",
      "---에피소드3종료---\n",
      "action = 3  state = [0 0] -> [-1  0]    reward = -10    termiated = True\n",
      "---에피소드4종료---\n",
      "action = 2  state = [0 0] -> [1 0]  reward = -1 termiated = False\n",
      "action = 1  state = [1 0] -> [ 1 -1]    reward = -10    termiated = True\n",
      "---에피소드5종료---\n",
      "action = 3  state = [0 0] -> [-1  0]    reward = -10    termiated = True\n",
      "---에피소드6종료---\n",
      "action = 1  state = [0 0] -> [ 0 -1]    reward = -10    termiated = True\n",
      "---에피소드7종료---\n",
      "action = 0  state = [0 0] -> [0 1]  reward = -1 termiated = False\n",
      "action = 1  state = [0 1] -> [0 0]  reward = -1 termiated = False\n",
      "action = 0  state = [0 0] -> [0 1]  reward = -1 termiated = False\n",
      "action = 2  state = [0 1] -> [1 1]  reward = -1 termiated = False\n",
      "action = 3  state = [1 1] -> [0 1]  reward = -1 termiated = False\n",
      "action = 2  state = [0 1] -> [1 1]  reward = -1 termiated = False\n",
      "action = 1  state = [1 1] -> [1 0]  reward = -1 termiated = False\n",
      "action = 2  state = [1 0] -> [2 0]  reward = -1 termiated = False\n",
      "action = 1  state = [2 0] -> [ 2 -1]    reward = -10    termiated = True\n",
      "---에피소드8종료---\n",
      "action = 1  state = [0 0] -> [ 0 -1]    reward = -10    termiated = True\n",
      "---에피소드9종료---\n",
      "action = 0  state = [0 0] -> [0 1]  reward = -1 termiated = False\n",
      "action = 0  state = [0 1] -> [0 2]  reward = -1 termiated = False\n",
      "action = 3  state = [0 2] -> [-1  2]    reward = -10    termiated = True\n",
      "---에피소드10종료---\n",
      "action = 0  state = [0 0] -> [0 1]  reward = -1 termiated = False\n",
      "action = 2  state = [0 1] -> [1 1]  reward = -1 termiated = False\n",
      "action = 3  state = [1 1] -> [0 1]  reward = -1 termiated = False\n",
      "action = 2  state = [0 1] -> [1 1]  reward = -1 termiated = False\n",
      "action = 2  state = [1 1] -> [2 1]  reward = -1 termiated = False\n",
      "action = 2  state = [2 1] -> [3 1]  reward = -1 termiated = False\n",
      "action = 1  state = [3 1] -> [3 0]  reward = -1 termiated = False\n",
      "action = 3  state = [3 0] -> [2 0]  reward = -1 termiated = False\n",
      "action = 0  state = [2 0] -> [2 1]  reward = -1 termiated = False\n",
      "action = 1  state = [2 1] -> [2 0]  reward = -1 termiated = False\n",
      "action = 3  state = [2 0] -> [1 0]  reward = -1 termiated = False\n",
      "action = 0  state = [1 0] -> [1 1]  reward = -1 termiated = False\n",
      "action = 1  state = [1 1] -> [1 0]  reward = -1 termiated = False\n",
      "action = 3  state = [1 0] -> [0 0]  reward = -1 termiated = False\n",
      "action = 2  state = [0 0] -> [1 0]  reward = -1 termiated = False\n",
      "action = 2  state = [1 0] -> [2 0]  reward = -1 termiated = False\n",
      "action = 2  state = [2 0] -> [3 0]  reward = -1 termiated = False\n",
      "action = 3  state = [3 0] -> [2 0]  reward = -1 termiated = False\n",
      "action = 0  state = [2 0] -> [2 1]  reward = -1 termiated = False\n",
      "action = 3  state = [2 1] -> [1 1]  reward = -1 termiated = False\n",
      "action = 0  state = [1 1] -> [1 2]  reward = -1 termiated = False\n",
      "action = 1  state = [1 2] -> [1 1]  reward = -1 termiated = False\n",
      "action = 0  state = [1 1] -> [1 2]  reward = -1 termiated = False\n",
      "action = 2  state = [1 2] -> [2 2]  reward = -1 termiated = False\n",
      "action = 1  state = [2 2] -> [2 1]  reward = -1 termiated = False\n",
      "action = 3  state = [2 1] -> [1 1]  reward = -1 termiated = False\n",
      "action = 2  state = [1 1] -> [2 1]  reward = -1 termiated = False\n",
      "action = 1  state = [2 1] -> [2 0]  reward = -1 termiated = False\n",
      "action = 0  state = [2 0] -> [2 1]  reward = -1 termiated = False\n",
      "action = 3  state = [2 1] -> [1 1]  reward = -1 termiated = False\n",
      "action = 3  state = [1 1] -> [0 1]  reward = -1 termiated = False\n",
      "action = 2  state = [0 1] -> [1 1]  reward = -1 termiated = False\n",
      "action = 3  state = [1 1] -> [0 1]  reward = -1 termiated = False\n",
      "action = 3  state = [0 1] -> [-1  1]    reward = -10    termiated = True\n",
      "---에피소드11종료---\n",
      "action = 3  state = [0 0] -> [-1  0]    reward = -10    termiated = True\n",
      "---에피소드12종료---\n",
      "action = 0  state = [0 0] -> [0 1]  reward = -1 termiated = False\n",
      "action = 0  state = [0 1] -> [0 2]  reward = -1 termiated = False\n",
      "action = 0  state = [0 2] -> [0 3]  reward = -1 termiated = False\n",
      "action = 1  state = [0 3] -> [0 2]  reward = -1 termiated = False\n",
      "action = 1  state = [0 2] -> [0 1]  reward = -1 termiated = False\n",
      "action = 0  state = [0 1] -> [0 2]  reward = -1 termiated = False\n",
      "action = 1  state = [0 2] -> [0 1]  reward = -1 termiated = False\n",
      "action = 3  state = [0 1] -> [-1  1]    reward = -10    termiated = True\n",
      "---에피소드13종료---\n",
      "action = 2  state = [0 0] -> [1 0]  reward = -1 termiated = False\n",
      "action = 0  state = [1 0] -> [1 1]  reward = -1 termiated = False\n",
      "action = 0  state = [1 1] -> [1 2]  reward = -1 termiated = False\n",
      "action = 1  state = [1 2] -> [1 1]  reward = -1 termiated = False\n",
      "action = 0  state = [1 1] -> [1 2]  reward = -1 termiated = False\n",
      "action = 1  state = [1 2] -> [1 1]  reward = -1 termiated = False\n",
      "action = 2  state = [1 1] -> [2 1]  reward = -1 termiated = False\n",
      "action = 1  state = [2 1] -> [2 0]  reward = -1 termiated = False\n",
      "action = 3  state = [2 0] -> [1 0]  reward = -1 termiated = False\n",
      "action = 2  state = [1 0] -> [2 0]  reward = -1 termiated = False\n",
      "action = 0  state = [2 0] -> [2 1]  reward = -1 termiated = False\n",
      "action = 0  state = [2 1] -> [2 2]  reward = -1 termiated = False\n",
      "action = 1  state = [2 2] -> [2 1]  reward = -1 termiated = False\n",
      "action = 1  state = [2 1] -> [2 0]  reward = -1 termiated = False\n",
      "action = 0  state = [2 0] -> [2 1]  reward = -1 termiated = False\n",
      "action = 2  state = [2 1] -> [3 1]  reward = -1 termiated = False\n",
      "action = 1  state = [3 1] -> [3 0]  reward = -1 termiated = False\n",
      "action = 2  state = [3 0] -> [4 0]  reward = -10    termiated = True\n",
      "---에피소드14종료---\n",
      "action = 0  state = [0 0] -> [0 1]  reward = -1 termiated = False\n",
      "action = 2  state = [0 1] -> [1 1]  reward = -1 termiated = False\n",
      "action = 2  state = [1 1] -> [2 1]  reward = -1 termiated = False\n",
      "action = 1  state = [2 1] -> [2 0]  reward = -1 termiated = False\n",
      "action = 0  state = [2 0] -> [2 1]  reward = -1 termiated = False\n",
      "action = 2  state = [2 1] -> [3 1]  reward = -1 termiated = False\n",
      "action = 3  state = [3 1] -> [2 1]  reward = -1 termiated = False\n",
      "action = 1  state = [2 1] -> [2 0]  reward = -1 termiated = False\n",
      "action = 2  state = [2 0] -> [3 0]  reward = -1 termiated = False\n",
      "action = 1  state = [3 0] -> [ 3 -1]    reward = -10    termiated = True\n",
      "---에피소드15종료---\n",
      "action = 3  state = [0 0] -> [-1  0]    reward = -10    termiated = True\n",
      "---에피소드16종료---\n",
      "action = 1  state = [0 0] -> [ 0 -1]    reward = -10    termiated = True\n",
      "---에피소드17종료---\n",
      "action = 0  state = [0 0] -> [0 1]  reward = -1 termiated = False\n",
      "action = 2  state = [0 1] -> [1 1]  reward = -1 termiated = False\n",
      "action = 1  state = [1 1] -> [1 0]  reward = -1 termiated = False\n",
      "action = 3  state = [1 0] -> [0 0]  reward = -1 termiated = False\n",
      "action = 2  state = [0 0] -> [1 0]  reward = -1 termiated = False\n",
      "action = 0  state = [1 0] -> [1 1]  reward = -1 termiated = False\n",
      "action = 2  state = [1 1] -> [2 1]  reward = -1 termiated = False\n",
      "action = 1  state = [2 1] -> [2 0]  reward = -1 termiated = False\n",
      "action = 0  state = [2 0] -> [2 1]  reward = -1 termiated = False\n",
      "action = 2  state = [2 1] -> [3 1]  reward = -1 termiated = False\n",
      "action = 0  state = [3 1] -> [3 2]  reward = -1 termiated = False\n",
      "action = 2  state = [3 2] -> [4 2]  reward = -10    termiated = True\n",
      "---에피소드18종료---\n",
      "action = 3  state = [0 0] -> [-1  0]    reward = -10    termiated = True\n",
      "---에피소드19종료---\n",
      "action = 1  state = [0 0] -> [ 0 -1]    reward = -10    termiated = True\n",
      "---에피소드20종료---\n",
      "action = 0  state = [0 0] -> [0 1]  reward = -1 termiated = False\n",
      "action = 2  state = [0 1] -> [1 1]  reward = -1 termiated = False\n",
      "action = 1  state = [1 1] -> [1 0]  reward = -1 termiated = False\n",
      "action = 0  state = [1 0] -> [1 1]  reward = -1 termiated = False\n",
      "action = 1  state = [1 1] -> [1 0]  reward = -1 termiated = False\n",
      "action = 0  state = [1 0] -> [1 1]  reward = -1 termiated = False\n",
      "action = 2  state = [1 1] -> [2 1]  reward = -1 termiated = False\n",
      "action = 0  state = [2 1] -> [2 2]  reward = -1 termiated = False\n",
      "action = 1  state = [2 2] -> [2 1]  reward = -1 termiated = False\n",
      "action = 0  state = [2 1] -> [2 2]  reward = -1 termiated = False\n",
      "action = 1  state = [2 2] -> [2 1]  reward = -1 termiated = False\n",
      "action = 0  state = [2 1] -> [2 2]  reward = -1 termiated = False\n",
      "action = 1  state = [2 2] -> [2 1]  reward = -1 termiated = False\n",
      "action = 2  state = [2 1] -> [3 1]  reward = -1 termiated = False\n",
      "action = 1  state = [3 1] -> [3 0]  reward = -1 termiated = False\n",
      "action = 0  state = [3 0] -> [3 1]  reward = -1 termiated = False\n",
      "action = 2  state = [3 1] -> [4 1]  reward = -10    termiated = True\n",
      "---에피소드21종료---\n",
      "action = 0  state = [0 0] -> [0 1]  reward = -1 termiated = False\n",
      "action = 3  state = [0 1] -> [-1  1]    reward = -10    termiated = True\n",
      "---에피소드22종료---\n",
      "action = 0  state = [0 0] -> [0 1]  reward = -1 termiated = False\n",
      "action = 3  state = [0 1] -> [-1  1]    reward = -10    termiated = True\n",
      "---에피소드23종료---\n",
      "action = 1  state = [0 0] -> [ 0 -1]    reward = -10    termiated = True\n",
      "---에피소드24종료---\n",
      "action = 0  state = [0 0] -> [0 1]  reward = -1 termiated = False\n",
      "action = 1  state = [0 1] -> [0 0]  reward = -1 termiated = False\n",
      "action = 0  state = [0 0] -> [0 1]  reward = -1 termiated = False\n",
      "action = 1  state = [0 1] -> [0 0]  reward = -1 termiated = False\n",
      "action = 1  state = [0 0] -> [ 0 -1]    reward = -10    termiated = True\n",
      "---에피소드25종료---\n",
      "action = 3  state = [0 0] -> [-1  0]    reward = -10    termiated = True\n",
      "---에피소드26종료---\n",
      "action = 2  state = [0 0] -> [1 0]  reward = -1 termiated = False\n",
      "action = 3  state = [1 0] -> [0 0]  reward = -1 termiated = False\n",
      "action = 2  state = [0 0] -> [1 0]  reward = -1 termiated = False\n",
      "action = 2  state = [1 0] -> [2 0]  reward = -1 termiated = False\n",
      "action = 2  state = [2 0] -> [3 0]  reward = -1 termiated = False\n",
      "action = 1  state = [3 0] -> [ 3 -1]    reward = -10    termiated = True\n",
      "---에피소드27종료---\n",
      "action = 2  state = [0 0] -> [1 0]  reward = -1 termiated = False\n",
      "action = 2  state = [1 0] -> [2 0]  reward = -1 termiated = False\n",
      "action = 3  state = [2 0] -> [1 0]  reward = -1 termiated = False\n",
      "action = 0  state = [1 0] -> [1 1]  reward = -1 termiated = False\n",
      "action = 0  state = [1 1] -> [1 2]  reward = -1 termiated = False\n",
      "action = 1  state = [1 2] -> [1 1]  reward = -1 termiated = False\n",
      "action = 0  state = [1 1] -> [1 2]  reward = -1 termiated = False\n",
      "action = 1  state = [1 2] -> [1 1]  reward = -1 termiated = False\n",
      "action = 1  state = [1 1] -> [1 0]  reward = -1 termiated = False\n",
      "action = 3  state = [1 0] -> [0 0]  reward = -1 termiated = False\n",
      "action = 1  state = [0 0] -> [ 0 -1]    reward = -10    termiated = True\n",
      "---에피소드28종료---\n",
      "action = 1  state = [0 0] -> [ 0 -1]    reward = -10    termiated = True\n",
      "---에피소드29종료---\n",
      "action = 0  state = [0 0] -> [0 1]  reward = -1 termiated = False\n",
      "action = 0  state = [0 1] -> [0 2]  reward = -1 termiated = False\n",
      "action = 1  state = [0 2] -> [0 1]  reward = -1 termiated = False\n",
      "action = 2  state = [0 1] -> [1 1]  reward = -1 termiated = False\n",
      "action = 3  state = [1 1] -> [0 1]  reward = -1 termiated = False\n",
      "action = 2  state = [0 1] -> [1 1]  reward = -1 termiated = False\n",
      "action = 2  state = [1 1] -> [2 1]  reward = -1 termiated = False\n",
      "action = 0  state = [2 1] -> [2 2]  reward = -1 termiated = False\n",
      "action = 0  state = [2 2] -> [2 3]  reward = -1 termiated = False\n",
      "action = 3  state = [2 3] -> [1 3]  reward = -1 termiated = False\n",
      "action = 0  state = [1 3] -> [1 4]  reward = -10    termiated = True\n",
      "---에피소드30종료---\n",
      "action = 0  state = [0 0] -> [0 1]  reward = -1 termiated = False\n",
      "action = 1  state = [0 1] -> [0 0]  reward = -1 termiated = False\n",
      "action = 1  state = [0 0] -> [ 0 -1]    reward = -10    termiated = True\n",
      "---에피소드31종료---\n",
      "action = 2  state = [0 0] -> [1 0]  reward = -1 termiated = False\n",
      "action = 3  state = [1 0] -> [0 0]  reward = -1 termiated = False\n",
      "action = 1  state = [0 0] -> [ 0 -1]    reward = -10    termiated = True\n",
      "---에피소드32종료---\n",
      "action = 1  state = [0 0] -> [ 0 -1]    reward = -10    termiated = True\n",
      "---에피소드33종료---\n",
      "action = 3  state = [0 0] -> [-1  0]    reward = -10    termiated = True\n",
      "---에피소드34종료---\n",
      "action = 1  state = [0 0] -> [ 0 -1]    reward = -10    termiated = True\n",
      "---에피소드35종료---\n",
      "action = 0  state = [0 0] -> [0 1]  reward = -1 termiated = False\n",
      "action = 1  state = [0 1] -> [0 0]  reward = -1 termiated = False\n",
      "action = 0  state = [0 0] -> [0 1]  reward = -1 termiated = False\n",
      "action = 2  state = [0 1] -> [1 1]  reward = -1 termiated = False\n",
      "action = 0  state = [1 1] -> [1 2]  reward = -1 termiated = False\n",
      "action = 0  state = [1 2] -> [1 3]  reward = -1 termiated = False\n",
      "action = 3  state = [1 3] -> [0 3]  reward = -1 termiated = False\n",
      "action = 1  state = [0 3] -> [0 2]  reward = -1 termiated = False\n",
      "action = 3  state = [0 2] -> [-1  2]    reward = -10    termiated = True\n",
      "---에피소드36종료---\n",
      "action = 3  state = [0 0] -> [-1  0]    reward = -10    termiated = True\n",
      "---에피소드37종료---\n",
      "action = 1  state = [0 0] -> [ 0 -1]    reward = -10    termiated = True\n",
      "---에피소드38종료---\n",
      "action = 1  state = [0 0] -> [ 0 -1]    reward = -10    termiated = True\n",
      "---에피소드39종료---\n",
      "action = 2  state = [0 0] -> [1 0]  reward = -1 termiated = False\n",
      "action = 0  state = [1 0] -> [1 1]  reward = -1 termiated = False\n",
      "action = 0  state = [1 1] -> [1 2]  reward = -1 termiated = False\n",
      "action = 1  state = [1 2] -> [1 1]  reward = -1 termiated = False\n",
      "action = 0  state = [1 1] -> [1 2]  reward = -1 termiated = False\n",
      "action = 2  state = [1 2] -> [2 2]  reward = -1 termiated = False\n",
      "action = 3  state = [2 2] -> [1 2]  reward = -1 termiated = False\n",
      "action = 1  state = [1 2] -> [1 1]  reward = -1 termiated = False\n",
      "action = 0  state = [1 1] -> [1 2]  reward = -1 termiated = False\n",
      "action = 3  state = [1 2] -> [0 2]  reward = -1 termiated = False\n",
      "action = 1  state = [0 2] -> [0 1]  reward = -1 termiated = False\n",
      "action = 1  state = [0 1] -> [0 0]  reward = -1 termiated = False\n",
      "action = 0  state = [0 0] -> [0 1]  reward = -1 termiated = False\n",
      "action = 1  state = [0 1] -> [0 0]  reward = -1 termiated = False\n",
      "action = 3  state = [0 0] -> [-1  0]    reward = -10    termiated = True\n",
      "---에피소드40종료---\n",
      "action = 1  state = [0 0] -> [ 0 -1]    reward = -10    termiated = True\n",
      "---에피소드41종료---\n",
      "action = 0  state = [0 0] -> [0 1]  reward = -1 termiated = False\n",
      "action = 1  state = [0 1] -> [0 0]  reward = -1 termiated = False\n",
      "action = 3  state = [0 0] -> [-1  0]    reward = -10    termiated = True\n",
      "---에피소드42종료---\n",
      "action = 2  state = [0 0] -> [1 0]  reward = -1 termiated = False\n",
      "action = 2  state = [1 0] -> [2 0]  reward = -1 termiated = False\n",
      "action = 3  state = [2 0] -> [1 0]  reward = -1 termiated = False\n",
      "action = 3  state = [1 0] -> [0 0]  reward = -1 termiated = False\n",
      "action = 3  state = [0 0] -> [-1  0]    reward = -10    termiated = True\n",
      "---에피소드43종료---\n",
      "action = 2  state = [0 0] -> [1 0]  reward = -1 termiated = False\n",
      "action = 1  state = [1 0] -> [ 1 -1]    reward = -10    termiated = True\n",
      "---에피소드44종료---\n",
      "action = 0  state = [0 0] -> [0 1]  reward = -1 termiated = False\n",
      "action = 0  state = [0 1] -> [0 2]  reward = -1 termiated = False\n",
      "action = 0  state = [0 2] -> [0 3]  reward = -1 termiated = False\n",
      "action = 3  state = [0 3] -> [-1  3]    reward = -10    termiated = True\n",
      "---에피소드45종료---\n",
      "action = 3  state = [0 0] -> [-1  0]    reward = -10    termiated = True\n",
      "---에피소드46종료---\n",
      "action = 1  state = [0 0] -> [ 0 -1]    reward = -10    termiated = True\n",
      "---에피소드47종료---\n",
      "action = 1  state = [0 0] -> [ 0 -1]    reward = -10    termiated = True\n",
      "---에피소드48종료---\n",
      "action = 1  state = [0 0] -> [ 0 -1]    reward = -10    termiated = True\n",
      "---에피소드49종료---\n",
      "action = 3  state = [0 0] -> [-1  0]    reward = -10    termiated = True\n",
      "---에피소드50종료---\n",
      "action = 1  state = [0 0] -> [ 0 -1]    reward = -10    termiated = True\n",
      "---에피소드51종료---\n",
      "action = 0  state = [0 0] -> [0 1]  reward = -1 termiated = False\n",
      "action = 2  state = [0 1] -> [1 1]  reward = -1 termiated = False\n",
      "action = 0  state = [1 1] -> [1 2]  reward = -1 termiated = False\n",
      "action = 0  state = [1 2] -> [1 3]  reward = -1 termiated = False\n",
      "action = 3  state = [1 3] -> [0 3]  reward = -1 termiated = False\n",
      "action = 1  state = [0 3] -> [0 2]  reward = -1 termiated = False\n",
      "action = 0  state = [0 2] -> [0 3]  reward = -1 termiated = False\n",
      "action = 2  state = [0 3] -> [1 3]  reward = -1 termiated = False\n",
      "action = 3  state = [1 3] -> [0 3]  reward = -1 termiated = False\n",
      "action = 2  state = [0 3] -> [1 3]  reward = -1 termiated = False\n",
      "action = 2  state = [1 3] -> [2 3]  reward = -1 termiated = False\n",
      "action = 1  state = [2 3] -> [2 2]  reward = -1 termiated = False\n",
      "action = 2  state = [2 2] -> [3 2]  reward = -1 termiated = False\n",
      "action = 3  state = [3 2] -> [2 2]  reward = -1 termiated = False\n",
      "action = 1  state = [2 2] -> [2 1]  reward = -1 termiated = False\n",
      "action = 2  state = [2 1] -> [3 1]  reward = -1 termiated = False\n",
      "action = 0  state = [3 1] -> [3 2]  reward = -1 termiated = False\n",
      "action = 3  state = [3 2] -> [2 2]  reward = -1 termiated = False\n",
      "action = 2  state = [2 2] -> [3 2]  reward = -1 termiated = False\n",
      "action = 0  state = [3 2] -> [3 3]  reward = 100    termiated = True\n",
      "---에피소드52종료---"
     ]
    }
   ],
   "source": [
    "scores = [] \n",
    "playtimes = []\n",
    "for e in range(1,1000):\n",
    "    player.state = env.reset()\n",
    "    score = 0 \n",
    "    #---#\n",
    "    for playtime in range(1,50):\n",
    "        # step1 : agent --> env \n",
    "        player.act()\n",
    "        # step2: agnet <-- env \n",
    "        player.next_state, player.reward, player.terminated = env.step(player.action)\n",
    "        # step3: agent: update (save + learn) \n",
    "        player.save_experience() \n",
    "        player.learn()\n",
    "        # step4: prepare next iterations \n",
    "        player.state = player.next_state\n",
    "        score = score + player.reward\n",
    "        if env.terminated:\n",
    "            print(f\"---에피소드{e}종료---\")\n",
    "            break\n",
    "    #---#\n",
    "    scores.append(score)\n",
    "    if scores[-1] > 0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "e903a918-8d0e-4c1b-b671-0dbec09e1f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "ea940746-b1f5-4c5f-963a-61b013ab5426",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = [np.array([0,0])]+ list(player.next_states)[-20:]\n",
    "show(paths)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
