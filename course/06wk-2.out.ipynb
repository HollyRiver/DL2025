{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be8526d6-58dc-45f8-b26b-c5873f8f618b",
   "metadata": {},
   "source": [
    "# 06wk-2: (신경망, 합성곱신경망) – 다항분류, 합성곱신경망\n",
    "\n",
    "최규빈  \n",
    "2025-04-14\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/guebin/DL2025/blob/main/posts/06wk-2.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" style=\"text-align: left\"></a>\n",
    "\n",
    "# 1. 강의영상"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ecdca12a-79f7-4e58-b76b-fe6d70131060",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# {{<video https://youtu.be/playlist?list=PLQqh36zP38-yx6DQsLACqw8pWm0udv8Jm&si=in1eMD0-wU49y7mS >}}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220e1493-c9cd-47dc-b3ee-e7104915f9a6",
   "metadata": {},
   "source": [
    "# 2. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c997af13-4f2b-45b9-967b-41e6f7d5725f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c6c8254-c4a2-468f-a77b-10cf791b1bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (4.5, 3.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e784abe2-dd6f-4a0c-acf5-5f238ec9272a",
   "metadata": {},
   "source": [
    "# 3. 다항분류\n",
    "\n",
    "## A. 이항분류와 `BCEWithLogitsLoss`\n",
    "\n",
    "`-` 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9cdc473d-e5f4-4f7d-9763-76c7b712d469",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True)\n",
    "to_tensor = torchvision.transforms.ToTensor()\n",
    "X0_train = torch.stack([to_tensor(Xi) for Xi, yi in train_dataset if yi==0])\n",
    "X1_train = torch.stack([to_tensor(Xi) for Xi, yi in train_dataset if yi==1])\n",
    "X = torch.concat([X0_train,X1_train],axis=0).reshape(-1,784)\n",
    "y = torch.tensor([0.0]*len(X0_train) + [1.0]*len(X1_train)).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1779c72-a113-4b23-93fd-6505a03e8c51",
   "metadata": {},
   "source": [
    "`-` 예전코드는 아래와 같음 (sig는 수동처리함)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9eb437e4-8139-4202-8167-7e14016b62bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 1    acc = 0.4677\n",
      "epoch = 2    acc = 0.4677\n",
      "epoch = 3    acc = 0.4745\n",
      "epoch = 4    acc = 0.5572\n",
      "epoch = 5    acc = 0.6995\n",
      "epoch = 6    acc = 0.8175\n",
      "epoch = 7    acc = 0.8904\n",
      "epoch = 8    acc = 0.9255\n",
      "epoch = 9    acc = 0.9444\n",
      "epoch = 10   acc = 0.9577"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "net = torch.nn.Sequential(\n",
    "    torch.nn.Linear(784,32),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(32,1)\n",
    ")\n",
    "loss_fn = torch.nn.BCELoss()\n",
    "optimizr = torch.optim.Adam(net.parameters())\n",
    "#---#\n",
    "for epoc in range(1,11):\n",
    "    # step1 \n",
    "    netout = net(X) # netout = logits \n",
    "    yhat = torch.exp(netout) / (1 + torch.exp(netout)) # yhat = prob \n",
    "    # step2\n",
    "    loss = loss_fn(yhat,y) \n",
    "    # step3     \n",
    "    loss.backward()\n",
    "    # step4 \n",
    "    optimizr.step()\n",
    "    optimizr.zero_grad()\n",
    "    #---에폭끝나고 확인할 것들---#\n",
    "    acc = ((net(X).data > 0)  == y).float().mean()\n",
    "    print(f\"epoch = {epoc}\\t acc = {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b00a64e-bf38-4a81-b473-b4d7d80774c9",
   "metadata": {},
   "source": [
    "`#` netout(= logits) 의 특징\n",
    "\n",
    "-   $netout > 0 \\Leftrightarrow sig(netout) >0.5$\n",
    "-   $netout < 0 \\Leftrightarrow sig(netout) <0.5$\n",
    "\n",
    "`-` 그런데 위의 코드는 아래의 코드와 같음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d9b3fe1-4d8a-460c-901b-5ac88bd6b8b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 1    acc = 0.4677\n",
      "epoch = 2    acc = 0.4677\n",
      "epoch = 3    acc = 0.4745\n",
      "epoch = 4    acc = 0.5572\n",
      "epoch = 5    acc = 0.6995\n",
      "epoch = 6    acc = 0.8175\n",
      "epoch = 7    acc = 0.8904\n",
      "epoch = 8    acc = 0.9255\n",
      "epoch = 9    acc = 0.9444\n",
      "epoch = 10   acc = 0.9577"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "net = torch.nn.Sequential(\n",
    "    torch.nn.Linear(784,32),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(32,1)\n",
    ")\n",
    "loss_fn = torch.nn.BCEWithLogitsLoss() # <--- 여기를 바꾸고 \n",
    "optimizr = torch.optim.Adam(net.parameters())\n",
    "#---#\n",
    "for epoc in range(1,11):\n",
    "    # step1 \n",
    "    netout = net(X) # netout = logits \n",
    "    # yhat = torch.exp(netout) / (1 + torch.exp(netout))  # yhat = prob  # <-- 여기는주석처리\n",
    "    # step2\n",
    "    loss = loss_fn(netout,y) \n",
    "    # step3     \n",
    "    loss.backward()\n",
    "    # step4 \n",
    "    optimizr.step()\n",
    "    optimizr.zero_grad()\n",
    "    #---에폭끝나고 확인할 것들---#\n",
    "    acc = ((net(X).data > 0)  == y).float().mean()\n",
    "    print(f\"epoch = {epoc}\\t acc = {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec40b33d-8347-4417-9429-7338c255676d",
   "metadata": {},
   "source": [
    "## B. 범주형자료의 변환\n",
    "\n",
    "`-` 범주형자료를 숫자로 어떻게 바꿀까?\n",
    "\n",
    "-   실패 / 성공 $\\to$ 0 / 1\n",
    "-   숫자0그림 / 숫자1그림 $\\to$ 0 / 1\n",
    "-   강아지그림 / 고양이그림 $\\to$ 0 / 1\n",
    "-   강아지그림 / 고양이그림 / 토끼그림 $\\to$ 0 / 1 / 2 ?????\n",
    "\n",
    "`-` 주입식교육: 강아지그림/고양이그림/토끼그림일 경우 숫자화시키는 방법\n",
    "\n",
    "-   잘못된방식: 강아지그림 = 0, 고양이그림 = 1, 토끼그림 = 2\n",
    "-   올바른방식: 강아지그림 = \\[1,0,0\\], 고양이그림 = \\[0,1,0\\], 토끼그림\n",
    "    = \\[0,0,1\\] \\### \\<– 이런방식을 원핫인코딩이라함\n",
    "\n",
    "`-` 왜?\n",
    "\n",
    "-   설명1: 강아지그림, 고양이그림, 토끼그림은 서열측도가 아니라\n",
    "    명목척도임. 그래서 범주를 0,1,2 로 숫자화하면 평균등의 의미가 없음\n",
    "    (사회조사분석사 2급 스타일)\n",
    "-   설명2: 범주형은 원핫인코딩으로 해야함 (“30일만에 끝내는\n",
    "    실전머신러닝” 이런 책에 나오는 스타일)\n",
    "-   설명3: 동전을 한번 던져서 나오는 결과는 $n=1$인 이항분포를 따름.\n",
    "    주사위 한번 던져서 나오는 눈금의 숫자는 $n=1$인 다항분포를 따름.\n",
    "    $n=1$인 이항분포의 실현값은 0,1 이고, $n=1$인 다항분포의 실현값은\n",
    "    \\[1,0,0\\], \\[0,1,0\\], \\[0,0,1\\] 이므로 당연히 $y_i$ 는 \\[1,0,0\\],\n",
    "    \\[0,1,0\\], \\[0,0,1\\] 중 하나의 형태를 가진다고 가정하는게 바람직함\n",
    "    (이 설명이 이 중에서 가장 정확한 설명임)\n",
    "\n",
    "## C. 실습: 3개의 클래스를 구분\n",
    "\n",
    "`-` 데이터준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7ec1bd3-9954-4ade-93cc-d9c6880e365f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True)\n",
    "to_tensor = torchvision.transforms.ToTensor()\n",
    "X0 = torch.stack([to_tensor(Xi) for Xi, yi in train_dataset if yi==0])\n",
    "X1 = torch.stack([to_tensor(Xi) for Xi, yi in train_dataset if yi==1])\n",
    "X2 = torch.stack([to_tensor(Xi) for Xi, yi in train_dataset if yi==2])\n",
    "X = torch.concat([X0,X1,X2]).reshape(-1,1*28*28)\n",
    "y = torch.tensor([0]*len(X0) + [1]*len(X1)+ [2]*len(X2)).reshape(-1,1).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c42b928a-7125-482f-b898-c65f36a389c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.nn.functional.one_hot(y.flatten().long()).float()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efea239e-0111-4580-bb08-ac6d8ca4c06c",
   "metadata": {},
   "source": [
    "`-` 적합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fba6e0ab-6d10-4ca3-bc6a-00f0777eb303",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(43052)\n",
    "net = torch.nn.Sequential(\n",
    "    torch.nn.Linear(784,32),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(32,3),\n",
    ")\n",
    "loss_fn = torch.nn.CrossEntropyLoss() # 이름이 좀 그래.. 나같으면 CEWithLogitsLoss 라고 했을듯 \n",
    "optimizr = torch.optim.Adam(net.parameters())\n",
    "#---#\n",
    "for epoc in range(100):\n",
    "    ## step1 \n",
    "    netout = net(X)\n",
    "    ## step2 \n",
    "    loss = loss_fn(netout,y)\n",
    "    ## step3 \n",
    "    loss.backward()\n",
    "    ## step4 \n",
    "    optimizr.step()\n",
    "    optimizr.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c9960353-82f1-46d6-afab-0c6df59ebb60",
   "metadata": {},
   "outputs": [],
   "source": [
    "(net(X).argmax(axis=1)  == y.argmax(axis=1)).float().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d53a51-d852-491b-a163-9b6b5c706310",
   "metadata": {},
   "source": [
    "## D. 결론 – 외우세여\n",
    "\n",
    "`-` 파이토치버전 // 코딩용\n",
    "\n",
    "|   분류   | netout의 의미 |      손실함수       |\n",
    "|:--------:|:-------------:|:-------------------:|\n",
    "| 이항분류 |     prob      |      `BCELoss`      |\n",
    "| 이항분류 |     logit     | `BCEWithLogitsLoss` |\n",
    "| 다항분류 |     probs     |         NA          |\n",
    "| 다항분류 |    logits     | `CrossEntropyLoss`  |\n",
    "\n",
    "> `CrossEntropyLoss` 이거 이름이 완전 마음에 안들어요..\n",
    "> `CEWithLogitsLoss` 라고 하는게 더 좋을 것 같습니다.\n",
    "\n",
    "`-` 일반적개념 // 이론용\n",
    "\n",
    "|   분류   | 오차항의가정 | 마지막활성화함수 |       손실함수       |\n",
    "|:--------:|:------------:|:----------------:|:--------------------:|\n",
    "| 이항분류 |   이항분포   |    sigmoid[1]    | Binary Cross Entropy |\n",
    "| 다항분류 |   다항분포   |    softmax[2]    |    Cross Entropy     |\n",
    "\n",
    "# 4. FashionMNIST\n",
    "\n",
    "## A. 데이터\n",
    "\n",
    "<https://arxiv.org/abs/1708.07747> (Xiao, Rasul, and Vollgraf 2017)\n",
    "\n",
    "[1] prob=sig(logit)\n",
    "\n",
    "[2] probs=soft(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "42a7ef81-8f3d-42b8-9e18-c21ee42b621e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torchvision.datasets.FashionMNIST(root='./data', train=True, download=True)\n",
    "test_dataset = torchvision.datasets.FashionMNIST(root='./data', train=False, download=True)\n",
    "to_tensor = torchvision.transforms.ToTensor()\n",
    "X = torch.stack([to_tensor(img) for img, lbl in train_dataset])\n",
    "y = torch.tensor([lbl for img, lbl in train_dataset])\n",
    "y = torch.nn.functional.one_hot(y).float()\n",
    "XX = torch.stack([to_tensor(img) for img, lbl in test_dataset])\n",
    "yy = torch.tensor([lbl for img, lbl in test_dataset])\n",
    "yy = torch.nn.functional.one_hot(yy).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "ef3d9f39-d791-4f48-b948-67d28f4e0cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = torch.utils.data.TensorDataset(X,y)\n",
    "dl_train = torch.utils.data.DataLoader(ds_train,batch_size=256,shuffle=True)\n",
    "ds_test = torch.utils.data.TensorDataset(XX,yy)\n",
    "dl_test = torch.utils.data.DataLoader(ds_test,batch_size=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6de3365-cb17-422c-8487-1a9fe2c3c51b",
   "metadata": {},
   "source": [
    "## B. 간단한 신경망"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "0794311c-fbf5-408f-9bdf-ba4cb46a7e86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of epochs = 5  train_acc = 0.8588\n",
      "# of epochs = 10     train_acc = 0.8659\n",
      "# of epochs = 15     train_acc = 0.8779\n",
      "# of epochs = 20     train_acc = 0.8830\n",
      "# of epochs = 25     train_acc = 0.8857\n",
      "# of epochs = 30     train_acc = 0.8875"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(43052)\n",
    "net = torch.nn.Sequential(\n",
    "    torch.nn.Flatten(),\n",
    "    torch.nn.Linear(784,32),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(32,10)\n",
    ").to(\"cuda:0\")\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizr = torch.optim.Adam(net.parameters())\n",
    "#---#\n",
    "for epoc in range(1,31):\n",
    "    #---에폭시작---#\n",
    "    net.train()\n",
    "    for Xm,ym in dl_train:\n",
    "        Xm = Xm.to(\"cuda:0\")\n",
    "        ym = ym.to(\"cuda:0\")\n",
    "        # Step1\n",
    "        netout = net(Xm)\n",
    "        # Step2\n",
    "        loss = loss_fn(netout,ym) \n",
    "        # Step3\n",
    "        loss.backward()\n",
    "        # Step4 \n",
    "        optimizr.step()\n",
    "        optimizr.zero_grad()\n",
    "    #---에폭끝---#\n",
    "    if epoc % 5 ==0:\n",
    "        net.eval()\n",
    "        s = 0 \n",
    "        for Xm,ym in dl_train:\n",
    "            Xm = Xm.to(\"cuda:0\")\n",
    "            ym = ym.to(\"cuda:0\")        \n",
    "            s = s+(net(Xm).data.argmax(axis=1) == ym.argmax(axis=1)).float().sum().item()\n",
    "        acc = s / len(X)\n",
    "        print(f\"# of epochs = {epoc}\\t train_acc = {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "90c9d25c-d1ce-4055-9dc0-b93344acb7aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc = 0.8639"
     ]
    }
   ],
   "source": [
    "net.eval()\n",
    "s = 0 \n",
    "for Xm,ym in dl_test:\n",
    "    Xm = Xm.to(\"cuda:0\")\n",
    "    ym = ym.to(\"cuda:0\")        \n",
    "    s = s+(net(Xm).data.argmax(axis=1) == ym.argmax(axis=1)).float().sum().item()\n",
    "acc = s / len(XX)\n",
    "print(f\"test_acc = {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "71b240e2-9475-49c3-aca0-ae81501a5131",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum([torch.tensor(para.shape).prod().item() for para in net.parameters()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bbeb9ad-434e-4fba-b3f5-77dfe48b8924",
   "metadata": {},
   "source": [
    "## C. 복잡한 신경망"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "f4b7e313-0663-45aa-bfa9-78ff46fc1ea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of epochs = 5  train_acc = 0.8831\n",
      "# of epochs = 10     train_acc = 0.9028\n",
      "# of epochs = 15     train_acc = 0.9183\n",
      "# of epochs = 20     train_acc = 0.9281\n",
      "# of epochs = 25     train_acc = 0.9331\n",
      "# of epochs = 30     train_acc = 0.9332"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(43052)\n",
    "net = torch.nn.Sequential(\n",
    "    torch.nn.Flatten(),\n",
    "    torch.nn.Linear(784,256),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(256,10)\n",
    ").to(\"cuda:0\")\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizr = torch.optim.Adam(net.parameters())\n",
    "#---#\n",
    "for epoc in range(1,31):\n",
    "    #---에폭시작---#\n",
    "    net.train()\n",
    "    for Xm,ym in dl_train:\n",
    "        Xm = Xm.to(\"cuda:0\")\n",
    "        ym = ym.to(\"cuda:0\")\n",
    "        # Step1\n",
    "        netout = net(Xm)\n",
    "        # Step2\n",
    "        loss = loss_fn(netout,ym) \n",
    "        # Step3\n",
    "        loss.backward()\n",
    "        # Step4 \n",
    "        optimizr.step()\n",
    "        optimizr.zero_grad()\n",
    "    #---에폭끝---#\n",
    "    if epoc % 5 ==0:\n",
    "        net.eval()\n",
    "        s = 0 \n",
    "        for Xm,ym in dl_train:\n",
    "            Xm = Xm.to(\"cuda:0\")\n",
    "            ym = ym.to(\"cuda:0\")        \n",
    "            s = s+(net(Xm).data.argmax(axis=1) == ym.argmax(axis=1)).float().sum().item()\n",
    "        acc = s / len(X)\n",
    "        print(f\"# of epochs = {epoc}\\t train_acc = {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "97f9da7a-077d-445b-8191-2d359258a0a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc = 0.8833"
     ]
    }
   ],
   "source": [
    "net.eval()\n",
    "s = 0 \n",
    "for Xm,ym in dl_test:\n",
    "    Xm = Xm.to(\"cuda:0\")\n",
    "    ym = ym.to(\"cuda:0\")        \n",
    "    s = s+(net(Xm).data.argmax(axis=1) == ym.argmax(axis=1)).float().sum().item()\n",
    "acc = s / len(XX)\n",
    "print(f\"test_acc = {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "69abc9c3-8377-4ec2-9101-fff8c3f8e8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum([torch.tensor(para.shape).prod().item() for para in net.parameters()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc077898-7463-4412-be61-eb06be625826",
   "metadata": {},
   "source": [
    "## D. 발악해보세요\n",
    "\n",
    "`-` 아주 넓게.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "ab841133-6e67-4e60-9e8d-b72f1c6b815a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of epochs = 5  train_acc = 0.8885\n",
      "# of epochs = 10     train_acc = 0.8977\n",
      "# of epochs = 15     train_acc = 0.9130\n",
      "# of epochs = 20     train_acc = 0.9232\n",
      "# of epochs = 25     train_acc = 0.9318\n",
      "# of epochs = 30     train_acc = 0.9308"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(43052)\n",
    "net = torch.nn.Sequential(\n",
    "    torch.nn.Flatten(),\n",
    "    torch.nn.Linear(784,4096),\n",
    "    torch.nn.Dropout(0.5),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(4096,10),\n",
    ").to(\"cuda:0\")\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizr = torch.optim.Adam(net.parameters())\n",
    "#---#\n",
    "for epoc in range(1,31):\n",
    "    #---에폭시작---#\n",
    "    net.train()\n",
    "    for Xm,ym in dl_train:\n",
    "        Xm = Xm.to(\"cuda:0\")\n",
    "        ym = ym.to(\"cuda:0\")\n",
    "        # Step1\n",
    "        netout = net(Xm)\n",
    "        # Step2\n",
    "        loss = loss_fn(netout,ym) \n",
    "        # Step3\n",
    "        loss.backward()\n",
    "        # Step4 \n",
    "        optimizr.step()\n",
    "        optimizr.zero_grad()\n",
    "    #---에폭끝---#\n",
    "    if epoc % 5 ==0:\n",
    "        net.eval()\n",
    "        s = 0 \n",
    "        for Xm,ym in dl_train:\n",
    "            Xm = Xm.to(\"cuda:0\")\n",
    "            ym = ym.to(\"cuda:0\")        \n",
    "            s = s+(net(Xm).data.argmax(axis=1) == ym.argmax(axis=1)).float().sum().item()\n",
    "        acc = s / len(X)\n",
    "        print(f\"# of epochs = {epoc}\\t train_acc = {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "0ea817a7-f0ea-4366-ad89-518a6b056aa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc = 0.8934"
     ]
    }
   ],
   "source": [
    "net.eval()\n",
    "s = 0 \n",
    "for Xm,ym in dl_test:\n",
    "    Xm = Xm.to(\"cuda:0\")\n",
    "    ym = ym.to(\"cuda:0\")        \n",
    "    s = s+(net(Xm).data.argmax(axis=1) == ym.argmax(axis=1)).float().sum().item()\n",
    "acc = s / len(XX)\n",
    "print(f\"test_acc = {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "4338b8de-d410-48a8-af1f-6f36e08ea28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum([torch.tensor(para.shape).prod().item() for para in net.parameters()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e092b156-85d7-4c8f-b9a0-0b0de5944504",
   "metadata": {},
   "source": [
    "`-` 아주 깊게.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "7e141a44-de71-4774-b734-35c81da6c31f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of epochs = 5  train_acc = 0.8903\n",
      "# of epochs = 10     train_acc = 0.9157\n",
      "# of epochs = 15     train_acc = 0.9281\n",
      "# of epochs = 20     train_acc = 0.9333\n",
      "# of epochs = 25     train_acc = 0.9424\n",
      "# of epochs = 30     train_acc = 0.9524"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(43052)\n",
    "net = torch.nn.Sequential(\n",
    "    torch.nn.Flatten(),\n",
    "    torch.nn.Linear(784,256),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(256,256),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(256,256),\n",
    "    torch.nn.Dropout(0.5),    \n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(256,256),\n",
    "    torch.nn.Dropout(0.5),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(256,10),\n",
    ").to(\"cuda:0\")\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizr = torch.optim.Adam(net.parameters())\n",
    "#---#\n",
    "for epoc in range(1,31):\n",
    "    #---에폭시작---#\n",
    "    net.train()\n",
    "    for Xm,ym in dl_train:\n",
    "        Xm = Xm.to(\"cuda:0\")\n",
    "        ym = ym.to(\"cuda:0\")\n",
    "        # Step1\n",
    "        netout = net(Xm)\n",
    "        # Step2\n",
    "        loss = loss_fn(netout,ym) \n",
    "        # Step3\n",
    "        loss.backward()\n",
    "        # Step4 \n",
    "        optimizr.step()\n",
    "        optimizr.zero_grad()\n",
    "    #---에폭끝---#\n",
    "    if epoc % 5 ==0:\n",
    "        net.eval()\n",
    "        s = 0 \n",
    "        for Xm,ym in dl_train:\n",
    "            Xm = Xm.to(\"cuda:0\")\n",
    "            ym = ym.to(\"cuda:0\")        \n",
    "            s = s+(net(Xm).data.argmax(axis=1) == ym.argmax(axis=1)).float().sum().item()\n",
    "        acc = s / len(X)\n",
    "        print(f\"# of epochs = {epoc}\\t train_acc = {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "900867a7-1075-445e-a59f-01c03c1a6664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc = 0.8950"
     ]
    }
   ],
   "source": [
    "net.eval()\n",
    "s = 0 \n",
    "for Xm,ym in dl_test:\n",
    "    Xm = Xm.to(\"cuda:0\")\n",
    "    ym = ym.to(\"cuda:0\")        \n",
    "    s = s+(net(Xm).data.argmax(axis=1) == ym.argmax(axis=1)).float().sum().item()\n",
    "acc = s / len(XX)\n",
    "print(f\"test_acc = {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "8ba83ae1-9912-42b4-a8f0-95ffde5f04aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum([torch.tensor(para.shape).prod().item() for para in net.parameters()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcfa6c9a-b478-48a4-8b2c-329b6e455bdb",
   "metadata": {},
   "source": [
    "## F. 합성곱신경망\n",
    "\n",
    "`-` <https://brunch.co.kr/@hvnpoet/109>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "c44cc5f7-dd47-445f-96e8-026ed7e22af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of epochs = 5  train_acc = 0.9204\n",
      "# of epochs = 10     train_acc = 0.9504\n",
      "# of epochs = 15     train_acc = 0.9655\n",
      "# of epochs = 20     train_acc = 0.9789\n",
      "# of epochs = 25     train_acc = 0.9906\n",
      "# of epochs = 30     train_acc = 0.9934"
     ]
    }
   ],
   "source": [
    "net = torch.nn.Sequential(\n",
    "    torch.nn.Conv2d(in_channels=1,out_channels=128,kernel_size=5),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.MaxPool2d(kernel_size=2),\n",
    "    torch.nn.Conv2d(in_channels=128,out_channels=128,kernel_size=5),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.MaxPool2d(kernel_size=2),\n",
    "    torch.nn.Flatten(),\n",
    "    torch.nn.Linear(2048,10),\n",
    ").to(\"cuda:0\")\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizr = torch.optim.Adam(net.parameters())\n",
    "#---#\n",
    "for epoc in range(1,31):\n",
    "    #---에폭시작---#\n",
    "    net.train()\n",
    "    for Xm,ym in dl_train:\n",
    "        Xm = Xm.to(\"cuda:0\")\n",
    "        ym = ym.to(\"cuda:0\")\n",
    "        # Step1\n",
    "        netout = net(Xm)\n",
    "        # Step2\n",
    "        loss = loss_fn(netout,ym) \n",
    "        # Step3\n",
    "        loss.backward()\n",
    "        # Step4 \n",
    "        optimizr.step()\n",
    "        optimizr.zero_grad()\n",
    "    #---에폭끝---#\n",
    "    if epoc % 5 ==0:\n",
    "        net.eval()\n",
    "        s = 0 \n",
    "        for Xm,ym in dl_train:\n",
    "            Xm = Xm.to(\"cuda:0\")\n",
    "            ym = ym.to(\"cuda:0\")        \n",
    "            s = s+(net(Xm).data.argmax(axis=1) == ym.argmax(axis=1)).float().sum().item()\n",
    "        acc = s / len(X)\n",
    "        print(f\"# of epochs = {epoc}\\t train_acc = {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "da2977e7-ad48-4315-9f68-5e45d77e2868",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc = 0.9157"
     ]
    }
   ],
   "source": [
    "net.eval()\n",
    "s = 0 \n",
    "for Xm,ym in dl_test:\n",
    "    Xm = Xm.to(\"cuda:0\")\n",
    "    ym = ym.to(\"cuda:0\")        \n",
    "    s = s+(net(Xm).data.argmax(axis=1) == ym.argmax(axis=1)).float().sum().item()\n",
    "acc = s / len(XX)\n",
    "print(f\"test_acc = {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "540ac31c-52e7-418a-a062-253b0c1befe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum([torch.tensor(para.shape).prod().item() for para in net.parameters()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6e267a-6e3b-4f13-8615-8149823fd963",
   "metadata": {},
   "source": [
    "Xiao, Han, Kashif Rasul, and Roland Vollgraf. 2017. “Fashion-Mnist: A\n",
    "Novel Image Dataset for Benchmarking Machine Learning Algorithms.”\n",
    "*arXiv Preprint arXiv:1708.07747*."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
