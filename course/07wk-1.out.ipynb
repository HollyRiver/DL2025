{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4b943d8-f131-46ca-b4ca-b96ffb46dedf",
   "metadata": {},
   "source": [
    "# 07wk-1: (합성곱신경망) – CNN 자랑, CNN 핵심레이어\n",
    "\n",
    "최규빈  \n",
    "2025-04-16\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/guebin/DL2025/blob/main/posts/06wk-2.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" style=\"text-align: left\"></a>\n",
    "\n",
    "# 1. 강의영상"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854076ca-0234-427b-9a95-147a041cf58f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# {{<video https://youtu.be/playlist?list=PLQqh36zP38-wcPiCEdYML9-6-Xv5RVbso&si=BbNo6mwCHqwOV0FS>}}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee35b083-47a4-4336-b461-c30d2a2ca404",
   "metadata": {},
   "source": [
    "# 2. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "229dfe04-bb02-4a02-81e4-c6fdd9eb2f91",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "758b9fdc-63aa-4526-a12e-42a784516343",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (4.5, 3.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca0f4912-94e1-4c68-ba28-3babd5988718",
   "metadata": {},
   "source": [
    "# 3. CNN 자랑\n",
    "\n",
    "## A. 성능좋음\n",
    "\n",
    "*Fashion MNIST*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "19ffc154-e4b6-4e09-9c32-73110128d4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torchvision.datasets.FashionMNIST(root='./data', train=True, download=True)\n",
    "test_dataset = torchvision.datasets.FashionMNIST(root='./data', train=False, download=True)\n",
    "train_dataset = torch.utils.data.Subset(train_dataset, range(5000))\n",
    "test_dataset = torch.utils.data.Subset(test_dataset, range(1000))\n",
    "to_tensor = torchvision.transforms.ToTensor()\n",
    "X = torch.stack([to_tensor(img) for img, lbl in train_dataset]).to(\"cuda:0\")\n",
    "y = torch.tensor([lbl for img, lbl in train_dataset])\n",
    "y = torch.nn.functional.one_hot(y).float().to(\"cuda:0\")\n",
    "XX = torch.stack([to_tensor(img) for img, lbl in test_dataset]).to(\"cuda:0\")\n",
    "yy = torch.tensor([lbl for img, lbl in test_dataset])\n",
    "yy = torch.nn.functional.one_hot(yy).float().to(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e041353-f347-4bbc-b8b0-92d3ecb47dca",
   "metadata": {},
   "source": [
    "*발악수준으로 설계한 신경망*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f5290e2d-e9d9-4641-92fd-7e6df5b68ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = torch.nn.Sequential(\n",
    "    torch.nn.Flatten(),\n",
    "    torch.nn.Linear(784,2048),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(2048,10)\n",
    ").to(\"cuda\")\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizr = torch.optim.Adam(net.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "963b8ded-f1e7-48be-8975-3ba38bfac4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoc in range(1,500):\n",
    "    #1\n",
    "    logits = net(X)\n",
    "    #2\n",
    "    loss = loss_fn(logits, y) \n",
    "    #3\n",
    "    loss.backward()\n",
    "    #4 \n",
    "    optimizr.step()\n",
    "    optimizr.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0972367a-51bb-47c6-8ee3-cd177c968dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "(net(X).argmax(axis=1) == y.argmax(axis=1)).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b95f70ad-2b90-4ecb-9610-90a91c862c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "(net(XX).argmax(axis=1) == yy.argmax(axis=1)).float().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d5d470e-69fa-4cd5-bb7f-326ad626fbc0",
   "metadata": {},
   "source": [
    "*대충대충 설계한 합성곱신경망*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "70a00a09-6d44-43de-9395-f68d7ca25b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = torch.nn.Sequential(\n",
    "    torch.nn.Conv2d(1,16,2),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.MaxPool2d(2),\n",
    "    torch.nn.Flatten(),\n",
    "    torch.nn.Linear(2704,10),\n",
    ").to(\"cuda\")\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizr = torch.optim.Adam(net.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b7b598c9-e55b-4d88-a2a9-1974d20f0906",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoc in range(1,500):\n",
    "    #1\n",
    "    logits = net(X)\n",
    "    #2\n",
    "    loss = loss_fn(logits, y) \n",
    "    #3\n",
    "    loss.backward()\n",
    "    #4 \n",
    "    optimizr.step()\n",
    "    optimizr.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "84e56cf1-abf9-49f8-82cf-2cd9e739c7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "(net(X).argmax(axis=1) == y.argmax(axis=1)).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1ca554ed-6556-4c13-bf7b-0de533ceb487",
   "metadata": {},
   "outputs": [],
   "source": [
    "(net(XX).argmax(axis=1) == yy.argmax(axis=1)).float().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e5326e5-2541-4b48-ad87-6fd2573cfdcb",
   "metadata": {},
   "source": [
    "## B. 파라메터적음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f7ea0eee-5dff-4d54-a05b-1b9681d6aeb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "net1 = torch.nn.Sequential(\n",
    "    torch.nn.Flatten(),\n",
    "    torch.nn.Linear(784,2048),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(2048,10)\n",
    ")\n",
    "net2 = torch.nn.Sequential(\n",
    "    torch.nn.Conv2d(1,16,2),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.MaxPool2d(2),\n",
    "    torch.nn.Flatten(),\n",
    "    torch.nn.Linear(2704,10),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7304bb47-7550-41c5-baae-aa92909d8ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "net1_params = list(net1.parameters())\n",
    "net2_params = list(net2.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "0ef7b74d-bff2-4f7b-8ba9-58178603b674",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2048, 784])\n",
      "torch.Size([2048])\n",
      "torch.Size([10, 2048])\n",
      "torch.Size([10])"
     ]
    }
   ],
   "source": [
    "for params in net1_params:\n",
    "    print(params.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "83ee0d71-65cf-4e41-95c2-26592e2c5b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "2048*784 + 2048 + 10*2048 + 10 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "3fd0625a-44ca-4a30-9316-dc3cc6c1d85f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 1, 2, 2])\n",
      "torch.Size([16])\n",
      "torch.Size([10, 2704])\n",
      "torch.Size([10])"
     ]
    }
   ],
   "source": [
    "for params in net2_params:\n",
    "    print(params.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "54d4ed1d-50dc-418a-9f02-c0759855f566",
   "metadata": {},
   "outputs": [],
   "source": [
    "16*1*2*2 + 16 + 10*2704 + 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a331f506-68f2-448f-ae44-d1da776a05a7",
   "metadata": {},
   "source": [
    "## C. 유명함\n",
    "\n",
    "`-` <https://brunch.co.kr/@hvnpoet/109>\n",
    "\n",
    "# 4. CNN 핵심레이어\n",
    "\n",
    "## A. `torch.nn.ReLU`\n",
    "\n",
    "**(예시1) 연산방법**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "ddfe4d3f-d4d8-4c34-ac5c-8de819f3ae93",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = torch.randn(1,1,5,5) # 흑백이미지한장\n",
    "relu = torch.nn.ReLU()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "40beef3a-f5f7-494d-b34d-f6b5a33d45e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "img # - 값도 있지만 이미지라고 생각하자.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "4fd92056-55e6-4f61-96a7-722d890c7ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "relu(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa05a0d4-cbc9-4969-bf7e-0078b759aab0",
   "metadata": {},
   "source": [
    "## B. `torch.nn.MaxPool2d`\n",
    "\n",
    "**(예시1) 연산방법, kernel_size 의 의미**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "c4c00350-ee51-4c86-bbdf-fcbf8c66daff",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = torch.rand(1,1,4,4) # 흑백이미지한장\n",
    "mp = torch.nn.MaxPool2d(kernel_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "630dbbd6-da23-4339-bbc2-b9efa8dca8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "1dbbbc48-4ebc-4412-8a92-8bbbd93c7816",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80cbdbd5-899b-405b-ac02-e775ee447e17",
   "metadata": {},
   "source": [
    "**(예시2) 이미지크기와 딱 맞지않는 커널일경우?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "fccb5604-0db5-4948-bd95-51ae23efabd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = torch.rand(1,1,5,5) # 흑백이미지한장\n",
    "mp = torch.nn.MaxPool2d(kernel_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b4cb5fa2-1eac-4158-9258-6cd618d5a9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "cb1776fa-5b7f-46ad-8b01-4b72d0226782",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03189ff7-d1ef-4eec-8936-b4100a38fd64",
   "metadata": {},
   "source": [
    "**(예시3) 정사각형이 아닌 커널**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5a478ae0-dfdd-48d7-8edd-3b36ef845cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = torch.rand(1,1,4,4) # 흑백이미지한장\n",
    "mp = torch.nn.MaxPool2d(kernel_size=(2,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "830cdd06-024c-43cf-b431-10a10a59b568",
   "metadata": {},
   "outputs": [],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c1f17e1c-792a-4166-b066-b60a1dd58740",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c631211c-a036-43a1-a22a-8c3c4874d33a",
   "metadata": {},
   "source": [
    "## C. `torch.nn.Conv2d`\n",
    "\n",
    "**(예시1) 연산방법, stride=2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "e43be7af-c9ee-44d7-adab-5d2586cb251c",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = torch.rand(1,1,4,4) # 흑백이미지한장\n",
    "conv = torch.nn.Conv2d(in_channels=1,out_channels=1,kernel_size=2,stride=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "ee807862-2b35-43c5-9f33-c118adb00375",
   "metadata": {},
   "outputs": [],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "671587db-11c0-43d6-b7c4-436982b66a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee29f399-4004-4df7-a810-4d748f04a6a2",
   "metadata": {},
   "source": [
    "??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "9c4b07ff-2ca2-45ec-ac11-c7f073d1d596",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv.weight, conv.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "f1a9d7be-940f-439c-bcb4-5853d72c50b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "(img[:,  :,  :2,  :2] * conv.weight.data).sum() + conv.bias, conv(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "717081f4-3d98-4dc4-9b98-f29d719d4a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "(img[:,  :,  :2,  2:] * conv.weight.data).sum() + conv.bias, conv(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "94278a54-352f-4d0c-b0f7-c8454f32f9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "(img[:,  :,  2:,  :2] * conv.weight.data).sum() + conv.bias, conv(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "ec5e5316-05e4-4917-9813-4e318dcf656a",
   "metadata": {},
   "outputs": [],
   "source": [
    "(img[:,  :,  2:,  2:] * conv.weight.data).sum() + conv.bias, conv(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b7ce22-1793-4517-93c0-244ca01c94ca",
   "metadata": {},
   "source": [
    "**(예시2) 이동평균**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "4182d95a-1e60-4f60-aa39-fb5e1100b730",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = torch.arange(1,17).float().reshape(1,1,4,4)\n",
    "conv = torch.nn.Conv2d(in_channels=1,out_channels=1,kernel_size=2,stride=1,bias=False)\n",
    "conv.weight.data = conv.weight.data*0+1/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "a60186b1-74b3-41e8-b4e5-3e0201674d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "76d90240-4e7c-421b-be38-91dcf25d2104",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e374b30d-97d6-424c-9e53-3af00b2cc3e6",
   "metadata": {},
   "source": [
    "**(예시3) 2개의 이미지**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "0cb6c677-8e2a-4f87-8cee-62c6e1ebb4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = torch.arange(1,33).float().reshape(2,1,4,4)\n",
    "conv = torch.nn.Conv2d(in_channels=1,out_channels=1,kernel_size=2,stride=1,bias=False)\n",
    "conv.weight.data = conv.weight.data*0+1/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "6bcb5b4f-d3e5-4eaa-a29a-fdf3e445204d",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "284a2078-6308-49e2-a1f7-7775bb2a44ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv(imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "147c1596-a85a-41b6-91e5-bcf3c15d541a",
   "metadata": {},
   "source": [
    "**(예시4) 2개의 out_channels**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "0037cb52-49e7-4ca9-846d-57c34f1119ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = torch.arange(1,33).float().reshape(2,1,4,4)\n",
    "conv = torch.nn.Conv2d(in_channels=1,out_channels=2,kernel_size=2,stride=1,bias=False)\n",
    "conv.weight.data[0] = conv.weight.data[0]*0 + 1/4\n",
    "conv.weight.data[1] = conv.weight.data[1]*0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "50ad8b5e-dee2-4d2c-9891-98d1fbb7bc0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "0b929a67-732e-45cc-b7e0-baacf44aceec",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv(img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
