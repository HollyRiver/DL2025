{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 06wk-2: (신경망, 합성곱신경망) – 다항분류, 합성곱신경망\n",
        "\n",
        "최규빈  \n",
        "2025-04-14\n",
        "\n",
        "<a href=\"https://colab.research.google.com/github/guebin/DL2025/blob/main/posts/06wk-2.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" style=\"text-align: left\"></a>\n",
        "\n",
        "# 1. 강의영상"
      ],
      "id": "be8526d6-58dc-45f8-b26b-c5873f8f618b"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "# {{<video https://youtu.be/playlist?list=PLQqh36zP38-yx6DQsLACqw8pWm0udv8Jm&si=in1eMD0-wU49y7mS >}}"
      ],
      "id": "ecdca12a-79f7-4e58-b76b-fe6d70131060"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 2. Imports"
      ],
      "id": "220e1493-c9cd-47dc-b3ee-e7104915f9a6"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt"
      ],
      "id": "c997af13-4f2b-45b9-967b-41e6f7d5725f"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.rcParams['figure.figsize'] = (4.5, 3.0)"
      ],
      "id": "2c6c8254-c4a2-468f-a77b-10cf791b1bfa"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 3. 다항분류\n",
        "\n",
        "## A. 이항분류와 `BCEWithLogitsLoss`\n",
        "\n",
        "`-` 데이터"
      ],
      "id": "e784abe2-dd6f-4a0c-acf5-5f238ec9272a"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True)\n",
        "to_tensor = torchvision.transforms.ToTensor()\n",
        "X0_train = torch.stack([to_tensor(Xi) for Xi, yi in train_dataset if yi==0])\n",
        "X1_train = torch.stack([to_tensor(Xi) for Xi, yi in train_dataset if yi==1])\n",
        "X = torch.concat([X0_train,X1_train],axis=0).reshape(-1,784)\n",
        "y = torch.tensor([0.0]*len(X0_train) + [1.0]*len(X1_train)).reshape(-1,1)"
      ],
      "id": "9cdc473d-e5f4-4f7d-9763-76c7b712d469"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`-` 예전코드는 아래와 같음 (sig는 수동처리함)"
      ],
      "id": "d1779c72-a113-4b23-93fd-6505a03e8c51"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch = 1    acc = 0.4677\n",
            "epoch = 2    acc = 0.4677\n",
            "epoch = 3    acc = 0.4745\n",
            "epoch = 4    acc = 0.5572\n",
            "epoch = 5    acc = 0.6995\n",
            "epoch = 6    acc = 0.8175\n",
            "epoch = 7    acc = 0.8904\n",
            "epoch = 8    acc = 0.9255\n",
            "epoch = 9    acc = 0.9444\n",
            "epoch = 10   acc = 0.9577"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(0)\n",
        "net = torch.nn.Sequential(\n",
        "    torch.nn.Linear(784,32),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Linear(32,1)\n",
        ")\n",
        "loss_fn = torch.nn.BCELoss()\n",
        "optimizr = torch.optim.Adam(net.parameters())\n",
        "#---#\n",
        "for epoc in range(1,11):\n",
        "    # step1 \n",
        "    netout = net(X) # netout = logits \n",
        "    yhat = torch.exp(netout) / (1 + torch.exp(netout)) # yhat = prob \n",
        "    # step2\n",
        "    loss = loss_fn(yhat,y) \n",
        "    # step3     \n",
        "    loss.backward()\n",
        "    # step4 \n",
        "    optimizr.step()\n",
        "    optimizr.zero_grad()\n",
        "    #---에폭끝나고 확인할 것들---#\n",
        "    acc = ((net(X).data > 0)  == y).float().mean()\n",
        "    print(f\"epoch = {epoc}\\t acc = {acc:.4f}\")"
      ],
      "id": "9eb437e4-8139-4202-8167-7e14016b62bb"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`#` netout(= logits) 의 특징\n",
        "\n",
        "-   $netout > 0 \\Leftrightarrow sig(netout) >0.5$\n",
        "-   $netout < 0 \\Leftrightarrow sig(netout) <0.5$\n",
        "\n",
        "`-` 그런데 위의 코드는 아래의 코드와 같음"
      ],
      "id": "9b00a64e-bf38-4a81-b473-b4d7d80774c9"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch = 1    acc = 0.4677\n",
            "epoch = 2    acc = 0.4677\n",
            "epoch = 3    acc = 0.4745\n",
            "epoch = 4    acc = 0.5572\n",
            "epoch = 5    acc = 0.6995\n",
            "epoch = 6    acc = 0.8175\n",
            "epoch = 7    acc = 0.8904\n",
            "epoch = 8    acc = 0.9255\n",
            "epoch = 9    acc = 0.9444\n",
            "epoch = 10   acc = 0.9577"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(0)\n",
        "net = torch.nn.Sequential(\n",
        "    torch.nn.Linear(784,32),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Linear(32,1)\n",
        ")\n",
        "loss_fn = torch.nn.BCEWithLogitsLoss() # <--- 여기를 바꾸고 \n",
        "optimizr = torch.optim.Adam(net.parameters())\n",
        "#---#\n",
        "for epoc in range(1,11):\n",
        "    # step1 \n",
        "    netout = net(X) # netout = logits \n",
        "    # yhat = torch.exp(netout) / (1 + torch.exp(netout))  # yhat = prob  # <-- 여기는주석처리\n",
        "    # step2\n",
        "    loss = loss_fn(netout,y) \n",
        "    # step3     \n",
        "    loss.backward()\n",
        "    # step4 \n",
        "    optimizr.step()\n",
        "    optimizr.zero_grad()\n",
        "    #---에폭끝나고 확인할 것들---#\n",
        "    acc = ((net(X).data > 0)  == y).float().mean()\n",
        "    print(f\"epoch = {epoc}\\t acc = {acc:.4f}\")"
      ],
      "id": "8d9b3fe1-4d8a-460c-901b-5ac88bd6b8b1"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## B. 범주형자료의 변환\n",
        "\n",
        "`-` 범주형자료를 숫자로 어떻게 바꿀까?\n",
        "\n",
        "-   실패 / 성공 $\\to$ 0 / 1\n",
        "-   숫자0그림 / 숫자1그림 $\\to$ 0 / 1\n",
        "-   강아지그림 / 고양이그림 $\\to$ 0 / 1\n",
        "-   강아지그림 / 고양이그림 / 토끼그림 $\\to$ 0 / 1 / 2 ?????\n",
        "\n",
        "`-` 주입식교육: 강아지그림/고양이그림/토끼그림일 경우 숫자화시키는 방법\n",
        "\n",
        "-   잘못된방식: 강아지그림 = 0, 고양이그림 = 1, 토끼그림 = 2\n",
        "-   올바른방식: 강아지그림 = \\[1,0,0\\], 고양이그림 = \\[0,1,0\\], 토끼그림\n",
        "    = \\[0,0,1\\] \\### \\<– 이런방식을 원핫인코딩이라함\n",
        "\n",
        "`-` 왜?\n",
        "\n",
        "-   설명1: 강아지그림, 고양이그림, 토끼그림은 서열측도가 아니라\n",
        "    명목척도임. 그래서 범주를 0,1,2 로 숫자화하면 평균등의 의미가 없음\n",
        "    (사회조사분석사 2급 스타일)\n",
        "-   설명2: 범주형은 원핫인코딩으로 해야함 (“30일만에 끝내는\n",
        "    실전머신러닝” 이런 책에 나오는 스타일)\n",
        "-   설명3: 동전을 한번 던져서 나오는 결과는 $n=1$인 이항분포를 따름.\n",
        "    주사위 한번 던져서 나오는 눈금의 숫자는 $n=1$인 다항분포를 따름.\n",
        "    $n=1$인 이항분포의 실현값은 0,1 이고, $n=1$인 다항분포의 실현값은\n",
        "    \\[1,0,0\\], \\[0,1,0\\], \\[0,0,1\\] 이므로 당연히 $y_i$ 는 \\[1,0,0\\],\n",
        "    \\[0,1,0\\], \\[0,0,1\\] 중 하나의 형태를 가진다고 가정하는게 바람직함\n",
        "    (이 설명이 이 중에서 가장 정확한 설명임)\n",
        "\n",
        "## C. 실습: 3개의 클래스를 구분\n",
        "\n",
        "`-` 데이터준비"
      ],
      "id": "ec40b33d-8347-4417-9429-7338c255676d"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True)\n",
        "to_tensor = torchvision.transforms.ToTensor()\n",
        "X0 = torch.stack([to_tensor(Xi) for Xi, yi in train_dataset if yi==0])\n",
        "X1 = torch.stack([to_tensor(Xi) for Xi, yi in train_dataset if yi==1])\n",
        "X2 = torch.stack([to_tensor(Xi) for Xi, yi in train_dataset if yi==2])\n",
        "X = torch.concat([X0,X1,X2]).reshape(-1,1*28*28)\n",
        "y = torch.tensor([0]*len(X0) + [1]*len(X1)+ [2]*len(X2)).reshape(-1,1).float()"
      ],
      "id": "a7ec1bd3-9954-4ade-93cc-d9c6880e365f"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "y = torch.nn.functional.one_hot(y.flatten().long()).float()"
      ],
      "id": "c42b928a-7125-482f-b898-c65f36a389c2"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`-` 적합"
      ],
      "id": "efea239e-0111-4580-bb08-ac6d8ca4c06c"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.manual_seed(43052)\n",
        "net = torch.nn.Sequential(\n",
        "    torch.nn.Linear(784,32),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Linear(32,3),\n",
        ")\n",
        "loss_fn = torch.nn.CrossEntropyLoss() # 이름이 좀 그래.. 나같으면 CEWithLogitsLoss 라고 했을듯 \n",
        "optimizr = torch.optim.Adam(net.parameters())\n",
        "#---#\n",
        "for epoc in range(100):\n",
        "    ## step1 \n",
        "    netout = net(X)\n",
        "    ## step2 \n",
        "    loss = loss_fn(netout,y)\n",
        "    ## step3 \n",
        "    loss.backward()\n",
        "    ## step4 \n",
        "    optimizr.step()\n",
        "    optimizr.zero_grad()"
      ],
      "id": "fba6e0ab-6d10-4ca3-bc6a-00f0777eb303"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "(net(X).argmax(axis=1)  == y.argmax(axis=1)).float().mean()"
      ],
      "id": "c9960353-82f1-46d6-afab-0c6df59ebb60"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## D. 결론 – 외우세여\n",
        "\n",
        "`-` 파이토치버전 // 코딩용\n",
        "\n",
        "|   분류   | netout의 의미 |      손실함수       |\n",
        "|:--------:|:-------------:|:-------------------:|\n",
        "| 이항분류 |     prob      |      `BCELoss`      |\n",
        "| 이항분류 |     logit     | `BCEWithLogitsLoss` |\n",
        "| 다항분류 |     probs     |         NA          |\n",
        "| 다항분류 |    logits     | `CrossEntropyLoss`  |\n",
        "\n",
        "> `CrossEntropyLoss` 이거 이름이 완전 마음에 안들어요..\n",
        "> `CEWithLogitsLoss` 라고 하는게 더 좋을 것 같습니다.\n",
        "\n",
        "`-` 일반적개념 // 이론용\n",
        "\n",
        "|   분류   | 오차항의가정 | 마지막활성화함수 |       손실함수       |\n",
        "|:--------:|:------------:|:----------------:|:--------------------:|\n",
        "| 이항분류 |   이항분포   |    sigmoid[1]    | Binary Cross Entropy |\n",
        "| 다항분류 |   다항분포   |    softmax[2]    |    Cross Entropy     |\n",
        "\n",
        "# 4. FashionMNIST\n",
        "\n",
        "## A. 데이터\n",
        "\n",
        "<https://arxiv.org/abs/1708.07747> (Xiao, Rasul, and Vollgraf 2017)\n",
        "\n",
        "[1] prob=sig(logit)\n",
        "\n",
        "[2] probs=soft(logits)"
      ],
      "id": "d4d53a51-d852-491b-a163-9b6b5c706310"
    },
    {
      "cell_type": "code",
      "execution_count": 281,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_dataset = torchvision.datasets.FashionMNIST(root='./data', train=True, download=True)\n",
        "test_dataset = torchvision.datasets.FashionMNIST(root='./data', train=False, download=True)\n",
        "to_tensor = torchvision.transforms.ToTensor()\n",
        "X = torch.stack([to_tensor(img) for img, lbl in train_dataset])\n",
        "y = torch.tensor([lbl for img, lbl in train_dataset])\n",
        "y = torch.nn.functional.one_hot(y).float()\n",
        "XX = torch.stack([to_tensor(img) for img, lbl in test_dataset])\n",
        "yy = torch.tensor([lbl for img, lbl in test_dataset])\n",
        "yy = torch.nn.functional.one_hot(yy).float()"
      ],
      "id": "42a7ef81-8f3d-42b8-9e18-c21ee42b621e"
    },
    {
      "cell_type": "code",
      "execution_count": 282,
      "metadata": {},
      "outputs": [],
      "source": [
        "ds_train = torch.utils.data.TensorDataset(X,y)\n",
        "dl_train = torch.utils.data.DataLoader(ds_train,batch_size=256,shuffle=True)\n",
        "ds_test = torch.utils.data.TensorDataset(XX,yy)\n",
        "dl_test = torch.utils.data.DataLoader(ds_test,batch_size=256)"
      ],
      "id": "ef3d9f39-d791-4f48-b948-67d28f4e0cc6"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## B. 간단한 신경망"
      ],
      "id": "f6de3365-cb17-422c-8487-1a9fe2c3c51b"
    },
    {
      "cell_type": "code",
      "execution_count": 257,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# of epochs = 5  train_acc = 0.8588\n",
            "# of epochs = 10     train_acc = 0.8659\n",
            "# of epochs = 15     train_acc = 0.8779\n",
            "# of epochs = 20     train_acc = 0.8830\n",
            "# of epochs = 25     train_acc = 0.8857\n",
            "# of epochs = 30     train_acc = 0.8875"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(43052)\n",
        "net = torch.nn.Sequential(\n",
        "    torch.nn.Flatten(),\n",
        "    torch.nn.Linear(784,32),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Linear(32,10)\n",
        ").to(\"cuda:0\")\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "optimizr = torch.optim.Adam(net.parameters())\n",
        "#---#\n",
        "for epoc in range(1,31):\n",
        "    #---에폭시작---#\n",
        "    net.train()\n",
        "    for Xm,ym in dl_train:\n",
        "        Xm = Xm.to(\"cuda:0\")\n",
        "        ym = ym.to(\"cuda:0\")\n",
        "        # Step1\n",
        "        netout = net(Xm)\n",
        "        # Step2\n",
        "        loss = loss_fn(netout,ym) \n",
        "        # Step3\n",
        "        loss.backward()\n",
        "        # Step4 \n",
        "        optimizr.step()\n",
        "        optimizr.zero_grad()\n",
        "    #---에폭끝---#\n",
        "    if epoc % 5 ==0:\n",
        "        net.eval()\n",
        "        s = 0 \n",
        "        for Xm,ym in dl_train:\n",
        "            Xm = Xm.to(\"cuda:0\")\n",
        "            ym = ym.to(\"cuda:0\")        \n",
        "            s = s+(net(Xm).data.argmax(axis=1) == ym.argmax(axis=1)).float().sum().item()\n",
        "        acc = s / len(X)\n",
        "        print(f\"# of epochs = {epoc}\\t train_acc = {acc:.4f}\")"
      ],
      "id": "0794311c-fbf5-408f-9bdf-ba4cb46a7e86"
    },
    {
      "cell_type": "code",
      "execution_count": 260,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test_acc = 0.8639"
          ]
        }
      ],
      "source": [
        "net.eval()\n",
        "s = 0 \n",
        "for Xm,ym in dl_test:\n",
        "    Xm = Xm.to(\"cuda:0\")\n",
        "    ym = ym.to(\"cuda:0\")        \n",
        "    s = s+(net(Xm).data.argmax(axis=1) == ym.argmax(axis=1)).float().sum().item()\n",
        "acc = s / len(XX)\n",
        "print(f\"test_acc = {acc:.4f}\")"
      ],
      "id": "90c9d25c-d1ce-4055-9dc0-b93344acb7aa"
    },
    {
      "cell_type": "code",
      "execution_count": 261,
      "metadata": {},
      "outputs": [],
      "source": [
        "sum([torch.tensor(para.shape).prod().item() for para in net.parameters()])"
      ],
      "id": "71b240e2-9475-49c3-aca0-ae81501a5131"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## C. 복잡한 신경망"
      ],
      "id": "1bbeb9ad-434e-4fba-b3f5-77dfe48b8924"
    },
    {
      "cell_type": "code",
      "execution_count": 262,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# of epochs = 5  train_acc = 0.8831\n",
            "# of epochs = 10     train_acc = 0.9028\n",
            "# of epochs = 15     train_acc = 0.9183\n",
            "# of epochs = 20     train_acc = 0.9281\n",
            "# of epochs = 25     train_acc = 0.9331\n",
            "# of epochs = 30     train_acc = 0.9332"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(43052)\n",
        "net = torch.nn.Sequential(\n",
        "    torch.nn.Flatten(),\n",
        "    torch.nn.Linear(784,256),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Linear(256,10)\n",
        ").to(\"cuda:0\")\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "optimizr = torch.optim.Adam(net.parameters())\n",
        "#---#\n",
        "for epoc in range(1,31):\n",
        "    #---에폭시작---#\n",
        "    net.train()\n",
        "    for Xm,ym in dl_train:\n",
        "        Xm = Xm.to(\"cuda:0\")\n",
        "        ym = ym.to(\"cuda:0\")\n",
        "        # Step1\n",
        "        netout = net(Xm)\n",
        "        # Step2\n",
        "        loss = loss_fn(netout,ym) \n",
        "        # Step3\n",
        "        loss.backward()\n",
        "        # Step4 \n",
        "        optimizr.step()\n",
        "        optimizr.zero_grad()\n",
        "    #---에폭끝---#\n",
        "    if epoc % 5 ==0:\n",
        "        net.eval()\n",
        "        s = 0 \n",
        "        for Xm,ym in dl_train:\n",
        "            Xm = Xm.to(\"cuda:0\")\n",
        "            ym = ym.to(\"cuda:0\")        \n",
        "            s = s+(net(Xm).data.argmax(axis=1) == ym.argmax(axis=1)).float().sum().item()\n",
        "        acc = s / len(X)\n",
        "        print(f\"# of epochs = {epoc}\\t train_acc = {acc:.4f}\")"
      ],
      "id": "f4b7e313-0663-45aa-bfa9-78ff46fc1ea5"
    },
    {
      "cell_type": "code",
      "execution_count": 263,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test_acc = 0.8833"
          ]
        }
      ],
      "source": [
        "net.eval()\n",
        "s = 0 \n",
        "for Xm,ym in dl_test:\n",
        "    Xm = Xm.to(\"cuda:0\")\n",
        "    ym = ym.to(\"cuda:0\")        \n",
        "    s = s+(net(Xm).data.argmax(axis=1) == ym.argmax(axis=1)).float().sum().item()\n",
        "acc = s / len(XX)\n",
        "print(f\"test_acc = {acc:.4f}\")"
      ],
      "id": "97f9da7a-077d-445b-8191-2d359258a0a0"
    },
    {
      "cell_type": "code",
      "execution_count": 264,
      "metadata": {},
      "outputs": [],
      "source": [
        "sum([torch.tensor(para.shape).prod().item() for para in net.parameters()])"
      ],
      "id": "69abc9c3-8377-4ec2-9101-fff8c3f8e8e5"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## D. 발악해보세요\n",
        "\n",
        "`-` 아주 넓게.."
      ],
      "id": "bc077898-7463-4412-be61-eb06be625826"
    },
    {
      "cell_type": "code",
      "execution_count": 265,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# of epochs = 5  train_acc = 0.8885\n",
            "# of epochs = 10     train_acc = 0.8977\n",
            "# of epochs = 15     train_acc = 0.9130\n",
            "# of epochs = 20     train_acc = 0.9232\n",
            "# of epochs = 25     train_acc = 0.9318\n",
            "# of epochs = 30     train_acc = 0.9308"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(43052)\n",
        "net = torch.nn.Sequential(\n",
        "    torch.nn.Flatten(),\n",
        "    torch.nn.Linear(784,4096),\n",
        "    torch.nn.Dropout(0.5),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Linear(4096,10),\n",
        ").to(\"cuda:0\")\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "optimizr = torch.optim.Adam(net.parameters())\n",
        "#---#\n",
        "for epoc in range(1,31):\n",
        "    #---에폭시작---#\n",
        "    net.train()\n",
        "    for Xm,ym in dl_train:\n",
        "        Xm = Xm.to(\"cuda:0\")\n",
        "        ym = ym.to(\"cuda:0\")\n",
        "        # Step1\n",
        "        netout = net(Xm)\n",
        "        # Step2\n",
        "        loss = loss_fn(netout,ym) \n",
        "        # Step3\n",
        "        loss.backward()\n",
        "        # Step4 \n",
        "        optimizr.step()\n",
        "        optimizr.zero_grad()\n",
        "    #---에폭끝---#\n",
        "    if epoc % 5 ==0:\n",
        "        net.eval()\n",
        "        s = 0 \n",
        "        for Xm,ym in dl_train:\n",
        "            Xm = Xm.to(\"cuda:0\")\n",
        "            ym = ym.to(\"cuda:0\")        \n",
        "            s = s+(net(Xm).data.argmax(axis=1) == ym.argmax(axis=1)).float().sum().item()\n",
        "        acc = s / len(X)\n",
        "        print(f\"# of epochs = {epoc}\\t train_acc = {acc:.4f}\")"
      ],
      "id": "ab841133-6e67-4e60-9e8d-b72f1c6b815a"
    },
    {
      "cell_type": "code",
      "execution_count": 266,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test_acc = 0.8934"
          ]
        }
      ],
      "source": [
        "net.eval()\n",
        "s = 0 \n",
        "for Xm,ym in dl_test:\n",
        "    Xm = Xm.to(\"cuda:0\")\n",
        "    ym = ym.to(\"cuda:0\")        \n",
        "    s = s+(net(Xm).data.argmax(axis=1) == ym.argmax(axis=1)).float().sum().item()\n",
        "acc = s / len(XX)\n",
        "print(f\"test_acc = {acc:.4f}\")"
      ],
      "id": "0ea817a7-f0ea-4366-ad89-518a6b056aa0"
    },
    {
      "cell_type": "code",
      "execution_count": 267,
      "metadata": {},
      "outputs": [],
      "source": [
        "sum([torch.tensor(para.shape).prod().item() for para in net.parameters()])"
      ],
      "id": "4338b8de-d410-48a8-af1f-6f36e08ea28d"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`-` 아주 깊게.."
      ],
      "id": "e092b156-85d7-4c8f-b9a0-0b0de5944504"
    },
    {
      "cell_type": "code",
      "execution_count": 273,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# of epochs = 5  train_acc = 0.8903\n",
            "# of epochs = 10     train_acc = 0.9157\n",
            "# of epochs = 15     train_acc = 0.9281\n",
            "# of epochs = 20     train_acc = 0.9333\n",
            "# of epochs = 25     train_acc = 0.9424\n",
            "# of epochs = 30     train_acc = 0.9524"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(43052)\n",
        "net = torch.nn.Sequential(\n",
        "    torch.nn.Flatten(),\n",
        "    torch.nn.Linear(784,256),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Linear(256,256),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Linear(256,256),\n",
        "    torch.nn.Dropout(0.5),    \n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Linear(256,256),\n",
        "    torch.nn.Dropout(0.5),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Linear(256,10),\n",
        ").to(\"cuda:0\")\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "optimizr = torch.optim.Adam(net.parameters())\n",
        "#---#\n",
        "for epoc in range(1,31):\n",
        "    #---에폭시작---#\n",
        "    net.train()\n",
        "    for Xm,ym in dl_train:\n",
        "        Xm = Xm.to(\"cuda:0\")\n",
        "        ym = ym.to(\"cuda:0\")\n",
        "        # Step1\n",
        "        netout = net(Xm)\n",
        "        # Step2\n",
        "        loss = loss_fn(netout,ym) \n",
        "        # Step3\n",
        "        loss.backward()\n",
        "        # Step4 \n",
        "        optimizr.step()\n",
        "        optimizr.zero_grad()\n",
        "    #---에폭끝---#\n",
        "    if epoc % 5 ==0:\n",
        "        net.eval()\n",
        "        s = 0 \n",
        "        for Xm,ym in dl_train:\n",
        "            Xm = Xm.to(\"cuda:0\")\n",
        "            ym = ym.to(\"cuda:0\")        \n",
        "            s = s+(net(Xm).data.argmax(axis=1) == ym.argmax(axis=1)).float().sum().item()\n",
        "        acc = s / len(X)\n",
        "        print(f\"# of epochs = {epoc}\\t train_acc = {acc:.4f}\")"
      ],
      "id": "7e141a44-de71-4774-b734-35c81da6c31f"
    },
    {
      "cell_type": "code",
      "execution_count": 274,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test_acc = 0.8950"
          ]
        }
      ],
      "source": [
        "net.eval()\n",
        "s = 0 \n",
        "for Xm,ym in dl_test:\n",
        "    Xm = Xm.to(\"cuda:0\")\n",
        "    ym = ym.to(\"cuda:0\")        \n",
        "    s = s+(net(Xm).data.argmax(axis=1) == ym.argmax(axis=1)).float().sum().item()\n",
        "acc = s / len(XX)\n",
        "print(f\"test_acc = {acc:.4f}\")"
      ],
      "id": "900867a7-1075-445e-a59f-01c03c1a6664"
    },
    {
      "cell_type": "code",
      "execution_count": 275,
      "metadata": {},
      "outputs": [],
      "source": [
        "sum([torch.tensor(para.shape).prod().item() for para in net.parameters()])"
      ],
      "id": "8ba83ae1-9912-42b4-a8f0-95ffde5f04aa"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## F. 합성곱신경망\n",
        "\n",
        "`-` <https://brunch.co.kr/@hvnpoet/109>"
      ],
      "id": "fcfa6c9a-b478-48a4-8b2c-329b6e455bdb"
    },
    {
      "cell_type": "code",
      "execution_count": 277,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# of epochs = 5  train_acc = 0.9204\n",
            "# of epochs = 10     train_acc = 0.9504\n",
            "# of epochs = 15     train_acc = 0.9655\n",
            "# of epochs = 20     train_acc = 0.9789\n",
            "# of epochs = 25     train_acc = 0.9906\n",
            "# of epochs = 30     train_acc = 0.9934"
          ]
        }
      ],
      "source": [
        "net = torch.nn.Sequential(\n",
        "    torch.nn.Conv2d(in_channels=1,out_channels=128,kernel_size=5),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.MaxPool2d(kernel_size=2),\n",
        "    torch.nn.Conv2d(in_channels=128,out_channels=128,kernel_size=5),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.MaxPool2d(kernel_size=2),\n",
        "    torch.nn.Flatten(),\n",
        "    torch.nn.Linear(2048,10),\n",
        ").to(\"cuda:0\")\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "optimizr = torch.optim.Adam(net.parameters())\n",
        "#---#\n",
        "for epoc in range(1,31):\n",
        "    #---에폭시작---#\n",
        "    net.train()\n",
        "    for Xm,ym in dl_train:\n",
        "        Xm = Xm.to(\"cuda:0\")\n",
        "        ym = ym.to(\"cuda:0\")\n",
        "        # Step1\n",
        "        netout = net(Xm)\n",
        "        # Step2\n",
        "        loss = loss_fn(netout,ym) \n",
        "        # Step3\n",
        "        loss.backward()\n",
        "        # Step4 \n",
        "        optimizr.step()\n",
        "        optimizr.zero_grad()\n",
        "    #---에폭끝---#\n",
        "    if epoc % 5 ==0:\n",
        "        net.eval()\n",
        "        s = 0 \n",
        "        for Xm,ym in dl_train:\n",
        "            Xm = Xm.to(\"cuda:0\")\n",
        "            ym = ym.to(\"cuda:0\")        \n",
        "            s = s+(net(Xm).data.argmax(axis=1) == ym.argmax(axis=1)).float().sum().item()\n",
        "        acc = s / len(X)\n",
        "        print(f\"# of epochs = {epoc}\\t train_acc = {acc:.4f}\")"
      ],
      "id": "c44cc5f7-dd47-445f-96e8-026ed7e22af2"
    },
    {
      "cell_type": "code",
      "execution_count": 278,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test_acc = 0.9157"
          ]
        }
      ],
      "source": [
        "net.eval()\n",
        "s = 0 \n",
        "for Xm,ym in dl_test:\n",
        "    Xm = Xm.to(\"cuda:0\")\n",
        "    ym = ym.to(\"cuda:0\")        \n",
        "    s = s+(net(Xm).data.argmax(axis=1) == ym.argmax(axis=1)).float().sum().item()\n",
        "acc = s / len(XX)\n",
        "print(f\"test_acc = {acc:.4f}\")"
      ],
      "id": "da2977e7-ad48-4315-9f68-5e45d77e2868"
    },
    {
      "cell_type": "code",
      "execution_count": 279,
      "metadata": {},
      "outputs": [],
      "source": [
        "sum([torch.tensor(para.shape).prod().item() for para in net.parameters()])"
      ],
      "id": "540ac31c-52e7-418a-a062-253b0c1befe5"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Xiao, Han, Kashif Rasul, and Roland Vollgraf. 2017. “Fashion-Mnist: A\n",
        "Novel Image Dataset for Benchmarking Machine Learning Algorithms.”\n",
        "*arXiv Preprint arXiv:1708.07747*."
      ],
      "id": "ab6e267a-6e3b-4f13-8615-8149823fd963"
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3 (ipykernel)",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "codemirror_mode": {
        "name": "ipython",
        "version": "3"
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.21"
    }
  }
}