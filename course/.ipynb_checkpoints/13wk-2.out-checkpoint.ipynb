{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 13wk-2: (강화학습) – Bandit 환경 설계 및 풀이, 4x4 Grid World 게임설명\n",
        "\n",
        "및 구현\n",
        "\n",
        "최규빈  \n",
        "2025-06-02\n",
        "\n",
        "<a href=\"https://colab.research.google.com/github/guebin/DL2025/blob/main/posts/13wk-2.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" style=\"text-align: left\"></a>\n",
        "\n",
        "# 1. 강의영상"
      ],
      "id": "60f02796-10bb-43d5-9060-afddbd00b4ef"
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "# {{<video https://youtu.be/playlist?list=PLQqh36zP38-zEjn2m8H8hMCHsQK8udE27&si=Sy-lnw4Kq56SRggu >}}"
      ],
      "id": "9c489bd1-72a5-415b-8b4c-1b1aeeb655b4"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 2. Imports"
      ],
      "id": "9859153c-95f4-4fa9-91db-d84a13213430"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "import gymnasium as gym\n",
        "#---#\n",
        "import numpy as np\n",
        "import collections\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.animation import FuncAnimation\n",
        "import IPython"
      ],
      "id": "3857ad14-f8de-4973-ae86-7adb7fd1af6f"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 3. Bandit 환경 설계 및 풀이\n",
        "\n",
        "## A. 대충 개념만 실습"
      ],
      "id": "e9a52191-a1f8-474b-9a62-cf1ea2b7b03e"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "action_space = [0,1] \n",
        "actions_deque = collections.deque(maxlen=500)\n",
        "rewards_deque =  collections.deque(maxlen=500)\n",
        "#---#"
      ],
      "id": "f58ccc61-bdef-4708-aabb-ff427cd89d99"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "for _ in range(10):\n",
        "    action = np.random.choice(action_space)\n",
        "    if action == 1:\n",
        "        reward = 10 \n",
        "    else:\n",
        "        reward = 1\n",
        "    actions_deque.append(action)\n",
        "    rewards_deque.append(reward)"
      ],
      "id": "4d6ab7a7-f7b1-48ef-adf0-072459dec4cf"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "actions_deque"
      ],
      "id": "4908cf64-ea61-4430-a526-5154fbca0b50"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "rewards_deque"
      ],
      "id": "0de137ca-a78b-4522-a56c-d391d0bc37b5"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "actions_numpy = np.array(actions_deque)\n",
        "rewards_numpy = np.array(rewards_deque)"
      ],
      "id": "1cfb5c3a-5c72-42a0-86a0-e48e9ad8f537"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "q0 = rewards_numpy[actions_numpy == 0].mean()\n",
        "q1 = rewards_numpy[actions_numpy == 1].mean()\n",
        "q_table = np.array([q0,q1])\n",
        "q_table"
      ],
      "id": "0fcadb60-bf36-4c5d-8f08-dcf890f26ff6"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "action = q_table.argmax()"
      ],
      "id": "3ba6499e-e137-45b6-8318-9f647c889585"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "for _ in range(5):\n",
        "    action = q_table.argmax()\n",
        "    if action == 1:\n",
        "        reward = 10 \n",
        "    else:\n",
        "        reward = 1\n",
        "    actions_deque.append(action)\n",
        "    rewards_deque.append(reward)\n",
        "    actions_numpy = np.array(actions_deque)\n",
        "    rewards_numpy = np.array(rewards_deque)    \n",
        "    q0 = rewards_numpy[actions_numpy == 0].mean()\n",
        "    q1 = rewards_numpy[actions_numpy == 1].mean()\n",
        "    q_table = np.array([q0,q1])"
      ],
      "id": "0ca81468-2ff7-454a-9fd9-c90abcfb30ed"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "actions_numpy"
      ],
      "id": "32e2d548-1c32-4aa2-b201-ac7b3ac6f9bd"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "rewards_numpy"
      ],
      "id": "6322c32b-dda3-4f74-bfc4-3f938eb78aa3"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## B. 클래스를 이용한 구현"
      ],
      "id": "b07ab74a-8bf1-43fc-a02a-8afcc6497afc"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Bandit:\n",
        "    def __init__(self):\n",
        "        self.reward = None \n",
        "    def step(self,action):\n",
        "        if action == 0:\n",
        "            self.reward = 1\n",
        "        else: \n",
        "            self.reward = 10 \n",
        "        return self.reward "
      ],
      "id": "ecadad99-7cb3-468f-9fd1-f7a1c90d6198"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Agent:\n",
        "    def __init__(self):\n",
        "        pass \n",
        "    def act(self):\n",
        "        # 만약에 경험이 20보다 작음 --> 랜덤액션 \n",
        "        # 경험이 20보다 크면 --> action = q_tabel.argmax()\n",
        "        pass \n",
        "    def save_experience(self):\n",
        "        # 데이터 저장 \n",
        "        pass \n",
        "    def learn(self):\n",
        "        # q_table 을 업데이트하는 과정 \n",
        "        pass"
      ],
      "id": "ab591669-92e9-40c6-8831-ed5cd9481b33"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "------------------------------------------------------------------------"
      ],
      "id": "563fe0d3-107e-49f3-a47e-7787f9edec7f"
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Agent:\n",
        "    def __init__(self):\n",
        "        self.n_experiences = 0 \n",
        "        self.action_space = [0,1]\n",
        "        self.action = None\n",
        "        self.reward = None \n",
        "        self.q_table = None \n",
        "        self.actions = collections.deque(maxlen=500)\n",
        "        self.rewards = collections.deque(maxlen=500)\n",
        "    def act(self):\n",
        "        if self.n_experiences < 20:\n",
        "            self.action = np.random.choice(self.action_space)\n",
        "        else: \n",
        "            self.action = self.q_table.argmax()\n",
        "        print(f\"버튼{self.action}누름!\")\n",
        "    def save_experience(self):\n",
        "        self.actions.append(self.action)\n",
        "        self.rewards.append(self.reward)\n",
        "        self.n_experiences = self.n_experiences + 1 \n",
        "    def learn(self):\n",
        "        if self.n_experiences < 20:\n",
        "            pass\n",
        "        else: \n",
        "            actions = np.array(self.actions)\n",
        "            rewards = np.array(self.rewards)\n",
        "            q0 = rewards[actions==0].mean()\n",
        "            q1 = rewards[actions==1].mean()\n",
        "            self.q_table = np.array([q0,q1])"
      ],
      "id": "1236cf3a-77d0-4b28-bf06-d756b58394f1"
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [],
      "source": [
        "env = Bandit()\n",
        "player = Agent()"
      ],
      "id": "b6715628-7443-4746-9b5e-6560585386f9"
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "버튼1누름!\n",
            "버튼1누름!\n",
            "버튼0누름!\n",
            "버튼1누름!\n",
            "버튼0누름!\n",
            "버튼1누름!\n",
            "버튼0누름!\n",
            "버튼1누름!\n",
            "버튼0누름!\n",
            "버튼1누름!\n",
            "버튼1누름!\n",
            "버튼1누름!\n",
            "버튼0누름!\n",
            "버튼1누름!\n",
            "버튼1누름!\n",
            "버튼0누름!\n",
            "버튼1누름!\n",
            "버튼1누름!\n",
            "버튼1누름!\n",
            "버튼0누름!\n",
            "버튼1누름!\n",
            "버튼1누름!\n",
            "버튼1누름!\n",
            "버튼1누름!\n",
            "버튼1누름!\n",
            "버튼1누름!\n",
            "버튼1누름!\n",
            "버튼1누름!\n",
            "버튼1누름!\n",
            "버튼1누름!\n",
            "버튼1누름!\n",
            "버튼1누름!\n",
            "버튼1누름!\n",
            "버튼1누름!\n",
            "버튼1누름!\n",
            "버튼1누름!\n",
            "---\n",
            "36번만에 게임클리어"
          ]
        }
      ],
      "source": [
        "for _ in range(50):\n",
        "    # step1 : agent --> env \n",
        "    player.act()\n",
        "    # step2: agnet <-- env \n",
        "    player.reward = env.step(player.action)\n",
        "    # step3: agent: update (save + learn) \n",
        "    player.save_experience() \n",
        "    player.learn()\n",
        "    #----#\n",
        "    if player.n_experiences < 20: \n",
        "        pass \n",
        "    else: \n",
        "        recent_rewards = np.array(player.rewards)[-20:]\n",
        "        if recent_rewards.mean() > 9.5:\n",
        "            print(\"---\")\n",
        "            print(f\"{player.n_experiences}번만에 게임클리어\")\n",
        "            break "
      ],
      "id": "dbd8b650-d610-4cad-90fe-4cbec4e27f90"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 3. 예비학습: `gym.spaces`\n",
        "\n",
        "ref: <https://gymnasium.farama.org/>\n",
        "\n",
        "`-` 예시1"
      ],
      "id": "5f92ef37-c522-4085-9e04-3fa55a16eef1"
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "action_space = gym.spaces.Discrete(4) \n",
        "action_space "
      ],
      "id": "a4659ed6-45f7-4553-9221-050a362f9105"
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "[action_space.sample() for _ in range(5)]"
      ],
      "id": "f1c07638-97b4-42c2-a090-d0c0afc90c05"
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "0 in action_space"
      ],
      "id": "a41cd503-e7e5-4914-a16d-f82a660b7685"
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "4 in action_space"
      ],
      "id": "57bc3c58-2c8f-44b7-9509-98b8c7cda86f"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`-` 예시2"
      ],
      "id": "9c7ee74c-4fa3-45d3-a205-15d7836df3b9"
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "state_space = gym.spaces.MultiDiscrete([4,4])\n",
        "state_space"
      ],
      "id": "a353fb16-f934-4c27-a91d-7d1b80808848"
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "[state_space.sample() for _ in range(5)]"
      ],
      "id": "66d65602-fbc5-4faf-aae9-277b0fe23b2b"
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {},
      "outputs": [],
      "source": [
        "np.array([0,1]) in state_space"
      ],
      "id": "93050a8d-175f-473d-b9b1-78f88d910109"
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "np.array([3,3]) in state_space"
      ],
      "id": "09f27265-17d9-4025-957f-f5a893e4612f"
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "np.array([3,4]) in state_space"
      ],
      "id": "887259ee-582b-4e33-9f03-23af74983c2d"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 4. 4x4 Grid World 게임 설명\n",
        "\n",
        "## A. 게임설명\n",
        "\n",
        "`-` 문제설명: 4x4 그리드월드에서 상하좌우로 움직이는 에이전트가 목표점에\n",
        "도달하도록 하는 게임\n",
        "\n",
        "-   백문이 불여일견:\n",
        "    <https://claude.ai/public/artifacts/76e13820-2b51-4e7e-a514-00190de17c45>\n",
        "    (출처: 클로드)\n",
        "\n",
        "`-` GridWorld에서 사용되는 주요변수\n",
        "\n",
        "1.  **`State`**: 각 격자 셀이 하나의 상태이며, 에이전트는 이러한 상태 중\n",
        "    하나에 있을 수 있음.\n",
        "2.  **`Action`**: 에이전트는 현재상태에서 다음상태로 이동하기 위해\n",
        "    상,하,좌,우 중 하나의 행동을 취할 수 있음.\n",
        "3.  **`Reward`**: 에이전트가 현재상태에서 특정 action을 하면 얻어지는\n",
        "    보상.\n",
        "4.  **`Terminated`**: 하나의 에피소드가 종료되었음을 나타내는 상태.\n",
        "\n",
        "## B. 시각화"
      ],
      "id": "17caa266-e348-4d71-9706-006aa15e866d"
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "def show(states):\n",
        "    fig = plt.Figure()\n",
        "    ax = fig.subplots()\n",
        "    ax.matshow(np.zeros([4,4]), cmap='bwr',alpha=0.0)\n",
        "    sc = ax.scatter(0, 0, color='red', s=500)  \n",
        "    ax.text(0, 0, 'start', ha='center', va='center')\n",
        "    ax.text(3, 3, 'end', ha='center', va='center')\n",
        "    # Adding grid lines to the plot\n",
        "    ax.set_xticks(np.arange(-.5, 4, 1), minor=True)\n",
        "    ax.set_yticks(np.arange(-.5, 4, 1), minor=True)\n",
        "    ax.grid(which='minor', color='black', linestyle='-', linewidth=2)\n",
        "    state_space = gym.spaces.MultiDiscrete([4,4])\n",
        "    def update(t):\n",
        "        if states[t] in state_space:\n",
        "            s1,s2 = states[t]\n",
        "            states[t] = [s2,s1]\n",
        "            sc.set_offsets(states[t])\n",
        "        else:\n",
        "            s1,s2 = states[t]\n",
        "            s1 = s1 + 0.5 if s1 < 0 else (s1 - 0.5 if s1 > 3 else s1)\n",
        "            s2 = s2 + 0.5 if s2 < 0 else (s2 - 0.5 if s2 > 3 else s2)\n",
        "            states[t] = [s2,s1]       \n",
        "            sc.set_offsets(states[t])\n",
        "    ani = FuncAnimation(fig,update,frames=len(states))\n",
        "    display(IPython.display.HTML(ani.to_jshtml()))"
      ],
      "id": "cd24d391-44ae-4d8b-ba8e-fc7ada7e2417"
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "show([[0,0],[1,0],[2,0],[3,0],[4,0]]) # show 사용방법"
      ],
      "id": "63d26411-c40f-4522-8ad0-4510b7b7f1d6"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 5. 4x4 Grid World 환경 구현"
      ],
      "id": "50212999-8bab-40b7-bc3d-098602e7287e"
    },
    {
      "cell_type": "code",
      "execution_count": 208,
      "metadata": {},
      "outputs": [],
      "source": [
        "class GridWorld:\n",
        "    def __init__(self):\n",
        "        self.a2d = {\n",
        "            0: np.array([0,1]), # →\n",
        "            1: np.array([0,-1]), # ←  \n",
        "            2: np.array([1,0]),  # ↓\n",
        "            3: np.array([-1,0])  # ↑\n",
        "        }\n",
        "        self.state = np.array([0,0])\n",
        "        self.state_space = gym.spaces.MultiDiscrete([4,4])\n",
        "        self.terminated = False \n",
        "        self.reward = None \n",
        "    def reset(self):\n",
        "        self.state = np.array([0,0])\n",
        "        self.reward = None \n",
        "        self.terminated = False\n",
        "    def step(self,action):\n",
        "        self.state = self.state + self.a2d[action]\n",
        "        s1,s2 = self.state \n",
        "        if (s1==3) and (s2==3):\n",
        "            self.reward = 100\n",
        "            self.terminated = True \n",
        "        elif self.state in self.state_space:\n",
        "            self.reward = -1 \n",
        "            self.terminated = False\n",
        "        else: \n",
        "            self.reward = -10 \n",
        "            self.terminated = True \n",
        "        print(\n",
        "            f\"action = {action}\\t\"\n",
        "            f\"state = {self.state - self.a2d[action]} -> {self.state}\\t\"\n",
        "            f\"reward = {self.reward}\\t\"\n",
        "            f\"termiated = {self.terminated}\"\n",
        "        )\n",
        "        return self.state, self.reward, self.terminated\n",
        "    def reset(self):\n",
        "        self.terminated = False \n",
        "        self.state = np.array([0,0])\n",
        "        return self.state"
      ],
      "id": "8d3e8992-67e8-422c-81e8-d416f3130aec"
    },
    {
      "cell_type": "code",
      "execution_count": 209,
      "metadata": {},
      "outputs": [],
      "source": [
        "env = GridWorld()"
      ],
      "id": "d15b6bfe-9ab2-4ab2-939b-dab3333921e1"
    },
    {
      "cell_type": "code",
      "execution_count": 210,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "action = 2  state = [0 0] -> [1 0]  reward = -1 termiated = False\n",
            "action = 1  state = [1 0] -> [ 1 -1]    reward = -10    termiated = True\n",
            "action = 3  state = [0 0] -> [-1  0]    reward = -10    termiated = True\n",
            "action = 0  state = [0 0] -> [0 1]  reward = -1 termiated = False\n",
            "action = 2  state = [0 1] -> [1 1]  reward = -1 termiated = False\n",
            "action = 3  state = [1 1] -> [0 1]  reward = -1 termiated = False\n",
            "action = 2  state = [0 1] -> [1 1]  reward = -1 termiated = False\n",
            "action = 1  state = [1 1] -> [1 0]  reward = -1 termiated = False\n",
            "action = 2  state = [1 0] -> [2 0]  reward = -1 termiated = False\n",
            "action = 0  state = [2 0] -> [2 1]  reward = -1 termiated = False"
          ]
        }
      ],
      "source": [
        "for t in range(10):\n",
        "    action = action_space.sample()\n",
        "    env.step(action)\n",
        "    if env.terminated:\n",
        "        env.state = env.reset()"
      ],
      "id": "a9f5b936-676d-4ad9-81dc-9c36dd3cfc58"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 6. “에이전트 $\\Leftrightarrow$ 환경” 상호작용 구현\n",
        "\n",
        "`-` 우리가 구현하고 싶은 기능\n",
        "\n",
        "-   `.act()`: 액션을 결정 –\\> 여기서는 그냥 랜덤액션\n",
        "-   `.save_experience()`: 데이터를 저장 –\\> 여기에 일단 초점을 맞추자\n",
        "-   `.learn()`: 데이터로에서 학습 –\\> 패스"
      ],
      "id": "13baac13-5ba1-43dc-9cf3-acf7b0960c90"
    },
    {
      "cell_type": "code",
      "execution_count": 238,
      "metadata": {},
      "outputs": [],
      "source": [
        "class RandomAgent:\n",
        "    def __init__(self):\n",
        "        self.n_experiences = 0 \n",
        "        self.action_space = gym.spaces.Discrete(4)\n",
        "        #---#\n",
        "        self.state = None \n",
        "        self.action = None\n",
        "        self.reward = None \n",
        "        self.next_state = None \n",
        "        self.termiated = None\n",
        "        #---#\n",
        "        self.states = collections.deque(maxlen=500)\n",
        "        self.actions = collections.deque(maxlen=500)\n",
        "        self.rewards = collections.deque(maxlen=500)\n",
        "        self.next_states = collections.deque(maxlen=500)\n",
        "        self.terminations = collections.deque(maxlen=500)\n",
        "        #---#\n",
        "        #self.q_table = None \n",
        "    def act(self):\n",
        "        self.action = self.action_space.sample()\n",
        "    def save_experience(self):\n",
        "        self.states.append(self.state)\n",
        "        self.actions.append(self.action)        \n",
        "        self.rewards.append(self.reward)\n",
        "        self.next_states.append(self.next_state)\n",
        "        self.terminations.append(self.termiated)\n",
        "        self.n_experiences = self.n_experiences + 1 \n",
        "    def learn(self):\n",
        "        pass"
      ],
      "id": "0a30dc5e-e602-44fe-b884-29fa7ae6a430"
    },
    {
      "cell_type": "code",
      "execution_count": 244,
      "metadata": {},
      "outputs": [],
      "source": [
        "player = RandomAgent()\n",
        "env = GridWorld()"
      ],
      "id": "f91c3cdf-f134-427a-b341-599e5bba1f8d"
    },
    {
      "cell_type": "code",
      "execution_count": 307,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "action = 2  state = [0 0] -> [1 0]  reward = -1 termiated = False\n",
            "action = 1  state = [1 0] -> [ 1 -1]    reward = -10    termiated = True"
          ]
        }
      ],
      "source": [
        "for _ in range(50):\n",
        "    # step1 : agent --> env \n",
        "    player.act()\n",
        "    # step2: agnet <-- env \n",
        "    player.next_state, player.reward, player.terminated = env.step(player.action)\n",
        "    # step3: agent: update (save + learn) \n",
        "    player.save_experience() \n",
        "    player.learn()\n",
        "    # step4: prepare next iterations \n",
        "    player.state = player.next_state\n",
        "    if env.terminated:\n",
        "        player.state = env.reset()\n",
        "        break"
      ],
      "id": "0b565c60-b029-427e-9c63-2c7e3c2e1b57"
    },
    {
      "cell_type": "code",
      "execution_count": 315,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "action = 3  state = [0 0] -> [-1  0]    reward = -10    termiated = True\n",
            "---에피소드1종료---\n",
            "action = 2  state = [0 0] -> [1 0]  reward = -1 termiated = False\n",
            "action = 0  state = [1 0] -> [1 1]  reward = -1 termiated = False\n",
            "action = 1  state = [1 1] -> [1 0]  reward = -1 termiated = False\n",
            "action = 1  state = [1 0] -> [ 1 -1]    reward = -10    termiated = True\n",
            "---에피소드2종료---\n",
            "action = 3  state = [0 0] -> [-1  0]    reward = -10    termiated = True\n",
            "---에피소드3종료---\n",
            "action = 3  state = [0 0] -> [-1  0]    reward = -10    termiated = True\n",
            "---에피소드4종료---\n",
            "action = 2  state = [0 0] -> [1 0]  reward = -1 termiated = False\n",
            "action = 1  state = [1 0] -> [ 1 -1]    reward = -10    termiated = True\n",
            "---에피소드5종료---\n",
            "action = 3  state = [0 0] -> [-1  0]    reward = -10    termiated = True\n",
            "---에피소드6종료---\n",
            "action = 1  state = [0 0] -> [ 0 -1]    reward = -10    termiated = True\n",
            "---에피소드7종료---\n",
            "action = 0  state = [0 0] -> [0 1]  reward = -1 termiated = False\n",
            "action = 1  state = [0 1] -> [0 0]  reward = -1 termiated = False\n",
            "action = 0  state = [0 0] -> [0 1]  reward = -1 termiated = False\n",
            "action = 2  state = [0 1] -> [1 1]  reward = -1 termiated = False\n",
            "action = 3  state = [1 1] -> [0 1]  reward = -1 termiated = False\n",
            "action = 2  state = [0 1] -> [1 1]  reward = -1 termiated = False\n",
            "action = 1  state = [1 1] -> [1 0]  reward = -1 termiated = False\n",
            "action = 2  state = [1 0] -> [2 0]  reward = -1 termiated = False\n",
            "action = 1  state = [2 0] -> [ 2 -1]    reward = -10    termiated = True\n",
            "---에피소드8종료---\n",
            "action = 1  state = [0 0] -> [ 0 -1]    reward = -10    termiated = True\n",
            "---에피소드9종료---\n",
            "action = 0  state = [0 0] -> [0 1]  reward = -1 termiated = False\n",
            "action = 0  state = [0 1] -> [0 2]  reward = -1 termiated = False\n",
            "action = 3  state = [0 2] -> [-1  2]    reward = -10    termiated = True\n",
            "---에피소드10종료---\n",
            "action = 0  state = [0 0] -> [0 1]  reward = -1 termiated = False\n",
            "action = 2  state = [0 1] -> [1 1]  reward = -1 termiated = False\n",
            "action = 3  state = [1 1] -> [0 1]  reward = -1 termiated = False\n",
            "action = 2  state = [0 1] -> [1 1]  reward = -1 termiated = False\n",
            "action = 2  state = [1 1] -> [2 1]  reward = -1 termiated = False\n",
            "action = 2  state = [2 1] -> [3 1]  reward = -1 termiated = False\n",
            "action = 1  state = [3 1] -> [3 0]  reward = -1 termiated = False\n",
            "action = 3  state = [3 0] -> [2 0]  reward = -1 termiated = False\n",
            "action = 0  state = [2 0] -> [2 1]  reward = -1 termiated = False\n",
            "action = 1  state = [2 1] -> [2 0]  reward = -1 termiated = False\n",
            "action = 3  state = [2 0] -> [1 0]  reward = -1 termiated = False\n",
            "action = 0  state = [1 0] -> [1 1]  reward = -1 termiated = False\n",
            "action = 1  state = [1 1] -> [1 0]  reward = -1 termiated = False\n",
            "action = 3  state = [1 0] -> [0 0]  reward = -1 termiated = False\n",
            "action = 2  state = [0 0] -> [1 0]  reward = -1 termiated = False\n",
            "action = 2  state = [1 0] -> [2 0]  reward = -1 termiated = False\n",
            "action = 2  state = [2 0] -> [3 0]  reward = -1 termiated = False\n",
            "action = 3  state = [3 0] -> [2 0]  reward = -1 termiated = False\n",
            "action = 0  state = [2 0] -> [2 1]  reward = -1 termiated = False\n",
            "action = 3  state = [2 1] -> [1 1]  reward = -1 termiated = False\n",
            "action = 0  state = [1 1] -> [1 2]  reward = -1 termiated = False\n",
            "action = 1  state = [1 2] -> [1 1]  reward = -1 termiated = False\n",
            "action = 0  state = [1 1] -> [1 2]  reward = -1 termiated = False\n",
            "action = 2  state = [1 2] -> [2 2]  reward = -1 termiated = False\n",
            "action = 1  state = [2 2] -> [2 1]  reward = -1 termiated = False\n",
            "action = 3  state = [2 1] -> [1 1]  reward = -1 termiated = False\n",
            "action = 2  state = [1 1] -> [2 1]  reward = -1 termiated = False\n",
            "action = 1  state = [2 1] -> [2 0]  reward = -1 termiated = False\n",
            "action = 0  state = [2 0] -> [2 1]  reward = -1 termiated = False\n",
            "action = 3  state = [2 1] -> [1 1]  reward = -1 termiated = False\n",
            "action = 3  state = [1 1] -> [0 1]  reward = -1 termiated = False\n",
            "action = 2  state = [0 1] -> [1 1]  reward = -1 termiated = False\n",
            "action = 3  state = [1 1] -> [0 1]  reward = -1 termiated = False\n",
            "action = 3  state = [0 1] -> [-1  1]    reward = -10    termiated = True\n",
            "---에피소드11종료---\n",
            "action = 3  state = [0 0] -> [-1  0]    reward = -10    termiated = True\n",
            "---에피소드12종료---\n",
            "action = 0  state = [0 0] -> [0 1]  reward = -1 termiated = False\n",
            "action = 0  state = [0 1] -> [0 2]  reward = -1 termiated = False\n",
            "action = 0  state = [0 2] -> [0 3]  reward = -1 termiated = False\n",
            "action = 1  state = [0 3] -> [0 2]  reward = -1 termiated = False\n",
            "action = 1  state = [0 2] -> [0 1]  reward = -1 termiated = False\n",
            "action = 0  state = [0 1] -> [0 2]  reward = -1 termiated = False\n",
            "action = 1  state = [0 2] -> [0 1]  reward = -1 termiated = False\n",
            "action = 3  state = [0 1] -> [-1  1]    reward = -10    termiated = True\n",
            "---에피소드13종료---\n",
            "action = 2  state = [0 0] -> [1 0]  reward = -1 termiated = False\n",
            "action = 0  state = [1 0] -> [1 1]  reward = -1 termiated = False\n",
            "action = 0  state = [1 1] -> [1 2]  reward = -1 termiated = False\n",
            "action = 1  state = [1 2] -> [1 1]  reward = -1 termiated = False\n",
            "action = 0  state = [1 1] -> [1 2]  reward = -1 termiated = False\n",
            "action = 1  state = [1 2] -> [1 1]  reward = -1 termiated = False\n",
            "action = 2  state = [1 1] -> [2 1]  reward = -1 termiated = False\n",
            "action = 1  state = [2 1] -> [2 0]  reward = -1 termiated = False\n",
            "action = 3  state = [2 0] -> [1 0]  reward = -1 termiated = False\n",
            "action = 2  state = [1 0] -> [2 0]  reward = -1 termiated = False\n",
            "action = 0  state = [2 0] -> [2 1]  reward = -1 termiated = False\n",
            "action = 0  state = [2 1] -> [2 2]  reward = -1 termiated = False\n",
            "action = 1  state = [2 2] -> [2 1]  reward = -1 termiated = False\n",
            "action = 1  state = [2 1] -> [2 0]  reward = -1 termiated = False\n",
            "action = 0  state = [2 0] -> [2 1]  reward = -1 termiated = False\n",
            "action = 2  state = [2 1] -> [3 1]  reward = -1 termiated = False\n",
            "action = 1  state = [3 1] -> [3 0]  reward = -1 termiated = False\n",
            "action = 2  state = [3 0] -> [4 0]  reward = -10    termiated = True\n",
            "---에피소드14종료---\n",
            "action = 0  state = [0 0] -> [0 1]  reward = -1 termiated = False\n",
            "action = 2  state = [0 1] -> [1 1]  reward = -1 termiated = False\n",
            "action = 2  state = [1 1] -> [2 1]  reward = -1 termiated = False\n",
            "action = 1  state = [2 1] -> [2 0]  reward = -1 termiated = False\n",
            "action = 0  state = [2 0] -> [2 1]  reward = -1 termiated = False\n",
            "action = 2  state = [2 1] -> [3 1]  reward = -1 termiated = False\n",
            "action = 3  state = [3 1] -> [2 1]  reward = -1 termiated = False\n",
            "action = 1  state = [2 1] -> [2 0]  reward = -1 termiated = False\n",
            "action = 2  state = [2 0] -> [3 0]  reward = -1 termiated = False\n",
            "action = 1  state = [3 0] -> [ 3 -1]    reward = -10    termiated = True\n",
            "---에피소드15종료---\n",
            "action = 3  state = [0 0] -> [-1  0]    reward = -10    termiated = True\n",
            "---에피소드16종료---\n",
            "action = 1  state = [0 0] -> [ 0 -1]    reward = -10    termiated = True\n",
            "---에피소드17종료---\n",
            "action = 0  state = [0 0] -> [0 1]  reward = -1 termiated = False\n",
            "action = 2  state = [0 1] -> [1 1]  reward = -1 termiated = False\n",
            "action = 1  state = [1 1] -> [1 0]  reward = -1 termiated = False\n",
            "action = 3  state = [1 0] -> [0 0]  reward = -1 termiated = False\n",
            "action = 2  state = [0 0] -> [1 0]  reward = -1 termiated = False\n",
            "action = 0  state = [1 0] -> [1 1]  reward = -1 termiated = False\n",
            "action = 2  state = [1 1] -> [2 1]  reward = -1 termiated = False\n",
            "action = 1  state = [2 1] -> [2 0]  reward = -1 termiated = False\n",
            "action = 0  state = [2 0] -> [2 1]  reward = -1 termiated = False\n",
            "action = 2  state = [2 1] -> [3 1]  reward = -1 termiated = False\n",
            "action = 0  state = [3 1] -> [3 2]  reward = -1 termiated = False\n",
            "action = 2  state = [3 2] -> [4 2]  reward = -10    termiated = True\n",
            "---에피소드18종료---\n",
            "action = 3  state = [0 0] -> [-1  0]    reward = -10    termiated = True\n",
            "---에피소드19종료---\n",
            "action = 1  state = [0 0] -> [ 0 -1]    reward = -10    termiated = True\n",
            "---에피소드20종료---\n",
            "action = 0  state = [0 0] -> [0 1]  reward = -1 termiated = False\n",
            "action = 2  state = [0 1] -> [1 1]  reward = -1 termiated = False\n",
            "action = 1  state = [1 1] -> [1 0]  reward = -1 termiated = False\n",
            "action = 0  state = [1 0] -> [1 1]  reward = -1 termiated = False\n",
            "action = 1  state = [1 1] -> [1 0]  reward = -1 termiated = False\n",
            "action = 0  state = [1 0] -> [1 1]  reward = -1 termiated = False\n",
            "action = 2  state = [1 1] -> [2 1]  reward = -1 termiated = False\n",
            "action = 0  state = [2 1] -> [2 2]  reward = -1 termiated = False\n",
            "action = 1  state = [2 2] -> [2 1]  reward = -1 termiated = False\n",
            "action = 0  state = [2 1] -> [2 2]  reward = -1 termiated = False\n",
            "action = 1  state = [2 2] -> [2 1]  reward = -1 termiated = False\n",
            "action = 0  state = [2 1] -> [2 2]  reward = -1 termiated = False\n",
            "action = 1  state = [2 2] -> [2 1]  reward = -1 termiated = False\n",
            "action = 2  state = [2 1] -> [3 1]  reward = -1 termiated = False\n",
            "action = 1  state = [3 1] -> [3 0]  reward = -1 termiated = False\n",
            "action = 0  state = [3 0] -> [3 1]  reward = -1 termiated = False\n",
            "action = 2  state = [3 1] -> [4 1]  reward = -10    termiated = True\n",
            "---에피소드21종료---\n",
            "action = 0  state = [0 0] -> [0 1]  reward = -1 termiated = False\n",
            "action = 3  state = [0 1] -> [-1  1]    reward = -10    termiated = True\n",
            "---에피소드22종료---\n",
            "action = 0  state = [0 0] -> [0 1]  reward = -1 termiated = False\n",
            "action = 3  state = [0 1] -> [-1  1]    reward = -10    termiated = True\n",
            "---에피소드23종료---\n",
            "action = 1  state = [0 0] -> [ 0 -1]    reward = -10    termiated = True\n",
            "---에피소드24종료---\n",
            "action = 0  state = [0 0] -> [0 1]  reward = -1 termiated = False\n",
            "action = 1  state = [0 1] -> [0 0]  reward = -1 termiated = False\n",
            "action = 0  state = [0 0] -> [0 1]  reward = -1 termiated = False\n",
            "action = 1  state = [0 1] -> [0 0]  reward = -1 termiated = False\n",
            "action = 1  state = [0 0] -> [ 0 -1]    reward = -10    termiated = True\n",
            "---에피소드25종료---\n",
            "action = 3  state = [0 0] -> [-1  0]    reward = -10    termiated = True\n",
            "---에피소드26종료---\n",
            "action = 2  state = [0 0] -> [1 0]  reward = -1 termiated = False\n",
            "action = 3  state = [1 0] -> [0 0]  reward = -1 termiated = False\n",
            "action = 2  state = [0 0] -> [1 0]  reward = -1 termiated = False\n",
            "action = 2  state = [1 0] -> [2 0]  reward = -1 termiated = False\n",
            "action = 2  state = [2 0] -> [3 0]  reward = -1 termiated = False\n",
            "action = 1  state = [3 0] -> [ 3 -1]    reward = -10    termiated = True\n",
            "---에피소드27종료---\n",
            "action = 2  state = [0 0] -> [1 0]  reward = -1 termiated = False\n",
            "action = 2  state = [1 0] -> [2 0]  reward = -1 termiated = False\n",
            "action = 3  state = [2 0] -> [1 0]  reward = -1 termiated = False\n",
            "action = 0  state = [1 0] -> [1 1]  reward = -1 termiated = False\n",
            "action = 0  state = [1 1] -> [1 2]  reward = -1 termiated = False\n",
            "action = 1  state = [1 2] -> [1 1]  reward = -1 termiated = False\n",
            "action = 0  state = [1 1] -> [1 2]  reward = -1 termiated = False\n",
            "action = 1  state = [1 2] -> [1 1]  reward = -1 termiated = False\n",
            "action = 1  state = [1 1] -> [1 0]  reward = -1 termiated = False\n",
            "action = 3  state = [1 0] -> [0 0]  reward = -1 termiated = False\n",
            "action = 1  state = [0 0] -> [ 0 -1]    reward = -10    termiated = True\n",
            "---에피소드28종료---\n",
            "action = 1  state = [0 0] -> [ 0 -1]    reward = -10    termiated = True\n",
            "---에피소드29종료---\n",
            "action = 0  state = [0 0] -> [0 1]  reward = -1 termiated = False\n",
            "action = 0  state = [0 1] -> [0 2]  reward = -1 termiated = False\n",
            "action = 1  state = [0 2] -> [0 1]  reward = -1 termiated = False\n",
            "action = 2  state = [0 1] -> [1 1]  reward = -1 termiated = False\n",
            "action = 3  state = [1 1] -> [0 1]  reward = -1 termiated = False\n",
            "action = 2  state = [0 1] -> [1 1]  reward = -1 termiated = False\n",
            "action = 2  state = [1 1] -> [2 1]  reward = -1 termiated = False\n",
            "action = 0  state = [2 1] -> [2 2]  reward = -1 termiated = False\n",
            "action = 0  state = [2 2] -> [2 3]  reward = -1 termiated = False\n",
            "action = 3  state = [2 3] -> [1 3]  reward = -1 termiated = False\n",
            "action = 0  state = [1 3] -> [1 4]  reward = -10    termiated = True\n",
            "---에피소드30종료---\n",
            "action = 0  state = [0 0] -> [0 1]  reward = -1 termiated = False\n",
            "action = 1  state = [0 1] -> [0 0]  reward = -1 termiated = False\n",
            "action = 1  state = [0 0] -> [ 0 -1]    reward = -10    termiated = True\n",
            "---에피소드31종료---\n",
            "action = 2  state = [0 0] -> [1 0]  reward = -1 termiated = False\n",
            "action = 3  state = [1 0] -> [0 0]  reward = -1 termiated = False\n",
            "action = 1  state = [0 0] -> [ 0 -1]    reward = -10    termiated = True\n",
            "---에피소드32종료---\n",
            "action = 1  state = [0 0] -> [ 0 -1]    reward = -10    termiated = True\n",
            "---에피소드33종료---\n",
            "action = 3  state = [0 0] -> [-1  0]    reward = -10    termiated = True\n",
            "---에피소드34종료---\n",
            "action = 1  state = [0 0] -> [ 0 -1]    reward = -10    termiated = True\n",
            "---에피소드35종료---\n",
            "action = 0  state = [0 0] -> [0 1]  reward = -1 termiated = False\n",
            "action = 1  state = [0 1] -> [0 0]  reward = -1 termiated = False\n",
            "action = 0  state = [0 0] -> [0 1]  reward = -1 termiated = False\n",
            "action = 2  state = [0 1] -> [1 1]  reward = -1 termiated = False\n",
            "action = 0  state = [1 1] -> [1 2]  reward = -1 termiated = False\n",
            "action = 0  state = [1 2] -> [1 3]  reward = -1 termiated = False\n",
            "action = 3  state = [1 3] -> [0 3]  reward = -1 termiated = False\n",
            "action = 1  state = [0 3] -> [0 2]  reward = -1 termiated = False\n",
            "action = 3  state = [0 2] -> [-1  2]    reward = -10    termiated = True\n",
            "---에피소드36종료---\n",
            "action = 3  state = [0 0] -> [-1  0]    reward = -10    termiated = True\n",
            "---에피소드37종료---\n",
            "action = 1  state = [0 0] -> [ 0 -1]    reward = -10    termiated = True\n",
            "---에피소드38종료---\n",
            "action = 1  state = [0 0] -> [ 0 -1]    reward = -10    termiated = True\n",
            "---에피소드39종료---\n",
            "action = 2  state = [0 0] -> [1 0]  reward = -1 termiated = False\n",
            "action = 0  state = [1 0] -> [1 1]  reward = -1 termiated = False\n",
            "action = 0  state = [1 1] -> [1 2]  reward = -1 termiated = False\n",
            "action = 1  state = [1 2] -> [1 1]  reward = -1 termiated = False\n",
            "action = 0  state = [1 1] -> [1 2]  reward = -1 termiated = False\n",
            "action = 2  state = [1 2] -> [2 2]  reward = -1 termiated = False\n",
            "action = 3  state = [2 2] -> [1 2]  reward = -1 termiated = False\n",
            "action = 1  state = [1 2] -> [1 1]  reward = -1 termiated = False\n",
            "action = 0  state = [1 1] -> [1 2]  reward = -1 termiated = False\n",
            "action = 3  state = [1 2] -> [0 2]  reward = -1 termiated = False\n",
            "action = 1  state = [0 2] -> [0 1]  reward = -1 termiated = False\n",
            "action = 1  state = [0 1] -> [0 0]  reward = -1 termiated = False\n",
            "action = 0  state = [0 0] -> [0 1]  reward = -1 termiated = False\n",
            "action = 1  state = [0 1] -> [0 0]  reward = -1 termiated = False\n",
            "action = 3  state = [0 0] -> [-1  0]    reward = -10    termiated = True\n",
            "---에피소드40종료---\n",
            "action = 1  state = [0 0] -> [ 0 -1]    reward = -10    termiated = True\n",
            "---에피소드41종료---\n",
            "action = 0  state = [0 0] -> [0 1]  reward = -1 termiated = False\n",
            "action = 1  state = [0 1] -> [0 0]  reward = -1 termiated = False\n",
            "action = 3  state = [0 0] -> [-1  0]    reward = -10    termiated = True\n",
            "---에피소드42종료---\n",
            "action = 2  state = [0 0] -> [1 0]  reward = -1 termiated = False\n",
            "action = 2  state = [1 0] -> [2 0]  reward = -1 termiated = False\n",
            "action = 3  state = [2 0] -> [1 0]  reward = -1 termiated = False\n",
            "action = 3  state = [1 0] -> [0 0]  reward = -1 termiated = False\n",
            "action = 3  state = [0 0] -> [-1  0]    reward = -10    termiated = True\n",
            "---에피소드43종료---\n",
            "action = 2  state = [0 0] -> [1 0]  reward = -1 termiated = False\n",
            "action = 1  state = [1 0] -> [ 1 -1]    reward = -10    termiated = True\n",
            "---에피소드44종료---\n",
            "action = 0  state = [0 0] -> [0 1]  reward = -1 termiated = False\n",
            "action = 0  state = [0 1] -> [0 2]  reward = -1 termiated = False\n",
            "action = 0  state = [0 2] -> [0 3]  reward = -1 termiated = False\n",
            "action = 3  state = [0 3] -> [-1  3]    reward = -10    termiated = True\n",
            "---에피소드45종료---\n",
            "action = 3  state = [0 0] -> [-1  0]    reward = -10    termiated = True\n",
            "---에피소드46종료---\n",
            "action = 1  state = [0 0] -> [ 0 -1]    reward = -10    termiated = True\n",
            "---에피소드47종료---\n",
            "action = 1  state = [0 0] -> [ 0 -1]    reward = -10    termiated = True\n",
            "---에피소드48종료---\n",
            "action = 1  state = [0 0] -> [ 0 -1]    reward = -10    termiated = True\n",
            "---에피소드49종료---\n",
            "action = 3  state = [0 0] -> [-1  0]    reward = -10    termiated = True\n",
            "---에피소드50종료---\n",
            "action = 1  state = [0 0] -> [ 0 -1]    reward = -10    termiated = True\n",
            "---에피소드51종료---\n",
            "action = 0  state = [0 0] -> [0 1]  reward = -1 termiated = False\n",
            "action = 2  state = [0 1] -> [1 1]  reward = -1 termiated = False\n",
            "action = 0  state = [1 1] -> [1 2]  reward = -1 termiated = False\n",
            "action = 0  state = [1 2] -> [1 3]  reward = -1 termiated = False\n",
            "action = 3  state = [1 3] -> [0 3]  reward = -1 termiated = False\n",
            "action = 1  state = [0 3] -> [0 2]  reward = -1 termiated = False\n",
            "action = 0  state = [0 2] -> [0 3]  reward = -1 termiated = False\n",
            "action = 2  state = [0 3] -> [1 3]  reward = -1 termiated = False\n",
            "action = 3  state = [1 3] -> [0 3]  reward = -1 termiated = False\n",
            "action = 2  state = [0 3] -> [1 3]  reward = -1 termiated = False\n",
            "action = 2  state = [1 3] -> [2 3]  reward = -1 termiated = False\n",
            "action = 1  state = [2 3] -> [2 2]  reward = -1 termiated = False\n",
            "action = 2  state = [2 2] -> [3 2]  reward = -1 termiated = False\n",
            "action = 3  state = [3 2] -> [2 2]  reward = -1 termiated = False\n",
            "action = 1  state = [2 2] -> [2 1]  reward = -1 termiated = False\n",
            "action = 2  state = [2 1] -> [3 1]  reward = -1 termiated = False\n",
            "action = 0  state = [3 1] -> [3 2]  reward = -1 termiated = False\n",
            "action = 3  state = [3 2] -> [2 2]  reward = -1 termiated = False\n",
            "action = 2  state = [2 2] -> [3 2]  reward = -1 termiated = False\n",
            "action = 0  state = [3 2] -> [3 3]  reward = 100    termiated = True\n",
            "---에피소드52종료---"
          ]
        }
      ],
      "source": [
        "scores = [] \n",
        "playtimes = []\n",
        "for e in range(1,1000):\n",
        "    player.state = env.reset()\n",
        "    score = 0 \n",
        "    #---#\n",
        "    for playtime in range(1,50):\n",
        "        # step1 : agent --> env \n",
        "        player.act()\n",
        "        # step2: agnet <-- env \n",
        "        player.next_state, player.reward, player.terminated = env.step(player.action)\n",
        "        # step3: agent: update (save + learn) \n",
        "        player.save_experience() \n",
        "        player.learn()\n",
        "        # step4: prepare next iterations \n",
        "        player.state = player.next_state\n",
        "        score = score + player.reward\n",
        "        if env.terminated:\n",
        "            print(f\"---에피소드{e}종료---\")\n",
        "            break\n",
        "    #---#\n",
        "    scores.append(score)\n",
        "    if scores[-1] > 0:\n",
        "        break"
      ],
      "id": "d5dedcb4-b0e2-4df4-8dc2-7bda11434756"
    },
    {
      "cell_type": "code",
      "execution_count": 317,
      "metadata": {},
      "outputs": [],
      "source": [
        "scores[-1]"
      ],
      "id": "e903a918-8d0e-4c1b-b671-0dbec09e1f71"
    },
    {
      "cell_type": "code",
      "execution_count": 343,
      "metadata": {},
      "outputs": [],
      "source": [
        "paths = [np.array([0,0])]+ list(player.next_states)[-20:]\n",
        "show(paths)"
      ],
      "id": "ea940746-b1f5-4c5f-963a-61b013ab5426"
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3 (ipykernel)",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "codemirror_mode": {
        "name": "ipython",
        "version": "3"
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.21"
    }
  }
}