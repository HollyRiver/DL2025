{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9bac18bf",
   "metadata": {},
   "source": [
    "# 13wk-1: 강화학습 (1) - Bandit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a20c324",
   "metadata": {},
   "source": [
    "## 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6caaef90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import collections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77e86b8",
   "metadata": {},
   "source": [
    "## 2. 주요 코드 등"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d37aed-8d03-49d6-a342-8f9e64c6ccdd",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "58e00b5d-e5e8-4172-87a4-b361e45a4aa1",
   "metadata": {},
   "source": [
    "## 3. 강화학습 Intro"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b155538-94aa-4f48-b8e3-88f6bf3b8b8f",
   "metadata": {},
   "source": [
    "`-` 강화학습(대충설명): 어떠한 “(게임)환경”이 있을때 거기서 “뭘 할지”를\n",
    "학습하는 과업\n",
    "\n",
    "<figure class=\"margin-caption\">\n",
    "<img\n",
    "src=\"https://github.com/guebin/DL2025/blob/main/posts/13wk-1-fig1.png?raw=true\"\n",
    "alt=\"그림1: 셔튼(Sutton, Barto, et al. (1998))의 교재에서 발췌한 그림, 되게 유명한 그림이에요\" />\n",
    "<figcaption aria-hidden=\"true\">그림1: 셔튼(<span class=\"citation\"\n",
    "data-cites=\"sutton1998reinforcement\">Sutton, Barto, et al.\n",
    "(1998)</span>)의 교재에서 발췌한 그림, 되게 유명한\n",
    "그림이에요</figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c86346-19b3-4dbf-a0ff-c9ff9e19aa41",
   "metadata": {},
   "source": [
    "> 게임환경 : Environment - Agent의 액션에 대한 보상\n",
    ">\n",
    "> 액션의 대상 : Agent - Environment에 대한 액션을 취함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eefd6f8-cec8-4096-8692-0005da46cb2a",
   "metadata": {},
   "source": [
    "`-` 딥마인드: breakout $\\to$ 알파고\n",
    "\n",
    "-   <https://www.youtube.com/watch?v=TmPfTpjtdgg>\n",
    "\n",
    "<figure class=\"margin-caption\">\n",
    "<img\n",
    "src=\"https://github.com/guebin/DL2025/blob/main/posts/13wk-1-fig2.png?raw=true\"\n",
    "alt=\"그림2: 벽돌깨기\" />\n",
    "<figcaption aria-hidden=\"true\">그림2: 벽돌깨기</figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6060c827-524a-43cf-8022-8ab469ef2d1c",
   "metadata": {},
   "source": [
    "> State : 현재의 상태. 실시간 데이터? 비전?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26554998-769e-4b3e-baa8-9a7259d7d394",
   "metadata": {},
   "source": [
    "`-` 강화학습에서 “강화”는 뭘 강화한다는것일까?\n",
    "\n",
    "-   <https://k9connoisseur.com/blogs/news/positive-reinforcement-dog-training>\n",
    "\n",
    "> Agent의 행동을 강화함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c813479-494c-4984-bce3-8311f590f3e4",
   "metadata": {},
   "source": [
    "`-` 강화학습 미래? (이거 잘하면 먹고 살 수 있을까?)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d501e92-40a5-4f3d-a78b-61ea13eb0885",
   "metadata": {},
   "source": [
    "> 트랜스포머가 나오면서 그냥 싸잡아서 다 잘하는 애가 나오게 되었음\n",
    ">\n",
    "> 그럼에도 간간히 쓰임, 독특한 포지션\n",
    ">\n",
    "> 계속 바뀜, 그냥 바뀜"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2363cd50-7336-4fe1-9fbf-d23f645e692b",
   "metadata": {},
   "source": [
    "## 4. Bandit 게임 설명\n",
    "\n",
    "`-` 문제설명: 두 개의 버튼이 있다. `버튼0`을 누르면 1의 보상을,\n",
    "`버튼1`을 누르면 10의 보상을 준다고 가정\n",
    "\n",
    "-   Agent: 버튼0을 누르거나,버튼1을 누르는 존재\n",
    "-   Env: Agent의 Action을 바탕으로 Reward를 주는 존재\n",
    "\n",
    "> **주의: 이 문제 상황에서 state는 없음**\n",
    "\n",
    "`-` 생성형AI로 위의 상황을 설명한것\n",
    "\n",
    "<table style=\"width:100%;\">\n",
    "<colgroup>\n",
    "<col style=\"width: 33%\" />\n",
    "<col style=\"width: 33%\" />\n",
    "<col style=\"width: 33%\" />\n",
    "</colgroup>\n",
    "<tbody>\n",
    "<tr>\n",
    "<td style=\"text-align: left;\"><div width=\"33.3%\"\n",
    "data-layout-align=\"left\">\n",
    "<figure class=\"margin-caption\">\n",
    "<img\n",
    "src=\"https://github.com/guebin/DL2025/blob/main/posts/13wk-1-fig3-gpt.png?raw=true\"\n",
    "alt=\"(a) 챗지피티로 생성한그림\" />\n",
    "<figcaption aria-hidden=\"true\">(a) 챗지피티로 생성한그림</figcaption>\n",
    "</figure>\n",
    "</div></td>\n",
    "<td style=\"text-align: left;\"><div width=\"33.3%\"\n",
    "data-layout-align=\"left\">\n",
    "<figure class=\"margin-caption\">\n",
    "<img\n",
    "src=\"https://github.com/guebin/DL2025/blob/main/posts/13wk-1-fig3-gemini.png?raw=true\"\n",
    "alt=\"(b) 제미나이로 생성한 그림\" />\n",
    "<figcaption aria-hidden=\"true\">(b) 제미나이로 생성한 그림</figcaption>\n",
    "</figure>\n",
    "</div></td>\n",
    "<td style=\"text-align: left;\"><div width=\"33.3%\"\n",
    "data-layout-align=\"left\">\n",
    "<figure class=\"margin-caption\">\n",
    "<img\n",
    "src=\"https://github.com/guebin/DL2025/blob/main/posts/13wk-1-fig3-perplexity.png?raw=true\"\n",
    "alt=\"(c) 퍼플렉시티로 생성한 그림\" />\n",
    "<figcaption aria-hidden=\"true\">(c) 퍼플렉시티로 생성한 그림</figcaption>\n",
    "</figure>\n",
    "</div></td>\n",
    "</tr>\n",
    "</tbody>\n",
    "</table>\n",
    "\n",
    "-   클로드로 생성:\n",
    "    <https://claude.ai/public/artifacts/1f52fcb2-ef08-4af1-8cf8-4a497d7bcc5f>\n",
    "\n",
    "`-` 게임진행양상\n",
    "\n",
    "-   처음에는 아는게 없음. 일단 “아무거나” 눌러보자. (“에이전트가\n",
    "    랜덤액션을 한다” 고 표현함 )\n",
    "-   한 20번 정도 눌러보면서 결과를 관찰함 (“에이전트가 경험을\n",
    "    축적한다”고 표현함)\n",
    "-   버튼0을 누를때는 1점, 버튼1을 누를때는 10점을 준다는 사실을 깨달음.\n",
    "    (“에이전트가 환경을 이해했다”고 표현함)\n",
    "-   버튼1을 누르는게 나한테 이득이 라는 사실을 깨달음. (“에이전트가\n",
    "    최적의 정책을 학습했다” 고 표현함)\n",
    "-   이제부터 무조건 버튼1만 누름 $\\to$ 게임 클리어 (“강화학습 성공”이라\n",
    "    표현할 수 있음)\n",
    "\n",
    "`-` 어떻게 버튼1을 누르는게 이득이라는 사실을 아는거지? $\\to$ 아래와\n",
    "같은 테이블을 만들면 된다. (`q_table`)\n",
    "\n",
    "|        |             Action0             |             Action1             |\n",
    "|:------:|:-------------------------------:|:-------------------------------:|\n",
    "| State0 | mean(Reward \\| State0, Action0) | mean(Reward \\| State0, Action1) |\n",
    "\n",
    "> 조건부 기댓값으로 칠 때, 가장 추정치가 높은 액션을 선택하게 됨"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "193198c0-0d9d-4133-9714-12a0c115b594",
   "metadata": {},
   "source": [
    "## 5. Bandit 환경 설계 및 풀이\n",
    "\n",
    "### **A. 대충 개념만 실습**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "03ffb9fa-91fb-444d-8aee-c14313ef1c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "action_space = [0, 1] ## agent가 할 수 있는 action들의 집합\n",
    "actions_queue = collections.deque(maxlen = 500) ## 액션들을 큐로 저장, 큐의 최대 길이는 500 -> 최근 500개 결과만 저장\n",
    "rewards_queue = collections.deque(maxlen = 500) ## 리워드도 큐에 저장"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f4673ac-0dbd-44d5-ac09-37e16893df44",
   "metadata": {},
   "source": [
    "* 처음엔 아는게 없어서 무작위 액션 - 에이전트가 랜덤액션을 함 + 에이전트가 경험을 축적함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2ca66968-90a7-49c2-ab3b-4f5b6d3a94ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(10) :\n",
    "    ## agent가 action을 선택\n",
    "    action = np.random.choice(action_space)\n",
    "    \n",
    "    ## env가 reward를 제공\n",
    "    if action == 0 :\n",
    "        reward = 1\n",
    "    elif action == 1 :\n",
    "        reward = 10\n",
    "    \n",
    "    actions_queue.append(action)\n",
    "    rewards_queue.append(reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "504a6867-9e94-4d52-b3c4-062c7bac0144",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 큐를 행렬로 변환\n",
    "actions_array = np.array(actions_queue)\n",
    "rewards_array = np.array(rewards_queue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5decf371-a441-4d8e-843b-837c6043170a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1., 10.])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q0 = rewards_array[actions_array == 0].mean()\n",
    "q1 = rewards_array[actions_array == 1].mean()\n",
    "\n",
    "q_table = np.array([q0, q1])\n",
    "q_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4a02c7c5-1621-44f0-9037-e17c97ff2ddf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(1)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action = q_table.argmax()\n",
    "action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "060dd64d-87fa-4836-b5dc-06397cbaccf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(10) :\n",
    "    action = q_table.argmax()\n",
    "\n",
    "    if action == 0 :\n",
    "        reward = 1\n",
    "    else :\n",
    "        reward = 10\n",
    "\n",
    "    actions_queue.append(action)\n",
    "    rewards_queue.append(reward)\n",
    "\n",
    "    actions_array = np.array(actions_queue)\n",
    "    rewards_array = np.array(rewards_queue)\n",
    "    q0 = rewards_array[actions_array == 0].mean()\n",
    "    q1 = rewards_array[actions_array == 1].mean()\n",
    "    q_table = np.array([q0, q1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "315148b6-a5f0-4890-ab8a-a0d6ab40f1f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "deque([np.int64(0),\n",
       "       np.int64(1),\n",
       "       np.int64(0),\n",
       "       np.int64(1),\n",
       "       np.int64(1),\n",
       "       np.int64(0),\n",
       "       np.int64(0),\n",
       "       np.int64(0),\n",
       "       np.int64(0),\n",
       "       np.int64(0),\n",
       "       np.int64(1),\n",
       "       np.int64(1),\n",
       "       np.int64(1),\n",
       "       np.int64(1),\n",
       "       np.int64(1),\n",
       "       np.int64(1),\n",
       "       np.int64(1),\n",
       "       np.int64(1),\n",
       "       np.int64(1),\n",
       "       np.int64(1)],\n",
       "      maxlen=500)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions_queue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ceaea4-6104-4cc4-8b9c-c740fb0c5aa1",
   "metadata": {},
   "source": [
    "### **B. 클래스를 이용한 설계 및 풀이**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "cbe20434-65ad-4050-9157-dbfba8ef16d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bandit() :\n",
    "    \"\"\"\n",
    "    Environment. 게임 그 자체\n",
    "    \"\"\"\n",
    "    def __init__(self) :\n",
    "        self.reward = None\n",
    "        \n",
    "    def step(self, action) :\n",
    "        \"\"\"\n",
    "        function : action -> reward\n",
    "        \"\"\"\n",
    "        if action == 0 :\n",
    "            self.reward = 1\n",
    "        else :\n",
    "            self.reward = 10\n",
    "\n",
    "        return self.reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a2e1f601-e173-4898-8fd4-b52f2887d353",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = Bandit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "41fc4912-1292-44c4-8083-9c36c56988f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.step(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f7dc0548-6aa3-48b2-8b34-ce67224229c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0078e28-1ab7-4d24-9a90-2b1622171327",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent :\n",
    "    def __init__(self) :\n",
    "        self.experience = 0\n",
    "\n",
    "    def act(self) :\n",
    "        if self.experience <= 20 :\n",
    "\n",
    "    def save_experience(self) :\n",
    "\n",
    "    def learn(self) :"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
