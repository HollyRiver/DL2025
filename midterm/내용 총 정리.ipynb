{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **중간고사 이전 내용 총 정리**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL\n",
    "\n",
    "import requests\n",
    "import io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1. 기본 문법**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **A. 벡터와 행렬**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` 선언"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor([1, 2, 3]) ## 벡터\n",
    "torch.tensor([[1, 2],\n",
    "              [3, 4]]) ## 행렬. 근데 사실상 둘다 차원만 다른 텐서..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` 연산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 덧셈\n",
    "torch.tensor([1, 2, 3]) + torch.tensor([2]*3)\n",
    "torch.tensor([1, 2, 3]) + 2 ## 브로드캐스팅 - 벡터\n",
    "torch.tensor([[1, 2],\n",
    "              [3, 4],\n",
    "              [5, 6]]) - 1 ## 브로드캐스팅 - 행렬\n",
    "\n",
    "## 열별 브로드 캐스팅\n",
    "torch.tensor([[1, 2], [3, 4], [5, 6]]) + torch.tensor([[-1],\n",
    "                                                       [-3],\n",
    "                                                       [-5]])\n",
    "\n",
    "## 벡터와의 연산 : 열벡터로 취급\n",
    "torch.tensor([[1, 2], [3, 4], [5, 6]]) + torch.tensor([1, 2])\n",
    "torch.tensor([[1, 2], [3, 4], [5, 6]]) + torch.tensor([1, 2, 3]) ## 안됨\n",
    "\n",
    "## 행별 브로드캐스팅\n",
    "torch.tensor([[1, 2], [3, 4], [5, 6]]) + torch.tensor([[-1, -2]])\n",
    "\n",
    "\n",
    "## 개별 원소 곱\n",
    "torch.tensor([[1, 2], [3, 4], [5, 6]])*0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` 행렬곱"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 정상적인 행렬곱\n",
    "torch.tensor([[1, 2], [3, 4], [5, 6]]) @ torch.tensor([[1],\n",
    "                                                       [2]])\n",
    "torch.tensor([[1, 2], [3, 4], [5, 6]]) @ torch.tensor([1, 2]) ## 열벡터\n",
    "torch.tensor([[1, 2, 3]]) @ torch.tensor([[1, 2], [3, 4], [5, 6]])\n",
    "\n",
    "## 벡터와의 행렬곱 - 행벡터 취급\n",
    "torch.tensor([1, 2, 3]) @ torch.tensor([[1, 2], [3, 4], [5, 6]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` 전치, 차원 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 3],\n",
       "        [2, 4]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 행렬 전치\n",
    "torch.tensor([[1, 2], [3, 4]]).T\n",
    "\n",
    "## reshape\n",
    "torch.tensor([[1,2],[3,4],[5,6]]).reshape(2,-1) ## [[1, 2, 3], [4, 5, 6]]\n",
    "torch.tensor([[1,2],[3,4],[5,6]]).reshape(-1,6)\n",
    "torch.tensor([[1,2],[3,4],[5,6]]).reshape(-1) ## 1차원 벡터"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **B. `concat`, `stack`**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` concat(차원 유지)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4],\n",
       "        [5, 5]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([[1], [3], [5]])\n",
    "b = torch.tensor([[2], [4], [5]])\n",
    "torch.concat([a, b], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` stack(차원 늘림)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4],\n",
       "        [5, 6]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([1, 3, 5])\n",
    "b = torch.tensor([2, 4, 6])\n",
    "torch.stack([a, b], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4],\n",
       "        [5, 6]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.concat([a.reshape(-1, 1), b.reshape(-1, 1)], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **C. `torch.einsum()`**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` 전치 : transpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.randn(5, 2) ## X.t() ## X.T\n",
    "\n",
    "## 전치\n",
    "torch.einsum(\"ij -> ji\", X)\n",
    "X.permute(1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` 행렬곱"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.randn(5,2)\n",
    "b = torch.randn(2,1) ## X@b\n",
    "\n",
    "## 행렬곱\n",
    "torch.einsum(\"ij, jk -> ik\", X, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` `linr`와 텐서 행렬곱"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X =  torch.randn(5,2)\n",
    "linr = torch.nn.Linear(2,1,bias=True) ## linr(X)\n",
    "\n",
    "## linr.weight는 행벡터이므로, 전치하여 곱함 : jk -> kj\n",
    "torch.einsum(\"ij, kj -> ik\", X, linr.weight) + linr.bias ## 일반 텐서"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` CAM을 위한 이미지 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.einsum(\"ochw, kc -> khw\", torch_img, linr.weight.data) + linr.bias.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **D. 부가 사항**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` 사용자 정의 네트워크"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "class H(torch.nn.Module) :\n",
    "    def __init__(self) :\n",
    "        super().__init__() ## 슈퍼 클래스의 __init__을 그대로 상속\n",
    "\n",
    "    def forward(self, u) :\n",
    "        ## 메소드 오버라이딩\n",
    "        h = lambda x : torch.sigmoid(200*(x+0.5)) + torch.sigmoid(-200*(x-0.5)) - 1.0\n",
    "        v = h(u)\n",
    "        return v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` 확률적 경사하강법 장점\n",
    "\n",
    "* GPU 메모리를 덜 사용함\n",
    "* 에폭 별 학습에 데이터 전체를 사용하지 않아 오버피팅을 방지(배깅 느낌)\n",
    "* 최적화 도중 로컬 미니멈에 빠져도 잘 빠져나옴"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` 배치 및 GPU 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 배치 생성\n",
    "ds_train = torch.utils.data.TensorDataset(X, y)\n",
    "dl_train = torch.utils.data.DataLoader(ds_train, batch_size = 1024, shuffle = True)\n",
    "\n",
    "ds_test = torch.utils.data.TensorDataset(XX, yy)\n",
    "dl_test = torch.utils.data.DataLoarder(dl_test, batch_size = 1024) ## 테스트라 셔플 X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## GPU 할당 및 학습\n",
    "net.to(\"cuda:0\")\n",
    "\n",
    "##---## 에폭 수는 기존 에폭 / (len(X)/batch_size)\n",
    "for epoc in range(100) :\n",
    "    ## training\n",
    "    net.train()\n",
    "    \n",
    "    for Xm, ym in dl_train :\n",
    "        Xm = Xm.to(\"cuda:0\")\n",
    "        ym = ym.to(\"cuda:0\")\n",
    "        netout = net(Xm)\n",
    "\n",
    "        loss = loss_fn(netout, ym)\n",
    "        loss.backward()\n",
    "    \n",
    "        optimizr.step()\n",
    "        optimizr.zero_grad()\n",
    "\n",
    "    ## evaluation\n",
    "    if epoc % 50 == 0 :\n",
    "        net.eval()\n",
    "    \n",
    "        s = 0\n",
    "        \n",
    "        for Xm, ym in dl_train :\n",
    "            Xm = Xm.to(\"cuda:0\")\n",
    "            ym = ym.to(\"cuda:0\")\n",
    "    \n",
    "            s += ((net(Xm) > 0.0) == ym).sum() ## BCEWithLogitsLoss일때\n",
    "    \n",
    "        train_acc = s/len(X)\n",
    "        print(f\"epoch : {epoc},\\ttrain_acc = {train_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## GPU 메모리 초기화\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` 평가\n",
    "\n",
    "* **MSE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.eval()\n",
    "\n",
    "train_mse = torch.mean((y - net(X).data)**2) ## loss_fn(net(X), y)\n",
    "test_mse = torch.mean((yy - net(XX).data)**2) ## loss_fn(net(XX), yy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **이진 분류 : Accuracy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.eval()\n",
    "\n",
    "## 확률을 비교하는 경우\n",
    "train_acc = ((net(X) > 0.5) == y).float().mean() ## loss_fn(net(X), y)\n",
    "test_acc = ((net(XX) > 0.5) == yy).float().mean() ## loss_fn(net(XX), yy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.eval()\n",
    "\n",
    "## 로짓을 비교하는 경우\n",
    "train_acc = ((net(X) > 0.0) == y).float().mean() ## loss_fn(net(X), y)\n",
    "test_acc = ((net(XX) > 0.0) == yy).float().mean() ## loss_fn(net(XX), yy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **다항분류 : Accuracy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.eval()\n",
    "\n",
    "## 다항분류의 경우\n",
    "train_acc = (net(X).argmax(axis = 1) == y.argmax(axis = 1)).float().mean()\n",
    "test_acc = (net(XX).argmax(axis = 1) == yy.argmax(axis = 1)).float().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 배치 사용 시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 0\n",
    "\n",
    "for Xm, ym in dl_train :\n",
    "    Xm = Xm.to(\"cuda:0\")\n",
    "    ym = ym.to(\"cuda:0\")\n",
    "\n",
    "    s += torch.sum((ym - net(Xm).data)**2)\n",
    "    # s += ((net(Xm) > 0.0) == ym).sum()\n",
    "    # s += ((net(Xm) > 0.5) == ym).sum()\n",
    "    # s += (net(Xm).argmax(axis = 1) == ym.argmax(axis = 1)).sum()\n",
    "\n",
    "train_mse = s/len(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. 파라메터 count**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 이거 쓰면 한번에 검산 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum([torch.prod(torch.tensor(l.shape)) for l in net.parameters()]).item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` 1차원 선형 네트워크의 경우\n",
    "\n",
    "```Python\n",
    "net = torch.nn.Sequential(\n",
    "    torch.nn.Linear(64, 1024, bias = False),\n",
    "    torch.nn.Sigmoid(),\n",
    "    torch.nn.Linear(1024, 1, bias = True)\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> `in_features` $\\times$ `out_features` + `output_channels`(`bias`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66561"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(64*1024) + (1024*1 + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` 컨볼루션 커널을 포함하는 경우\n",
    "\n",
    "```Python\n",
    "net = torch.nn.Sequential(\n",
    "    torch.nn.Conv2d(3, 64, kernel_size = 3, bias = True),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.MaxPool2d(kernel_size = 3),\n",
    "    torch.nn.Flatten(),\n",
    "    torch.nn.Linear(6400, 1)\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> `input_channels` $\\times$ `output_channels` $\\times$ `kernel_size`$^2$ + `output_channels`(`bias`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8193"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(3*64*3**2 + 64) + (6400*1 + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3. 최적화**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**항상 문제가 생겼을 땐 학습률이나 에폭을 먼저 조정해볼 것**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **A. 이차함수**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` convex의 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "## convex function 자리\n",
    "def f(x) :\n",
    "    return (x-1)**2\n",
    "\n",
    "What = torch.tensor([3.0], requires_grad = True)\n",
    "\n",
    "for epoc in range(300) :\n",
    "    l = f(What)\n",
    "    l.backward()\n",
    "    What.data -= 0.1*What.grad\n",
    "    What.grad = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "함수를 최소화하는 x값 = 1.0000\n"
     ]
    }
   ],
   "source": [
    "print(f\"함수를 최소화하는 x값 = {What.data.item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` concave의 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "함수를 최소화하는 x값 = 3.0000\n"
     ]
    }
   ],
   "source": [
    "## concave function 자리\n",
    "def f(x) :\n",
    "    return (-x**2 + 6*x - 9)\n",
    "\n",
    "What = torch.tensor([0.0], requires_grad = True)\n",
    "\n",
    "for epoc in range(300) :\n",
    "    l = -f(What) ## 함수를 뒤집으면 최소화 문제가 됨\n",
    "    l.backward()\n",
    "    What.data -= 0.1*What.grad\n",
    "    What.grad = None\n",
    "\n",
    "print(f\"함수를 최소화하는 x값 = {What.data.item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **B. 정규분포 MLE**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` 함수 $l(\\mu, \\sigma)$를 최대화하는 $(\\mu, \\sigma)$ 추정\n",
    "\n",
    "$$l(\\mu, \\sigma) = \\sum_{i=1}^{n} \\log f(x_i), ~ f(x_i) = \\frac{1}{\\sqrt{2\\pi}\\sigma} \\exp \\bigg(- \\frac{(x_i - \\mu)^2}{2\\sigma^2} \\bigg)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "## given x format : matrix\n",
    "x = torch.randn((10000, 1))*2 + 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "추정된 mu값 = 2.9871\n",
      "추정된 sigma값 = 1.9993\n"
     ]
    }
   ],
   "source": [
    "## 정규분포 -log likelihood function\n",
    "def neg_l(mu, sigma) :\n",
    "    \"\"\"\n",
    "    가능도는 최대화해야 하므로, 최적화를 위해서 음수로 바꿔줌\n",
    "    평균을 최대화하는 것과 동일하므로 torch.mean을 사용\n",
    "    \"\"\"\n",
    "    fx = 1/((2*torch.pi)**0.5 * sigma) * torch.exp(-(x - mu)**2 / (2*sigma**2))\n",
    "    return -torch.mean(torch.log(fx))\n",
    "\n",
    "theta = torch.tensor([0.0, 1.0], requires_grad = True)\n",
    "\n",
    "for epoc in range(300) :\n",
    "    l = neg_l(theta[0], theta[1])\n",
    "    l.backward()\n",
    "    theta.data -= 0.1*theta.grad\n",
    "    theta.grad = None\n",
    "\n",
    "print(f\"추정된 mu값 = {theta.data[0]:.4f}\\n추정된 sigma값 = {theta.data[1]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **C. 베르누이 MLE**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` 함수 `l(p)`를 최대화하는 $p$ 추정\n",
    "\n",
    "$$l(p) = \\sum_{i=1}^{n} \\log f(x_i), ~ f(x_i) = p^{x_i} (1-p)^{1-x_i}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "## given x format : matrix\n",
    "x = torch.bernoulli(torch.tensor([0.8]*10000)).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 베르누이 -log likelihood function\n",
    "def neg_l(p) :\n",
    "    \"\"\"\n",
    "    가능도는 최대화해야 하므로, 최적화를 위해서 음수로 바꿔줌\n",
    "    평균을 최대화하는 것과 동일하므로 torch.mean을 사용\n",
    "    \"\"\"\n",
    "    fx = p**x * (1-p)**(1-x)\n",
    "    return -torch.mean(torch.log(fx))\n",
    "\n",
    "phat = torch.tensor([0.5], requires_grad = True) ## 반반에서 시작\n",
    "\n",
    "for epoc in range(300) :\n",
    "    l = neg_l(phat)\n",
    "    l.backward()\n",
    "    phat.data -= 0.1*phat.grad\n",
    "    phat.grad = None\n",
    "\n",
    "print(f\"추정된 p값 = {phat.data[0]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **D. 회귀모형의 MLE**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` 함수 $l(\\beta_0, \\beta_1)$을 최대화하는 $(\\beta_0, \\beta_1)$을 추정\n",
    "\n",
    "$$l(\\beta_0, \\beta_1) = \\sum_{i=1}^{n} \\log f(y_i), ~ f(y_i) = \\frac{1}{\\sqrt{2 \\pi}} e^{-\\frac12 (y_i - \\mu_i)^2}, ~ \\mu_i = \\beta_0 + \\beta_1 x_i$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "## given x, y : matrix\n",
    "x = torch.linspace(0,1,10000).reshape(10000,1)\n",
    "y = 0.5+2*x + torch.randn(10000,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neg_l(Bhat) :\n",
    "    \"\"\"\n",
    "    가능도는 최대화해야 하므로, 최적화를 위해서 음수로 바꿔줌\n",
    "    평균을 최대화하는 것과 동일하므로 torch.mean을 사용\n",
    "    \"\"\"\n",
    "    mu = Bhat[0] + Bhat[1]*x\n",
    "    fy = 1/((2*torch.pi)**0.5) * torch.exp(-0.5 * (y - mu)**2)\n",
    "    return -torch.mean(torch.log(fy))\n",
    "\n",
    "Bhat = torch.tensor([1.0, 1.0], requires_grad = True)\n",
    "\n",
    "for epoc in range(1000) :\n",
    "    l = neg_l(Bhat)\n",
    "    l.backward()\n",
    "    Bhat.data -= 0.1*Bhat.grad\n",
    "    Bhat.grad = None\n",
    "\n",
    "print(f\"추정된 beta0 = {Bhat[0]:.4f}\\n추정된 beta1 = {Bhat[1]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **E. 로지스틱모형의 MLE**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` 함수 $l(w_0, w_1)$을 최대화하는 파라미터 $(w_0, w_1)$을 추정\n",
    "\n",
    "$$l(w_0, w_1) = \\sum_{i=1}^n \\log f(y_i), ~ f(x_i) = \\pi_i^{y_i} (1-\\pi_i)^{1-y_i}, ~ \\pi_i = \\frac{\\exp(w_0 + w_1 x_i)}{1 + \\exp(w_0 + w_1 x_i)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "## given x, y, p : matrix\n",
    "x = torch.linspace(-1,1,10000).reshape(10000,1)\n",
    "pi = torch.exp(-1 + 0.5* x) / (1 + torch.exp(-1 + 0.5 * x))\n",
    "y = torch.bernoulli(pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neg_l(What) :\n",
    "    \"\"\"\n",
    "    가능도는 최대화해야 하므로, 최적화를 위해서 음수로 바꿔줌\n",
    "    평균을 최대화하는 것과 동일하므로 torch.mean을 사용\n",
    "    \"\"\"\n",
    "    pi = 1 / (1 + torch.exp(-(What[0] + What[1] * x)))\n",
    "    fx = pi**y * (1-pi)**(1-y)\n",
    "    return -torch.mean(torch.log(fx))\n",
    "\n",
    "What = torch.tensor([1.0, 1.0], requires_grad = True)\n",
    "\n",
    "for epoc in range(500) :\n",
    "    l = neg_l(What)\n",
    "    l.backward()\n",
    "    What.data -= 0.1*What.grad\n",
    "    What.grad = None\n",
    "\n",
    "print(f\"추정된 w0 = {What[0]:.4f}\\n추정된 w1 = {What[1]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` $-l(w_0, w_1)$이 BCE loss의 계산식과 동일한 형태임을 이용한 풀이"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = torch.nn.Sequential(\n",
    "    torch.nn.Linear(1, 1),\n",
    "    torch.nn.Sigmoid()\n",
    ")\n",
    "\n",
    "loss_fn = torch.nn.BCELoss()\n",
    "optimizr = torch.optim.SGD(net.parameters(), lr = 0.1)\n",
    "\n",
    "for epoc in range(1000) :\n",
    "    yhat = net(x)\n",
    "    loss = loss_fn(yhat, y)\n",
    "    loss.backward()\n",
    "    optimizr.step()\n",
    "    optimizr.zero_grad()\n",
    "\n",
    "print(f\"추정된 w0 = {net[0].bias.data.item():.4f}\\n추정된 w1 = {net[0].weight.data.item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **4. 회귀**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **A. 단순선형회귀**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 단순선형회귀에서 최적화하고자 하는 파라미터"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ loss(\\hat{w}_0,\\hat{w}_1) := loss(\\hat{\\bf W})=\\sum_{i=1}^{n}(y_i-(\\hat{w}_0+\\hat{w}_1x_i))^2=({\\bf y}-{\\bf X}{\\bf \\hat{W}})^\\top({\\bf y}-{\\bf X}{\\bf \\hat{W}})$$\n",
    "\n",
    "$$\\hat{\\bf W}^{LSE} = \\underset{\\bf \\hat{W}}{\\operatorname{argmin}} ~ loss(\\hat{\\bf W})$$\n",
    "\n",
    "> 위의 식은\n",
    "> $\\hat{\\bf W} = \\underset{\\bf W}{\\operatorname{argmin}} ~ loss({\\bf W})$\n",
    "> 로 생각해도 무방"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* LSE\n",
    "\n",
    "$$\\hat \\beta ^{LSE} = (\\bf X^{\\top}X) ^{-1} X^{\\top} y$$\n",
    "\n",
    "> 주어진 데이터 하에서 loss를 최소로 만드는 모수의 추정값은 최소제곱추정량과 일치한다. 따라서 epoch을 증가시켜도 경사하강법으로 추정된 값은 LSE에 수렴할 뿐, 참 값으로 수렴할 순 없다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` 쌩으로 구현(미분만 사용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "## data\n",
    "What = torch.tensor([[1.0],\n",
    "                     [2.0]], requires_grad = True) ## 매개변수 넣어야 미분 가능\n",
    "X = torch.concat([torch.ones(len(x), 1), x], axis = 1)\n",
    "\n",
    "##---##\n",
    "for epoc in range(1000) :\n",
    "    yhat = X@What\n",
    "    \n",
    "    loss = torch.mean((yhat-y)**2)\n",
    "    loss.backward()\n",
    "\n",
    "    What.data -= 0.01*What.grad ## learning rate == 0.01 -> nan 나오면 이걸 조정\n",
    "    What.grad = None\n",
    "\n",
    "print(f\"추정된 w0 = {What.data[0][0]:.4f}\\n추정된 w1 = {What.data[0][1]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` 네트워크, 손실함수, 옵티마이저 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 네트워크 초기 설정\n",
    "net = torch.nn.Linear(in_features = 1, out_features = 1, bias = True)\n",
    "net.weight.data = torch.tensor([[1.0]]) ## 행벡터로 삽입\n",
    "net.bias.data = torch.tensor([1.0])\n",
    "\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "optimizr = torch.optim.SGD(net.parameters(), lr = 0.01)\n",
    "\n",
    "##---##\n",
    "for epoc in range(1000) :\n",
    "    yhat = net(X)\n",
    "    \n",
    "    loss = loss_fn(yhat, y) ## torch.mean((y - yhat)**2)\n",
    "    loss.backward()\n",
    "\n",
    "    optimizr.step() ## What.data -= 0.01*What.grad\n",
    "    optimizr.zero_grad() ## What.grad = None\n",
    "\n",
    "print(f\"추정된 w0 = {net.bias.data[0]:.4f}\\n추정된 w1 = {net.weight.data.item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **5. 분류**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **A. 로지스틱**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` 로지스틱\n",
    "\n",
    "> 이진 분류 문제를 해결하기 위한 가장 기초적인 모형\n",
    ">\n",
    "> 꺾이지 않은 선형 구조만 제대로 설명할 수 있다는 점에서 모형의 표현력이 다소 낮음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   회귀모형: $y_i \\sim {\\cal N}(w_0+w_1x_i, \\sigma^2)$ -> 정규분포의 평균 예측\n",
    "\n",
    "-   로지스틱: $y_i \\sim {\\cal B}(\\pi_i),\\quad$ where $\\pi_i = \\frac{\\exp(w_0+w_1x_i)}{1+\\exp(w_0+w_1x_i)} = \\frac{1}{1+\\exp(-w_0-w_1x_i)}$\n",
    "> 베르누이의 평균(확률값)을 예측"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` 쌩으로 구현(미분만 이용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.randn((100, 1))\n",
    "prob = 1 / (1 + torch.exp(- X @ torch.tensor([[2.0]]) - 0.5))\n",
    "y = torch.bernoulli(prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "What = torch.tensor([[1.0],\n",
    "                     [1.0]], requires_grad = True) ## 절편 추가\n",
    "\n",
    "def sigmoid(x) :\n",
    "    return 1/(1+torch.exp(-(What[0] + What[1]*x)))\n",
    "\n",
    "for epoc in range(1000) :\n",
    "    yhat = sigmoid(X)\n",
    "\n",
    "    ## MLE니까 가능도가 가장 높은 -> -l이 가장 작은 것을 찾는 최적화 문제로 바꿈\n",
    "    loss = -torch.sum(y*torch.log(yhat) + (1-y)*torch.log(1-yhat)) ## 강의 노트엔 그냥 MSELoss 쓰긴 함...\n",
    "    loss.backward()\n",
    "    \n",
    "    What.data -= 0.1*What.grad\n",
    "    What.grad = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` 네트워크, BCELoss, Adam 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = torch.nn.Sequential(\n",
    "    torch.nn.Linear(1, 1), ## 이진 분류문제이므로 y의 차원은 1\n",
    "    torch.nn.Sigmoid()\n",
    ")\n",
    "net[0].weight.data = torch.tensor([[1.0]])\n",
    "net[0].bias.data = torch.tensor([1.0])\n",
    "\n",
    "loss_fn = torch.nn.BCELoss()\n",
    "\n",
    "## 지역 최소값에 잘 빠지지 않고, 최적화 속도가 빠름\n",
    "optimizr = torch.optim.Adam(net.parameters(), lr = 0.1)\n",
    "\n",
    "##---##\n",
    "for epoc in range(300) :\n",
    "    yhat = net(X)\n",
    "    \n",
    "    loss = loss_fn(yhat, y)\n",
    "    loss.backward()\n",
    "    \n",
    "    optimizr.step()\n",
    "    optimizr.zero_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **B. 다항분류**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` 분류별 이론\n",
    "\n",
    "|**분류**|**오차항의 가정**|**마지막 활성화함수**|**손실함수**|\n",
    "|:-:|:-:|:-:|:-:|\n",
    "|이항분류|이항분포|sigmoid|Binary Cross Entropy|\n",
    "|다항분류|다항분포|softmax|Cross Entropy|\n",
    "\n",
    "\n",
    "> 소프트 맥스 == 일반화 로짓 -> 나온 로짓 값에 지수함수 먹이고 상대비율로 추정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` 코딩용\n",
    "\n",
    "|**분류**|**netout의 의미**|**손실함수**|\n",
    "|:-:|:-:|:-:|\n",
    "|이항분류|prob|`BCELoss`|\n",
    "|이항분류|logit|`BCEWithLogitsLoss`|\n",
    "|다항분류|prob|그런거 없음|\n",
    "|다항분류|logits|`CrossEntropyLoss`|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` 원-핫 인코딩\n",
    "\n",
    "> `y`가 정수형(`long()`)일 경우 파이토치가 알아서 범주형으로 인식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.nn.functional.one_hot(y.reshape(-1).long()) ## 1차원 정수형이여야 함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **C. 신경망, 시벤코 정리, `ReLU`**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` 시벤코 정리\n",
    "\n",
    "> 하나의 은닉층을 가지는 네트워크는 모든 보렐 가측함수 $f: {\\bf X}_{n \\times p} \\to {\\bf y}_{n\\times q}$를 원하는 정확도로 근사시킬 수 있음\n",
    ">\n",
    "> 이 때, 은닉층의 활성화함수는 어떤 것이여도 상관없음 (`ReLU`, `Sidmoid`, `H`, ...)\n",
    ">\n",
    "> 즉, 하나의 은닉층을 가진 신경망의 표현력은 거의 무한대라 볼 수 있음\n",
    ">\n",
    "> 무한한 표현력 때문에 모형이 맞추지 말아야 할 오차항까지 맞출 수 있음.\n",
    ">\n",
    "> 네트워크가 학습하지 못한 자료에서도 신경망이 올바르게 작동한다는 보장은 없음."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` 특징\n",
    "\n",
    "```Python\n",
    "## 레이어가 2개인 신경망\n",
    "torch.nn.Sequential(\n",
    "    torch.nn.Linear(),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear()\n",
    ")\n",
    "```\n",
    "\n",
    "* 꺾인 그래프를 만들어 선형 모형의 표현력을 확보\n",
    "* 언더라잉이 로지스틱이라면 신경망의 성능이 더 안좋을 수 있음(Test dataset에서)\n",
    "* 신경망의 경우 회귀분석과 달리 여러 개의 최적값이 존재할 수 있음 -> 한 개의 global minimum만 가지지 않을 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` 신경망의 표현"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\underset{(n,784)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,32)}{\\boldsymbol u^{(1)}} \\overset{relu}{\\to} \\underset{(n,32)}{\\boldsymbol v^{(1)}} \\overset{l_2}{\\to} \\underset{(n,1)}{\\boldsymbol u^{(2)}} \\overset{sig}{\\to} \\underset{(n,1)}{\\boldsymbol v^{(2)}} =\\underset{(n,1)}{\\hat{\\boldsymbol y}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* $l_k$ : 선형 변환 -> 아래의 괄호로 변환된 차원 확인\n",
    "\n",
    "> 보통 $u$라고 표기하기도 함\n",
    "\n",
    "* $relu, ~ sig$ : 비선형 변환, 파라미터 없음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` `ReLU`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.arange(-10, 10).float()\n",
    "relu = torch.nn.ReLU()\n",
    "\n",
    "## v자 그래프\n",
    "relu(x) + relu(-x)\n",
    "\n",
    "## A자 그래프\n",
    "- relu(x) - relu(-x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 브로드캐스팅\n",
    "u = torch.stack([x, -x], axis = 1)\n",
    "v = relu(u)\n",
    "\n",
    "-4.5*v[:, [0]] - 9.0*v[:, [1]] + 4.5 ## 이 경우 [0]번 열이 뒤쪽, [1]번 열이 앞쪽 모양을 담당\n",
    "\n",
    "## 선형 결합\n",
    "l2 = torch.nn.Linear(2, 1, bias = True)\n",
    "l2.weight.data = torch.tensor([[-4.5, -9.0]])\n",
    "l2.bias.data = torch.tensor([4.5])\n",
    "\n",
    "l2(v)\n",
    "\n",
    "## 두 번의 선형 결합\n",
    "l1 = torch.nn.Linear(1, 2)\n",
    "l1.weight.data = torch.tensor([[1.0], [-1.0]]) ## 실제로 행벡터를 넣어야 하니 반대로...\n",
    "l1.bias.data = l1.bias.data*0\n",
    "\n",
    "l2(relu(l1(x.reshape(-1, 1))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **6. CNN**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **A. 사용법**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 다항 분류 및 이미지 처리가 뛰어남\n",
    "* 복잡한 구조의 DNN보다 더 빠르고, 성능이 좋고, 파라미터의 수가 적음 -> `input_channels * output_channels * kernel_size**2`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` 학습 과정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = torch.nn.Sequential(\n",
    "    ##-----layer 1 : 2d part-----##\n",
    "    ## 해당 파트에서 일반적으로 레이어 많이 씀\n",
    "    torch.nn.Conv2d(1, 64, kernel_size = 5),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.MaxPool2d(kernel_size = 5),\n",
    "\n",
    "    torch.nn.Flatten(),\n",
    "\n",
    "    ##-----layer 2 : 1d part-----##\n",
    "    ## 해당 파트의 네트워크는 약하게 구성하는 경우가 많음\n",
    "    torch.nn.Linear(???, p) ## 아무 숫자나 넣어보고 오류가 생기면 해당 숫자만 수정\n",
    ")\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizr = torch.optim.Adam(net.parameters())\n",
    "\n",
    "##---##\n",
    "for epoc in range(300) :\n",
    "    netout = net(X)\n",
    "\n",
    "    loss = loss_fn(netout, y)\n",
    "    loss.backward()\n",
    "\n",
    "    optimizr.step()\n",
    "    optimizr.zero_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **B. CNN 핵심 레이어**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**특징을 추출하고 -> 다변화하고 -> 요약**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` `torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding = 0, bias = True)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 컨볼루션 커널\n",
    "* 텐서에 커널 사이즈만한 윈도우를 통과시키고, 각 원소에 `weight`의 값을 가중평균 해줌. 최종적으로 `bias`를 더함. `stride`만큼 이동하여 반복.\n",
    "* 각 원소에 행렬 원소를 곱하여 더한다는 측면에서 선형 변환\n",
    "* 패딩을 해주지 않으면 거의 필연적으로 텐서 사이즈가 줄어듦"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = torch.nn.Conv2d(1, 1, 3, bias = False)\n",
    "## 가중치 텐서가 4차원으로 들어감 -> 채널이나 obs별로도 가중치를 먹일 수 있는건가?\n",
    "conv.weight.data = torch.tensor([[0.0, 1.0, 2.0],\n",
    "                                 [2.0, 2.0, 0.0],\n",
    "                                 [0.0, 1.0, 2.0]]).reshape(1, 1, 3, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` `torch.nn.ReLU()`\n",
    "\n",
    "* 특징을 더욱 다변화하기 위한 비선형 변환"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` `torch.nn.MaxPool2d(kernel_size, stride)`\n",
    "\n",
    "* 이미지에서 디테일은 버리고, 중요한 특징만 뽑아서 과장되게 요약\n",
    "* 컨볼루션은 그림을 뭉개는 경향이 있으나, MaxPooling은 중요한 정보를 손실시키지 않으려고 함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **C. 사전 구성 CNN**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `torchvision.models`에 들어가있는 모델"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` **AlexNet**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "torchvision.models.AlexNet()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` 알렉스넷 아키텍쳐\n",
    "\n",
    "* Conv : kernel_size = 11, stride = 4\n",
    "> 먼저 러프하게 보고 싶음 : 처음엔 큰 이미지를 대충대충 보고 싶음\n",
    "\n",
    "* Pool : kernel_size = 3, stride = 2\n",
    "> 처음엔 요약하고, 나중엔 요약하지 않고 싶음\n",
    "\n",
    "* Conv : kernel_size = 3\n",
    "> 조금 세밀하게 보고 싶음\n",
    "\n",
    "* 마지막 Pool\n",
    "> Flatten하기 직전이고, 데이터가 좀 많은 것 같아서 줄여줌\n",
    "\n",
    "* 신경망 설계 부분\n",
    "> ReLU : 1d part에서 표현력을 좀 더 얻어내고 싶다.\n",
    ">\n",
    "> 요약하고 싶었으면 Linear 한층만 받아도 충분했겠죠"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` **resnet18**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = torch.nn.Sequential(\n",
    "    ## layer 0\n",
    "    torch.nn.Sequential(\n",
    "        resnet18.conv1,\n",
    "        resnet18.bn1, ## Batch Normalization : 컨볼루션 커널 결과를 정규화 / 비선형 성질 유지\n",
    "        resnet18.relu,\n",
    "        resnet18.maxpool\n",
    "    ),\n",
    "\n",
    "    resnet18.layer1,\n",
    "    resnet18.layer2,\n",
    "    resnet18.layer3,\n",
    "    resnet18.layer4,\n",
    "\n",
    "    ## head\n",
    "    resnet18.avgpool,\n",
    "    torch.nn.Flatten(), ## 원본 클래스의 forward에는 모듈이 아닌 torch.flatten()으로 들어감\n",
    "    resnet18.fc\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet18 = torchvision.models.resnet18(pretrained = True) ## 가중치 가져오기\n",
    "resnet18.fc = torch.nn.Linear(512, p) ## 몇개 범주로 구분할 것인지 사후 설정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 총 18개의 레이어\n",
    "\n",
    "> 17개의 CNN 레이어 + 1개의 네트워크\n",
    ">\n",
    "> `downsample`은 네트워크가 아님(말그대로 다운 샘플링)\n",
    ">\n",
    "> 신경망이 깊기 때문에 레이어마다 배치 정규화를 해줌 -> 미분값이 0에 가까워지는 문제 해소\n",
    ">\n",
    "> `resnet18` 객체 자체는 subscriptable이 아님. 리스트로 호출할 수 없음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **7. CAM - Class Activation Map**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` **기존 `resnet18`의 마지막 레이어 네트워크**\n",
    "$$\\underset{(1,3,512,512)}{\\boldsymbol x} \\overset{stem}{\\to} \\left( \\underset{(1,512,16,16)}{\\tilde{\\boldsymbol x}} \\overset{ap}{\\to} \\underset{(1,512,1,1)}{{\\boldsymbol \\sharp}}\\overset{flattn}{\\to} \\underset{(1,512)}{{\\boldsymbol \\sharp}}\\overset{linr}{\\to} \\underset{(1,1)}{\\text{logit}}\\right) = [[-5.5613]]$$\n",
    "\n",
    "`-` **바꾸고 싶은 네트워크**\n",
    "$$\\underset{(1,3,224,224)}{\\boldsymbol x} \\overset{stem}{\\to} \\left( \\underset{(1,512,16,16)}{\\tilde{\\boldsymbol x}} \\overset{\\_linr}{\\to} \\underset{(1,1,16,16)}{{\\boldsymbol \\sharp}}\\overset{ap}{\\to} \\underset{(1,1,1,1)}{{\\boldsymbol \\sharp}}\\overset{flattn}{\\to} \\underset{(1,1)}{\\text{logit}}\\right) = [[-5.5613]]$$\n",
    "\n",
    "* `linr(flattn(ap(X)))` $\\to$ `flattn(ap(_linr(X)))`\n",
    "\n",
    "> `(1, c, h, w)` $\\to$ `(1, c, 1, 1)` : `ap` 먼저\n",
    ">\n",
    "> `(1, c, h, w)` $\\to$ `(1, 1, h, w)` : 선형결합으로 채널 통합 먼저 -> 러프 이미지 산출\n",
    "\n",
    "\n",
    "* CAM의 한계\n",
    "\n",
    "> head-part가 `ap`와 `linr`로만 구성되어 있어야 함. `AlexNet`과 같은 신경망은 헤드 파트를 임의로 바꿔줘야 함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Z. 데이터 준비**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 이미지와 라벨로 구성된 `train_dataset`, `test_dataset`이 필요함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "compose = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize((512, 512)), ## 이미지 사이즈 통일\n",
    "    torchvision.transforms.ToTensor() ## 이미지를 텐서로 변환\n",
    "])\n",
    "\n",
    "X = torch.stack([compose(train_dataset[i][0]) for i in range(len(train_dataset))], axis = 0)\n",
    "XX = torch.stack([compose(test_dataset[i][0]) for i in range(len(test_dataset))], axis = 0)\n",
    "\n",
    "y = torch.tensor([train_dataset[i][1] for i in range(len(train_dataset))]).reshape(-1, 1).float()\n",
    "yy = torch.tensor([test_dataset[i][1] for i in range(len(test_dataset))]).reshape(-1, 1).float()\n",
    "\n",
    "## 이진분류가 아닐 때 - 정수형\n",
    "# y = torch.tensor([train_dataset[i][1] for i in range(len(train_dataset))]).reshape(-1, 1)\n",
    "# yy = torch.tensor([test_dataset[i][1] for i in range(len(test_dataset))]).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **A. 이미지 분류 잘하는 네트워크 선택 후 학습**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## step 1 : 데이터 로드\n",
    "ds_train = torch.utils.data.TensorDataset(X, y)\n",
    "dl_train = torch.utils.data.DataLoader(ds_train, batch_size = 32, shuffle = True)\n",
    "\n",
    "ds_test = torch.utils.data.TensorDataset(XX, yy)\n",
    "dl_test = torch.utils.data.DataLoader(ds_test, batch_size = 32)\n",
    "\n",
    "\n",
    "## step 2 : 모델 및 가중치 불러오기\n",
    "resnet18 = torchvision.models.resnet18(pretrained = True)\n",
    "resnet18.fc = torch.nn.Linear(512, 1)\n",
    "\n",
    "loss_fn = torch.nn.BCEWithLogitsLoss() ## 최종 모델에 시그모이드 안들어가있음(못들어감)\n",
    "optimizr = torch.optim.Adam(resnet18.parameters(), lr = 1e-5) ## 세부조정만\n",
    "\n",
    "\n",
    "## step 3 : 사후 트레이닝\n",
    "resnet18.to(\"cuda:0\")\n",
    "\n",
    "for epoc in range(3) :\n",
    "    resnet18.train() ## dropout 있음\n",
    "\n",
    "    for Xm, ym in dl_train :\n",
    "        Xm = Xm.to(\"cuda:0\")\n",
    "        ym = ym.to(\"cuda:0\")\n",
    "\n",
    "        netout = resnet18(Xm)\n",
    "        \n",
    "        loss = loss_fn(netout, ym)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizr.step()\n",
    "        optimizr.zero_grad()\n",
    "\n",
    "    ## eval in epochs\n",
    "    resnet18.eval()\n",
    "    s = 0\n",
    "    \n",
    "    for Xm, ym in dl_train :\n",
    "        Xm = Xm.to(\"cuda:0\")\n",
    "        ym = ym.to(\"cuda:0\")\n",
    "\n",
    "        s += ((resnet18(Xm) > 0.0) == ym).sum().item()\n",
    "\n",
    "    train_acc = s/len(X)\n",
    "\n",
    "    print(f\"epoch : {epoc},\\ttrain_acc = {train_acc:.4f}\")\n",
    "\n",
    "\n",
    "## step 4 : 평가\n",
    "# resnet18.eval() ## 이미 평가모드임\n",
    "s = 0\n",
    "\n",
    "for XXm, yym in dl_test :\n",
    "    XXm = XXm.to(\"cuda:0\")\n",
    "    yym = yym.to(\"cuda:0\")\n",
    "\n",
    "    s += ((resnet18(XXm) > 0.0) == yym).sum().item()\n",
    "\n",
    "test_acc = s/len(XX)\n",
    "\n",
    "print(f\"test_acc = {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **B. 마지막 1d 레이어 파트를 `_linr -> ap -> flatten` 형태로 바꿈**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "stem = torch.nn.Sequential(\n",
    "    ## layer 0\n",
    "    torch.nn.Sequential(\n",
    "        resnet18.conv1,\n",
    "        resnet18.bn1,\n",
    "        resnet18.relu,\n",
    "        resnet18.maxpool\n",
    "    ),\n",
    "\n",
    "    resnet18.layer1,\n",
    "    resnet18.layer2,\n",
    "    resnet18.layer3,\n",
    "    resnet18.layer4\n",
    ")\n",
    "\n",
    "head = torch.nn.Sequential(\n",
    "    resnet18.avgpool,\n",
    "    torch.nn.Flatten(),\n",
    "    resnet18.fc\n",
    ")\n",
    "\n",
    "net = torch.nn.Sequential(\n",
    "    stem,\n",
    "    head\n",
    ")\n",
    "\n",
    "ap = head[0]\n",
    "flattn = head[1]\n",
    "linr = head[2]\n",
    "\n",
    "def _linr(X) :\n",
    "    return torch.einsum(\"ochw, kc -> okhw\", X, linr.weight.data) + linr.bias.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **C. 보간법을 활용하여 시각화**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(5, 5)\n",
    "\n",
    "#---#\n",
    "k = 0\n",
    "\n",
    "for i in range(5) :\n",
    "    for j in range(5) :\n",
    "        ##--------핵심 코드--------##\n",
    "        \n",
    "        x = XX[[k]].to(\"cuda:0\")\n",
    "        \n",
    "        if net(x) > 0 :\n",
    "            pred = \"dog\"\n",
    "            why = _linr(stem(x))\n",
    "        \n",
    "        else :\n",
    "            pred = \"cat\"\n",
    "            why = - _linr(stem(x))\n",
    "\n",
    "        ## 보간법으로 이미지 크기 조정\n",
    "        why_resized = torch.nn.functional.interpolate(\n",
    "            why, size = (512, 512), mode = \"bilinear\"\n",
    "        ) ## (1, 1, 512, 512)로 나옴\n",
    "\n",
    "        ax[i][j].imshow(x.squeeze().cpu().data.permute(1, 2, 0))\n",
    "        ax[i][j].imshow(why_resized.squeeze().cpu().data, cmap = \"magma\", alpha = 0.5)\n",
    "        \n",
    "        ##--------핵심 코드--------##\n",
    "\n",
    "        \n",
    "        ax[i][j].set_title(f\"prediction = {pred}\")\n",
    "        ax[i][j].set_xticks([])\n",
    "        ax[i][j].set_yticks([])\n",
    "\n",
    "        k += 50\n",
    "\n",
    "fig.set_figheight(16)\n",
    "fig.set_figwidth(16)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **8. 생성모형 GAN**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 서로 적대적인(Adversarial) 네트워크(Netword)를 동시에 학습시켜 가짜 이미지를 만든다(Generate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **A. 내용**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` 데이터의 생성확률 $P({\\bf X}, y)$를 알면 클래스의 사후확률 $P(y|{\\bf X})$를 알 수 있음. 하지만 역은 불가능\n",
    "\n",
    "$$P(y|\\bf X) = \\frac{P({\\bf X}, y)}{P({\\bf X})} = \\frac{P({\\bf X}, y)}{\\sum _y P({\\bf X}, y)}$$\n",
    "\n",
    "> 즉, 이미지를 생성하는 것은 분류문제보다 더 어려운 일이라고 해석할 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` 초기 GAN의 한계점\n",
    "\n",
    "* 두 네트워크의 균형이 매우 중요함 - 균형이 깨지는 순간 학습은 실패함. 너무 성능이 좋은 식별자를 가져오면 학습이 불가능함\n",
    "> `net_faker`가 뭔짓을 해도 `loss`를 줄일 수 없어서 학습을 못함\n",
    "\n",
    "* 생성되는 이미지의 다양성이 부족할 수 있음\n",
    "> 하나의 이미지가 `loss`를 매우 많이 줄여줬음 -> 얘량 비슷한 모양을 계속해서 찍어냄\n",
    ">\n",
    "> 생성모형에서의 고질적인 문제인 줄 알았지만, 해결할 수 있는 방법이 나옴 ㅇㅇ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **B. 구현**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torchvision.datasets.MNIST(root = \"./data\", train = True, download = True)\n",
    "to_tensor = torchvision.transforms.ToTensor() ## 이미지 shape는 똑같으니까 텐서로만...\n",
    "X_real = torch.stack([to_tensor(Xi) for Xi, yi in train_dataset if yi == 3]) ## 숫자 3인 것만...\n",
    "\n",
    "y_real = torch.tensor([0.0]*len(X_real)).reshape(-1, 1)\n",
    "y_fake = torch.tensor([1.0]*len(X_real)).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlattenToImage(torch.nn.Module) :\n",
    "    '''\n",
    "    생성자에서 마지막에 들어가 펴진 매트릭스를 이미지 포맷의 텐서로 변환하는 함수\n",
    "    (n, 784) -> (n, 1, 28, 28)\n",
    "    '''\n",
    "    def __init__(self) :\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x) :\n",
    "        return x.reshape(-1, 1, 28, 28)\n",
    "\n",
    "## police network\n",
    "net_police = torch.nn.Sequential(\n",
    "    torch.nn.Flatten(),\n",
    "    torch.nn.Linear(784, 32),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(32, 1),\n",
    "    torch.nn.Sigmoid()\n",
    ")\n",
    "\n",
    "## faker network\n",
    "net_faker = torch.nn.Sequential(\n",
    "    torch.nn.Linear(4, 64), ## 한 번에 변환하면 너무 변하니까 여러 레이어로\n",
    "    torch.nn.ReLU(), ## 렐루를 넣어서 변환을 더 복잡하게\n",
    "    torch.nn.Linear(64, 64),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(64, 784),\n",
    "    torch.nn.Sigmoid(), ## 출력을 0~1로 눌러줌\n",
    "    FlattenToImage()\n",
    ")\n",
    "\n",
    "bce = torch.nn.BCELoss()\n",
    "optimizr_police = torch.optim.Adam(net_police.parameters(), lr = 0.001, betas = (0.5, 0.999))\n",
    "optimizr_faker = torch.optim.Adam(net_faker.parameters(), lr = 0.0002, betas = (0.5, 0.999))\n",
    "\n",
    "##---##\n",
    "for epoc in range(1000) :\n",
    "    ##--------police training 1 epoch--------##\n",
    "    X_fake = net_faker(torch.randn(len(X_real), 4)).data ## 훈련 데이터\n",
    "\n",
    "    yhat_real = net_police(X_real)\n",
    "    yhat_fake = net_police(X_fake)\n",
    "    \n",
    "    loss = bce(yhat_real, y_real) + bce(yhat_fake, y_fake) ## 경찰은 둘다 잘해야 함\n",
    "    loss.backward()\n",
    "\n",
    "    optimizr_police.step()\n",
    "    optimizr_police.zero_grad()\n",
    "\n",
    "    ##----------faker training 1 epoch--------##\n",
    "    X_fake = net_faker(torch.randn(len(X_real), 4)) ## 네트워크의 output -> 미분필요\n",
    "\n",
    "    yhat_fake = net_police(X_fake)\n",
    "\n",
    "    loss = bce(yhat_fake, y_real) ## 식별자가 자신의 output을 반대로 식별해야 함\n",
    "    loss.backward()\n",
    "\n",
    "    optimizr_faker.step()\n",
    "    optimizr_faker.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x400 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_fake = net_faker(torch.randn(10, 4))\n",
    "\n",
    "fig, ax = plt.subplots(2, 5, figsize = (10, 4))\n",
    "\n",
    "k = 0\n",
    "\n",
    "for i in range(2) :\n",
    "    for j in range(5) :\n",
    "        ax[i][j].imshow(X_fake[[k]].data.squeeze(), cmap = \"grey\")\n",
    "        ax[i][j].set_title(f\"police out = {net_police(X_fake[[k]]).item():.4f}\")\n",
    "        k += 1\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **C. GAN with GPU & Batch**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torchvision.datasets.MNIST(root = \"./data\", train = True, download = True)\n",
    "to_tensor = torchvision.transforms.ToTensor() ## 이미지 shape는 똑같으니까 텐서로만...\n",
    "X_real = torch.stack([to_tensor(Xi) for Xi, yi in train_dataset if yi == 3]) ## 숫자 3인 것만...\n",
    "\n",
    "ds = torch.utils.data.TensorDataset(X_real)\n",
    "dl = torch.utils.data.DataLoader(ds, batch_size = 128, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlattenToImage(torch.nn.Module) :\n",
    "    '''\n",
    "    생성자에서 마지막에 들어가 펴진 매트릭스를 이미지 포맷의 텐서로 변환하는 함수\n",
    "    (n, 784) -> (n, 1, 28, 28)\n",
    "    '''\n",
    "    def __init__(self) :\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x) :\n",
    "        return x.reshape(-1, 1, 28, 28)\n",
    "\n",
    "## police network\n",
    "net_police = torch.nn.Sequential(\n",
    "    torch.nn.Flatten(),\n",
    "    torch.nn.Linear(784, 32),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(32, 1),\n",
    "    torch.nn.Sigmoid()\n",
    ").to(\"cuda:0\")\n",
    "\n",
    "## faker network\n",
    "net_faker = torch.nn.Sequential(\n",
    "    torch.nn.Linear(4, 64), ## 한 번에 변환하면 너무 변하니까 여러 레이어로\n",
    "    torch.nn.ReLU(), ## 렐루를 넣어서 변환을 더 복잡하게\n",
    "    torch.nn.Linear(64, 64),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(64, 784),\n",
    "    torch.nn.Sigmoid(), ## 출력을 0~1로 눌러줌\n",
    "    FlattenToImage()\n",
    ").to(\"cuda:0\")\n",
    "\n",
    "bce = torch.nn.BCELoss()\n",
    "optimizr_police = torch.optim.Adam(net_police.parameters(), lr = 0.001, betas = (0.5, 0.999))\n",
    "optimizr_faker = torch.optim.Adam(net_faker.parameters(), lr = 0.0002, betas = (0.5, 0.999))\n",
    "\n",
    "##---##\n",
    "for epoc in range(10) :\n",
    "    for Xm in dl :\n",
    "        ##--------police training 1 epoch--------##\n",
    "        Xm_real = Xm.to(\"cuda:0\")\n",
    "        Xm_fake = net_faker(torch.randn(len(Xm_real), 4).to(\"cuda:0\")).data\n",
    "        \n",
    "        ym_real = torch.tensor([0.0]*len(Xm_real)).reshape(-1, 1).to(\"cuda:0\")\n",
    "        ym_fake = torch.tensor([1.0]*len(Xm_real)).reshape(-1, 1).to(\"cuda:0\")\n",
    "\n",
    "        yhat_real = net_police(Xm_real)\n",
    "        yhat_fake = net_police(Xm_fake)\n",
    "        \n",
    "        loss = bce(yhat_real, ym_real) + bce(yhat_fake, ym_fake) ## 경찰은 둘다 잘해야 함\n",
    "        loss.backward()\n",
    "    \n",
    "        optimizr_police.step()\n",
    "        optimizr_police.zero_grad()\n",
    "    \n",
    "        ##----------faker training 1 epoch--------##\n",
    "        Xm_fake = net_faker(torch.randn(len(Xm_real), 4).to(\"cuda:0\")) ## 네트워크의 output -> 미분필요\n",
    "        ym_real = torch.tensor([0.0]*len(Xm_fake)).reshape(-1, 1).to(\"cuda:0\")\n",
    "        \n",
    "        yhat_fake = net_police(Xm_fake)\n",
    "\n",
    "        loss = bce(yhat_fake, ym_real) ## 식별자가 자신의 output을 반대로 식별해야 함\n",
    "        loss.backward()\n",
    "    \n",
    "        optimizr_faker.step()\n",
    "        optimizr_faker.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_fake = net_faker(torch.randn(10, 4).to(\"cuda:0\"))\n",
    "\n",
    "fig, ax = plt.subplots(2, 5, figsize = (10, 4))\n",
    "\n",
    "k = 0\n",
    "\n",
    "for i in range(2) :\n",
    "    for j in range(5) :\n",
    "        ax[i][j].imshow(X_fake[[k]].to(\"cpu\").data.squeeze(), cmap = \"grey\")\n",
    "        ax[i][j].set_title(f\"police out = {net_police(X_fake[[k]]).item():.4f}\")\n",
    "        k += 1\n",
    "\n",
    "fig.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
