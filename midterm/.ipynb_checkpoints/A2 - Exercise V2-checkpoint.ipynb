{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0af22e59-5b02-4832-a07d-4fac3e85da70",
   "metadata": {},
   "source": [
    "# A1: Exercise – ver. 0420-2\n",
    "\n",
    "최규빈  \n",
    "2025-01-01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "284757a4-ca47-4f7d-bd4a-5ee86e26cc46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import PIL\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a3c061a-d0fc-4928-af07-811b0996cc2f",
   "metadata": {},
   "source": [
    "# `#` – 최적화\n",
    "\n",
    "## `$`. 경사하강법, 경사상승법\n",
    "\n",
    "`(1)` 아래의 함수를 최소화하는 $x$를 경사하강법기반의 알고리즘을\n",
    "활용하여 추정하라. (꼭 SGD를 쓸 필요는 없음)\n",
    "\n",
    "$$f(x)=(x-1)^2$$\n",
    "\n",
    "초기값은 $x=3$ 으로 설정하라."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f394b524-cde3-43d6-bbf9-38ad8dcfb7c9",
   "metadata": {},
   "source": [
    "`-` 함수 선언"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "866e96fc-dcbd-4f0e-b756-2c0205ba3f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 본함수\n",
    "def f(x) :\n",
    "    return (x-1)**2\n",
    "\n",
    "## 미분계수 산출\n",
    "def f_prime(x) :\n",
    "    h = 0.000001\n",
    "    return (f(x+h) - f(x))/h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d27d37b3-134e-46eb-9fde-a1e7bbbbab45",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 경사하강법\n",
    "def GD(x, f_prime, lr = 0.1, convex = True) :\n",
    "    slope = f_prime(x)\n",
    "    \n",
    "    if (abs(slope) <= 1e-6) :\n",
    "        print(f\"optimal value x = {x:.4f}\")\n",
    "        \n",
    "        return x\n",
    "\n",
    "    else :\n",
    "        if convex :\n",
    "            renewed_x = x - lr*slope\n",
    "        else :\n",
    "            renewed_x = x + lr*slope\n",
    "\n",
    "        return SGD(renewed_x, f_prime, lr, convex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d0384413-2bcb-46b2-a968-44e940956b66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimal value x = 1.0000\n"
     ]
    }
   ],
   "source": [
    "optim = GD(x = 3, f_prime = f_prime)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45bb6266-6604-4c68-b3a9-5cfbfbed6009",
   "metadata": {},
   "source": [
    "`(2)` 아래의 함수를 최대화하는 $x$를 경사하강법기반의 알고리즘을\n",
    "활용하여 추정하라. (꼭 SGD를 쓸 필요는 없음)\n",
    "\n",
    "$$f(x)=-x^2 +6x-9 $$\n",
    "\n",
    "초기값은 $x=0$ 으로 설정하라.\n",
    "\n",
    "hint: $f(x)$을 최대화하는 $x$는 $-f(x)$를 최소화한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7a414d35-eb0d-48d6-92c9-8280760fa4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def g(x) :\n",
    "    return (-x**2 + 6*x - 9)\n",
    "\n",
    "def g_prime(x) :\n",
    "    h = 0.000001\n",
    "    return (g(x+h) - g(x))/h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f7a6140f-f597-4f4a-a6fb-62fc820b5b73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimal value x = 3.0000\n"
     ]
    }
   ],
   "source": [
    "optim = SGD(x = 0.0, f_prime = g_prime, lr = 0.1, convex = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d437d23-979a-4d12-84a2-0fc891b3cc81",
   "metadata": {},
   "source": [
    "## `$`. 정규분포 MLE\n",
    "\n",
    "아래는 $X_i \\sim N(3, 2^2)$ 를 생성하는 코드이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "cd7c1357-7113-425b-ac68-1a9efb9f3302",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(43052)\n",
    "x = torch.randn((10000,1)) * 2 + 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95433c94-b557-4a33-982d-3eae15fad312",
   "metadata": {},
   "source": [
    "함수 $l(\\mu, \\sigma)$를 최대화하는 $(\\mu, \\sigma)$를 경사하강법기반의\n",
    "알고리즘을 활용하여 추정하라. (꼭 SGD를 쓸 필요는 없음)\n",
    "\n",
    "$$l(\\mu, \\sigma) = \\sum_{i=1}^{n} \\log f(x_i), \\quad\n",
    "f(x_i) = \\frac{1}{\\sqrt{2\\pi}\\sigma} \\exp\\left(-\\frac{(x_i - \\mu)^2}{2\\sigma^2}\\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f064ce47-0263-4867-b9ef-3140f2108a7c",
   "metadata": {},
   "source": [
    "* 위는 아래 함수를 최소화하는 $\\mu, \\sigma$를 찾는 것과 동일하므로\n",
    "\n",
    "$$l_2(\\mu, \\sigma) = -\\frac1n\\sum_{i=1}^{n} \\log f(x_i)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "f0e20254-7de6-460a-9e84-055b329585a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def neg_l(What) :\n",
    "    fx = (1/((2*torch.pi)**0.5 * What[1])) * torch.exp(-(x - What[0])**2 / (2*What[1]**2))\n",
    "\n",
    "    return -torch.mean(torch.log(fx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "a7ca6230-8349-48d1-baf6-75e3dca38934",
   "metadata": {},
   "outputs": [],
   "source": [
    "What = torch.tensor([0.0, 1.0], requires_grad = True)\n",
    "\n",
    "##---##\n",
    "for _ in range(1000) :\n",
    "    loss = neg_l(What)\n",
    "    loss.backward()\n",
    "    What.data -= 0.1*What.grad\n",
    "    What.grad = What.grad*0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "c29a1648-894e-4771-8284-c2c8aa0fbe1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "추정된 mu = 3.0187\n",
      "추정된 sigma = 2.0113\n"
     ]
    }
   ],
   "source": [
    "print(f\"추정된 mu = {What.data[0]:.4f}\\n추정된 sigma = {What.data[1]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b2b8aa-4809-4158-ab9e-8db1067a08d2",
   "metadata": {},
   "source": [
    "## `$`. 베르누이 MLE\n",
    "\n",
    "아래는 $X_i \\overset{iid}{\\sim} Ber(0.8)$을 생성하는 코드이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "61d3fef6-e0ec-4d5e-8eda-543ac60d4d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(43052)\n",
    "x = torch.bernoulli(torch.tensor([0.8]*10000)).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cef4e7e-6383-48de-98c5-9cfc804a0f5f",
   "metadata": {},
   "source": [
    "함수 $l(p)$를 최대화하는 $p$를 경사하강법기반을 알고리즘을 활용하여\n",
    "추정하라. (꼭 SGD를 쓸 필요는 없음)\n",
    "\n",
    "$$l(p) = \\sum_{i=1}^{n} \\log f(x_i), \\quad f(x_i) = p^{x_i} (1-p)^{1-x_i}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d199d0f-8072-4ff2-b54b-c049a3ce10a5",
   "metadata": {},
   "source": [
    "* 위는 아래 함수를 최소화하는 $\\mu, \\sigma$를 찾는 것과 동일하므로\n",
    "\n",
    "$$l_2(p) = -\\frac1n\\sum_{i=1}^{n} \\log f(x_i)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "0f55d40f-79e8-48c7-8af7-db380685f95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def neg_l(p) :\n",
    "    fx = p**x * (1-p)**(1-x)\n",
    "\n",
    "    return -(torch.mean(torch.log(fx)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "c32460bf-af72-490e-920c-29a7ade7773c",
   "metadata": {},
   "outputs": [],
   "source": [
    "phat = torch.tensor([0.5], requires_grad = True)\n",
    "\n",
    "##---##\n",
    "for _ in range(1000) :\n",
    "    loss = neg_l(phat)\n",
    "    loss.backward()\n",
    "    phat.data -= 0.01*phat.grad\n",
    "    phat.grad = phat.data*0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "0d0acca3-f692-449e-930c-9fffb0633c49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "추정된 p = 0.7971\n"
     ]
    }
   ],
   "source": [
    "print(f\"추정된 p = {phat.data[0]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b733226-ddc0-4019-a9f1-ceba7b861bc2",
   "metadata": {},
   "source": [
    "## `$`. 회귀모형의 MLE\n",
    "\n",
    "아래의 모형을 생각하자.\n",
    "\n",
    "-   $Y_i \\overset{iid}{\\sim} \\mathcal{N}(\\mu_i, 1)$\n",
    "-   $\\mu_i = \\beta_0 + \\beta_1 x_i = 0.5 + 2x_i$\n",
    "\n",
    "아래는 위의 모형에서 얻은 샘플이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "1e972856-76dc-46d9-9f69-54fae18110fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.linspace(0,1,10000).reshape(10000,1)\n",
    "y = 0.5+2*x + torch.randn(10000,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750845fc-2179-4aec-b749-41cb7688585a",
   "metadata": {},
   "source": [
    "함수 $l(\\beta_0, \\beta_1)$를 최대화하는 $(\\beta_0, \\beta_1)$를\n",
    "경사하강법기반의 알고리즘을 활용하여 추정하라. (꼭 SGD를 쓸 필요는 없음)\n",
    "\n",
    "$$\n",
    "l(\\beta_0, \\beta_1) = \\sum_{i=1}^{n} \\log f(y_i), \\quad f(y_i) = \\frac{1}{\\sqrt{2\\pi}} e^{-\\frac{1}{2}(y_i - \\mu_i)^2}, \\quad \\mu_i = \\beta_0 + \\beta_1 x_i\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41274bb3-7b29-4a56-a5fd-c404232db345",
   "metadata": {},
   "source": [
    "* 위는 아래 함수를 최소화하는 $\\mu, \\sigma$를 찾는 것과 동일하므로\n",
    "\n",
    "$$l_2(\\beta_0, \\beta_1) = -\\frac1n\\sum_{i=1}^{n} \\log f(x_i)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "42ffb662-7180-4edb-a14b-7cb519254966",
   "metadata": {},
   "outputs": [],
   "source": [
    "def neg_l(Bhat) :\n",
    "    mu = Bhat[0] + Bhat[1] * x\n",
    "    fy = (1/((2*torch.pi)**0.5)) * torch.exp(-0.5*(y - mu)**2)\n",
    "\n",
    "    return -torch.mean(torch.log(fy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "8ace7ac0-3204-47d0-bb2d-cf6d7ed5fa7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Bhat = torch.tensor([0.0, 0.0], requires_grad = True)\n",
    "\n",
    "##---##\n",
    "for _ in range(1000) :\n",
    "    loss = neg_l(Bhat)\n",
    "    loss.backward()\n",
    "    Bhat.data -= 0.1*Bhat.grad\n",
    "    Bhat.grad = Bhat.data*0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "c7b72aaa-7930-4e47-82f5-d4e87e231607",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "추정된 beta0 = 0.5039\n",
      "추정된 beta1 = 2.0019\n"
     ]
    }
   ],
   "source": [
    "print(f\"추정된 beta0 = {Bhat.data[0]:.4f}\\n추정된 beta1 = {Bhat.data[1]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b64b4026-e535-40c2-9fd6-966df0273119",
   "metadata": {},
   "source": [
    "## `$`. 로지스틱모형의 MLE\n",
    "\n",
    "아래의 모형을 생각하자.\n",
    "\n",
    "-   $Y_i \\overset{iid}{\\sim} Ber(\\pi_i)$\n",
    "-   $\\pi_i = \\dfrac{\\exp(w_0 + w_1 x_i)}{1 + \\exp(w_0 + w_1 x_i)} = \\dfrac{\\exp(-1 + 0.5x_i)}{1 + \\exp(-1 + 0.5x_i)}$\n",
    "\n",
    "아래는 위의 모형에서 얻은 샘플이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "c1e45e39-09f6-49cb-81b9-f2da71f7ebaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.linspace(-1,1,10000).reshape(10000,1)\n",
    "pi = torch.exp(-1 + 0.5* x) / (1 + torch.exp(-1 + 0.5 * x))\n",
    "y = torch.bernoulli(pi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353c81f1-1418-4951-8145-6e29ead59ec4",
   "metadata": {},
   "source": [
    "함수 $l(w_0, w_1)$을 최대화하는 파라미터 $(w_0, w_1)$를 경사하강법기반을\n",
    "알고리즘을 활용하여 추정하라. (꼭 SGD를 쓸 필요는 없음)\n",
    "\n",
    "$$\n",
    "l(w_0, w_1) = \\sum_{i=1}^{n} \\log f(y_i), \\quad\n",
    "f(x_i) = \\pi_i^{y_i}(1 - \\pi_i)^{1 - y_i}, \\quad\n",
    "\\pi_i = \\dfrac{\\exp(w_0 + w_1 x_i)}{1 + \\exp(w_0 + w_1 x_i)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad84da8-2330-4079-bea7-6f3094e5368e",
   "metadata": {},
   "source": [
    "* 위는 아래 함수를 최소화하는 $\\mu, \\sigma$를 찾는 것과 동일하므로\n",
    "\n",
    "$$l_2(w_0, w_1) = -\\frac1n\\sum_{i=1}^{n} \\log f(x_i)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "83969729-ca9f-41b1-957e-5a2aa580bbd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def neg_l(What) :\n",
    "    pii = torch.exp(What[0] + What[1] * x)/(1+torch.exp(What[0] + What[1] * x))\n",
    "    fx = pii**y * (1-pii)**(1-y)\n",
    "\n",
    "    return -torch.mean(torch.log(fx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "d811311f-16a2-4542-8340-12f2d09c8846",
   "metadata": {},
   "outputs": [],
   "source": [
    "What = torch.tensor([0.0, 0.0], requires_grad = True)\n",
    "\n",
    "##---##\n",
    "for _ in range(1000) :\n",
    "    loss = neg_l(What)\n",
    "    loss.backward()\n",
    "    What.data -= 0.1*What.grad\n",
    "    What.grad = What.data*0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "7156fd41-b7f8-494d-b38d-8dce1656f7c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "추정된 w0 = -1.0231\n",
      "추정된 w1 = 0.5272\n"
     ]
    }
   ],
   "source": [
    "print(f\"추정된 w0 = {What.data[0]:.4f}\\n추정된 w1 = {What.data[1]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae15ba9-214d-48d6-abf7-29537641c1b9",
   "metadata": {},
   "source": [
    "# `#` – 분류\n",
    "\n",
    "## `$`. iris\n",
    "\n",
    "아래의 자료를 고려하자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22c196d3-5c7b-4ca5-ab6a-99185a5f9a6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SepalLength</th>\n",
       "      <th>SepalWidth</th>\n",
       "      <th>PetalLength</th>\n",
       "      <th>PetalWidth</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     SepalLength  SepalWidth  PetalLength  PetalWidth  Species\n",
       "0            5.1         3.5          1.4         0.2      0.0\n",
       "1            4.9         3.0          1.4         0.2      0.0\n",
       "2            4.7         3.2          1.3         0.2      0.0\n",
       "3            4.6         3.1          1.5         0.2      0.0\n",
       "4            5.0         3.6          1.4         0.2      0.0\n",
       "..           ...         ...          ...         ...      ...\n",
       "145          6.7         3.0          5.2         2.3      2.0\n",
       "146          6.3         2.5          5.0         1.9      2.0\n",
       "147          6.5         3.0          5.2         2.0      2.0\n",
       "148          6.2         3.4          5.4         2.3      2.0\n",
       "149          5.9         3.0          5.1         1.8      2.0\n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"https://raw.githubusercontent.com/guebin/DL2025/main/posts/iris.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b24169-dd82-4742-b244-bd43d4ecd075",
   "metadata": {},
   "source": [
    "위의 자료는 아이리스 데이터셋으로 머신러닝에서 자주 사용되는\n",
    "분류(classification) 예제 데이터이다. 데이터는 다음과 같은 특징을 가지고\n",
    "있다:\n",
    "\n",
    "**샘플 수: 150개**\n",
    "\n",
    "**특징 수: 4개**\n",
    "\n",
    "-   꽃받침 길이 (sepal length)\n",
    "-   꽃받침 너비 (sepal width)\n",
    "-   꽃잎 길이 (petal length)\n",
    "-   꽃잎 너비 (petal width)\n",
    "\n",
    "**클래스 수: 3개 (각 50개 샘플)**\n",
    "\n",
    "-   0: setosa\n",
    "-   1: versicolor\n",
    "-   2: virginica\n",
    "\n",
    "`(1)` 주어진 데이터를 8:2 비율로 학습용(df_train)과\n",
    "테스트용(df_test)으로 나누고, SepalLength, SepalWidth, PetalLength,\n",
    "PetalWidth를 입력으로 하여 Species를 예측할 수 있도록 데이터를 텐서\n",
    "형태로 변환하라.\n",
    "\n",
    "hint: 아래의 코드를 활용할 것\n",
    "\n",
    "``` python\n",
    "df_train = df.sample(frac=0.8, random_state=42)\n",
    "df_test = df.drop(df_train.index)\n",
    "#---#\n",
    "X = torch.tensor(df_train.iloc[:,:4].values).float()\n",
    "y = ???\n",
    "XX = ???\n",
    "yy = ???\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04673f4f-4d7e-400b-91af-a448d43692ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df.sample(frac=0.8, random_state=42)\n",
    "df_test = df.drop(df_train.index)\n",
    "#---#\n",
    "X = torch.tensor(df_train.iloc[:,:4].values).float()\n",
    "y = torch.nn.functional.one_hot(torch.tensor(df_train.Species.values).int().long()).float()\n",
    "XX = torch.tensor(df_test.iloc[:,:4].values).float()\n",
    "yy = torch.nn.functional.one_hot(torch.tensor(df_test.Species.values).int().long()).float()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2832d1df-7c9e-4086-91f1-376f91fde226",
   "metadata": {},
   "source": [
    "`(2)` 아래의 제약사항에 맞추어 Species를 예측할 수 있는 적당한\n",
    "네트워크를 학습하라.\n",
    "\n",
    "**제약사항**\n",
    "\n",
    "-   학습가능한 파라메터는 1층만 설계할 것\n",
    "-   학습 후 test accuracy 가 70% 이상일것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d041862-0d69-45bc-adc1-9215592565c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoc : 0,\ttrain acc = 0.3167\n",
      "epoc : 50,\ttrain acc = 0.7417\n",
      "epoc : 100,\ttrain acc = 0.8250\n",
      "epoc : 150,\ttrain acc = 0.9167\n",
      "epoc : 200,\ttrain acc = 0.9250\n",
      "epoc : 250,\ttrain acc = 0.9417\n",
      "epoc : 300,\ttrain acc = 0.9500\n",
      "epoc : 350,\ttrain acc = 0.9583\n",
      "epoc : 400,\ttrain acc = 0.9583\n",
      "epoc : 450,\ttrain acc = 0.9583\n"
     ]
    }
   ],
   "source": [
    "net = torch.nn.Sequential(\n",
    "    torch.nn.Linear(4, 3) ## 레이어 한개\n",
    ")\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizr = torch.optim.Adam(net.parameters(), lr = 0.01)\n",
    "\n",
    "##--##\n",
    "for epoc in range(500) :\n",
    "    net.train()\n",
    "    netout = net(X)\n",
    "    loss = loss_fn(netout, y)\n",
    "    loss.backward()\n",
    "    optimizr.step()\n",
    "    optimizr.zero_grad()\n",
    "\n",
    "    if epoc % 50 == 0 :\n",
    "        net.eval()\n",
    "        acc = (net(X).argmax(axis = 1) == y.argmax(axis = 1)).float().mean().item()\n",
    "        print(f\"epoc : {epoc},\\ttrain acc = {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42706db3-afc4-4422-bf34-4f3dc5bbebaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test acc = 0.9667\n"
     ]
    }
   ],
   "source": [
    "acc = (net(XX).argmax(axis = 1) == yy.argmax(axis = 1)).float().mean().item()\n",
    "print(f\"test acc = {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78107d4c-0fbb-4d67-8281-2e20232cf40a",
   "metadata": {},
   "source": [
    "> ?????? 이게 말이 됨??? -> 애초에 선형 분류문제였던 것 같음..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be419460-d1d9-4aa7-94b1-397e8fd54eb6",
   "metadata": {},
   "source": [
    "`(3)` 아래의 제약사항에 맞추어 Species를 예측할 수 있는 적당한\n",
    "네트워크를 학습하라.\n",
    "\n",
    "**제약사항**\n",
    "\n",
    "-   학습가능한 파라메터는 1층만 설계할 것\n",
    "-   학습 후 test accuracy 가 70% 이상일것\n",
    "-   train/test에서 모두 `batch_size = 10` 으로 설정할 것\n",
    "-   GPU를 사용할 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "15c8b5bb-51db-4eee-8a69-fe3faf9acf9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0,\ttrain_acc = 0.3583\n",
      "epoch : 5,\ttrain_acc = 0.9333\n",
      "epoch : 10,\ttrain_acc = 0.9417\n",
      "epoch : 15,\ttrain_acc = 0.9167\n",
      "epoch : 20,\ttrain_acc = 0.9250\n",
      "epoch : 25,\ttrain_acc = 0.9083\n",
      "epoch : 30,\ttrain_acc = 0.9583\n",
      "epoch : 35,\ttrain_acc = 0.9500\n",
      "epoch : 40,\ttrain_acc = 0.9667\n",
      "epoch : 45,\ttrain_acc = 0.9667\n"
     ]
    }
   ],
   "source": [
    "## data\n",
    "ds_train = torch.utils.data.TensorDataset(X, y)\n",
    "dl_train = torch.utils.data.DataLoader(ds_train, batch_size = 10, shuffle = True)\n",
    "\n",
    "ds_test = torch.utils.data.TensorDataset(XX, yy)\n",
    "dl_test = torch.utils.data.DataLoader(ds_test, batch_size = 10, shuffle = True)\n",
    "\n",
    "## network\n",
    "net = torch.nn.Sequential(\n",
    "    torch.nn.Linear(4, 3) ## 레이어 한개\n",
    ").to(\"cuda:0\")\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizr = torch.optim.Adam(net.parameters(), lr = 0.01)\n",
    "\n",
    "##--##\n",
    "for epoc in range(50) :\n",
    "    net.train()\n",
    "\n",
    "    for Xm, ym in dl_train :\n",
    "        Xm = Xm.to(\"cuda:0\")\n",
    "        ym = ym.to(\"cuda:0\")\n",
    "        \n",
    "        netout = net(Xm)\n",
    "        loss = loss_fn(netout, ym)\n",
    "        loss.backward()\n",
    "        optimizr.step()\n",
    "        optimizr.zero_grad()\n",
    "\n",
    "    if epoc % 5 == 0 :\n",
    "        net.eval()\n",
    "\n",
    "        s = 0\n",
    "        \n",
    "        for Xm, ym in dl_train :\n",
    "            Xm = Xm.to(\"cuda:0\")\n",
    "            ym = ym.to(\"cuda:0\")\n",
    "            s += (net(Xm).argmax(axis = 1) == ym.argmax(axis = 1)).sum().item()\n",
    "\n",
    "        acc = s/len(y)\n",
    "        print(f\"epoch : {epoc},\\ttrain_acc = {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6eb38fdc-83fa-485c-bc97-ceccb1b8eee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc = 0.9667\n"
     ]
    }
   ],
   "source": [
    "s = 0\n",
    "\n",
    "for XXm, yym in dl_test :\n",
    "    XXm = XXm.to(\"cuda:0\")\n",
    "    yym = yym.to(\"cuda:0\")\n",
    "\n",
    "    s += (net(XXm).argmax(axis = 1) == yym.argmax(axis = 1)).sum()\n",
    "\n",
    "acc = s/len(yy)\n",
    "print(f\"test_acc = {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1984523f-d1b7-4dc2-a38d-9fcb7b135416",
   "metadata": {},
   "source": [
    "`(4)` 아래의 제약사항에 맞추어 Species를 예측할 수 있는 적당한\n",
    "네트워크를 학습하라.\n",
    "\n",
    "**제약사항**\n",
    "\n",
    "-   학습가능한 파라메터는 1층만 설계할 것\n",
    "-   학습 후 test accuracy 가 70% 이상일 것\n",
    "-   train에서 `batch_size = 50` 으로, test에서는 `batch_size=30`을\n",
    "    설정할것\n",
    "-   GPU를 사용할 것\n",
    "-   매 epoch마다 loss와 train accuracy를 출력할 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c8330c4f-932d-4350-bc16-d43c00b5e1e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0,\tloss = 1.8602,\ttrain_acc = 0.3250\n",
      "epoch : 1,\tloss = 2.1620,\ttrain_acc = 0.3083\n",
      "epoch : 2,\tloss = 1.6821,\ttrain_acc = 0.2167\n",
      "epoch : 3,\tloss = 2.1459,\ttrain_acc = 0.2833\n",
      "epoch : 4,\tloss = 1.1585,\ttrain_acc = 0.2833\n",
      "epoch : 5,\tloss = 1.2899,\ttrain_acc = 0.2833\n",
      "epoch : 6,\tloss = 1.2899,\ttrain_acc = 0.2917\n",
      "epoch : 7,\tloss = 1.1892,\ttrain_acc = 0.2833\n",
      "epoch : 8,\tloss = 1.1405,\ttrain_acc = 0.2500\n",
      "epoch : 9,\tloss = 1.0963,\ttrain_acc = 0.3000\n",
      "epoch : 10,\tloss = 1.0746,\ttrain_acc = 0.5333\n",
      "epoch : 11,\tloss = 1.0237,\ttrain_acc = 0.6167\n",
      "epoch : 12,\tloss = 0.9573,\ttrain_acc = 0.7333\n",
      "epoch : 13,\tloss = 0.9723,\ttrain_acc = 0.7583\n",
      "epoch : 14,\tloss = 0.8908,\ttrain_acc = 0.7917\n",
      "epoch : 15,\tloss = 0.8238,\ttrain_acc = 0.7917\n",
      "epoch : 16,\tloss = 0.7907,\ttrain_acc = 0.7333\n",
      "epoch : 17,\tloss = 0.7691,\ttrain_acc = 0.6833\n",
      "epoch : 18,\tloss = 0.7404,\ttrain_acc = 0.6750\n",
      "epoch : 19,\tloss = 0.6843,\ttrain_acc = 0.6750\n",
      "epoch : 20,\tloss = 0.7209,\ttrain_acc = 0.6750\n",
      "epoch : 21,\tloss = 0.6936,\ttrain_acc = 0.6833\n",
      "epoch : 22,\tloss = 0.7371,\ttrain_acc = 0.7583\n",
      "epoch : 23,\tloss = 0.7052,\ttrain_acc = 0.8167\n",
      "epoch : 24,\tloss = 0.6695,\ttrain_acc = 0.9083\n",
      "epoch : 25,\tloss = 0.6297,\ttrain_acc = 0.9167\n",
      "epoch : 26,\tloss = 0.6317,\ttrain_acc = 0.9000\n",
      "epoch : 27,\tloss = 0.6766,\ttrain_acc = 0.7583\n",
      "epoch : 28,\tloss = 0.5885,\ttrain_acc = 0.7500\n",
      "epoch : 29,\tloss = 0.6485,\ttrain_acc = 0.7500\n",
      "epoch : 30,\tloss = 0.5033,\ttrain_acc = 0.7667\n",
      "epoch : 31,\tloss = 0.5978,\ttrain_acc = 0.7750\n",
      "epoch : 32,\tloss = 0.5321,\ttrain_acc = 0.8083\n",
      "epoch : 33,\tloss = 0.5746,\ttrain_acc = 0.8250\n",
      "epoch : 34,\tloss = 0.6602,\ttrain_acc = 0.8333\n",
      "epoch : 35,\tloss = 0.6058,\ttrain_acc = 0.8750\n",
      "epoch : 36,\tloss = 0.5083,\ttrain_acc = 0.9417\n",
      "epoch : 37,\tloss = 0.4958,\ttrain_acc = 0.9417\n",
      "epoch : 38,\tloss = 0.5500,\ttrain_acc = 0.9417\n",
      "epoch : 39,\tloss = 0.5488,\ttrain_acc = 0.9500\n",
      "epoch : 40,\tloss = 0.5390,\ttrain_acc = 0.9417\n",
      "epoch : 41,\tloss = 0.4963,\ttrain_acc = 0.8750\n",
      "epoch : 42,\tloss = 0.4805,\ttrain_acc = 0.8333\n",
      "epoch : 43,\tloss = 0.4976,\ttrain_acc = 0.8583\n",
      "epoch : 44,\tloss = 0.5624,\ttrain_acc = 0.8083\n",
      "epoch : 45,\tloss = 0.4919,\ttrain_acc = 0.8583\n",
      "epoch : 46,\tloss = 0.5219,\ttrain_acc = 0.8750\n",
      "epoch : 47,\tloss = 0.4460,\ttrain_acc = 0.9333\n",
      "epoch : 48,\tloss = 0.4718,\ttrain_acc = 0.9500\n",
      "epoch : 49,\tloss = 0.4635,\ttrain_acc = 0.9500\n"
     ]
    }
   ],
   "source": [
    "## data\n",
    "ds_train = torch.utils.data.TensorDataset(X, y)\n",
    "dl_train = torch.utils.data.DataLoader(ds_train, batch_size = 50, shuffle = True)\n",
    "\n",
    "ds_test = torch.utils.data.TensorDataset(XX, yy)\n",
    "dl_test = torch.utils.data.DataLoader(ds_test, batch_size = 30, shuffle = True)\n",
    "\n",
    "## network\n",
    "net = torch.nn.Sequential(\n",
    "    torch.nn.Linear(4, 3) ## 레이어 한개\n",
    ").to(\"cuda:0\")\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizr = torch.optim.Adam(net.parameters(), lr = 0.01)\n",
    "\n",
    "##--##\n",
    "for epoc in range(50) :\n",
    "    net.train()\n",
    "\n",
    "    for Xm, ym in dl_train :\n",
    "        Xm = Xm.to(\"cuda:0\")\n",
    "        ym = ym.to(\"cuda:0\")\n",
    "        \n",
    "        netout = net(Xm)\n",
    "        loss = loss_fn(netout, ym)\n",
    "        loss.backward()\n",
    "        optimizr.step()\n",
    "        optimizr.zero_grad()\n",
    "\n",
    "    net.eval()\n",
    "\n",
    "    s = 0\n",
    "    \n",
    "    for Xm, ym in dl_train :\n",
    "        Xm = Xm.to(\"cuda:0\")\n",
    "        ym = ym.to(\"cuda:0\")\n",
    "        s += (net(Xm).argmax(axis = 1) == ym.argmax(axis = 1)).sum().item()\n",
    "\n",
    "    acc = s/len(y)\n",
    "    print(f\"epoch : {epoc},\\tloss = {loss:.4f},\\ttrain_acc = {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3d5dad64-003a-46cc-b22f-1e5fe8d7263c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc = 0.9667\n"
     ]
    }
   ],
   "source": [
    "s = 0\n",
    "\n",
    "for XXm, yym in dl_test :\n",
    "    XXm = XXm.to(\"cuda:0\")\n",
    "    yym = yym.to(\"cuda:0\")\n",
    "\n",
    "    s += (net(XXm).argmax(axis = 1) == yym.argmax(axis = 1)).sum()\n",
    "\n",
    "acc = s/len(yy)\n",
    "print(f\"test_acc = {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005e42dd-9d90-4402-82a8-78142da335ff",
   "metadata": {},
   "source": [
    "`(5)` 아래의 제약사항에 맞추어 Species를 예측할 수 있는 적당한\n",
    "네트워크를 학습하라.\n",
    "\n",
    "**제약사항**\n",
    "\n",
    "-   학습가능한 파라메터는 2층이상 설계할 것\n",
    "-   드랍아웃을 포함시킬 것\n",
    "-   학습 후 test accuracy 가 70% 이상일 것\n",
    "-   train에서 `batch_size = 50` 으로, test에서는 `batch_size=30`을\n",
    "    설정할것\n",
    "-   GPU를 사용할 것\n",
    "-   매 epoch마다 loss와 train accuracy를 출력할 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6af38d9e-5f32-4fe9-bb6b-abfd0c5567b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0,\tloss = 5.2917,\ttrain_acc = 0.6750\n",
      "epoch : 1,\tloss = 2.6907,\ttrain_acc = 0.3750\n",
      "epoch : 2,\tloss = 1.2877,\ttrain_acc = 0.6750\n",
      "epoch : 3,\tloss = 0.1650,\ttrain_acc = 0.8917\n",
      "epoch : 4,\tloss = 0.6500,\ttrain_acc = 0.7667\n",
      "epoch : 5,\tloss = 0.4570,\ttrain_acc = 0.7167\n",
      "epoch : 6,\tloss = 0.0911,\ttrain_acc = 0.9083\n",
      "epoch : 7,\tloss = 0.1824,\ttrain_acc = 0.9250\n",
      "epoch : 8,\tloss = 0.1707,\ttrain_acc = 0.8583\n",
      "epoch : 9,\tloss = 0.2091,\ttrain_acc = 0.9750\n",
      "epoch : 10,\tloss = 0.1088,\ttrain_acc = 0.9000\n",
      "epoch : 11,\tloss = 0.1407,\ttrain_acc = 0.9417\n",
      "epoch : 12,\tloss = 0.3887,\ttrain_acc = 0.9417\n",
      "epoch : 13,\tloss = 0.1715,\ttrain_acc = 0.9083\n",
      "epoch : 14,\tloss = 0.1626,\ttrain_acc = 0.9667\n",
      "epoch : 15,\tloss = 0.1006,\ttrain_acc = 0.9417\n",
      "epoch : 16,\tloss = 0.1631,\ttrain_acc = 0.9833\n",
      "epoch : 17,\tloss = 0.0529,\ttrain_acc = 0.9750\n",
      "epoch : 18,\tloss = 0.0355,\ttrain_acc = 0.9750\n",
      "epoch : 19,\tloss = 0.1224,\ttrain_acc = 0.9833\n"
     ]
    }
   ],
   "source": [
    "## data\n",
    "ds_train = torch.utils.data.TensorDataset(X, y)\n",
    "dl_train = torch.utils.data.DataLoader(ds_train, batch_size = 50, shuffle = True)\n",
    "\n",
    "ds_test = torch.utils.data.TensorDataset(XX, yy)\n",
    "dl_test = torch.utils.data.DataLoader(ds_test, batch_size = 30, shuffle = True)\n",
    "\n",
    "## network\n",
    "net = torch.nn.Sequential(\n",
    "    torch.nn.Linear(4, 1024),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Dropout(0.5),\n",
    "    torch.nn.Linear(1024, 3)\n",
    ").to(\"cuda:0\")\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizr = torch.optim.Adam(net.parameters(), lr = 0.01)\n",
    "\n",
    "##--##\n",
    "for epoc in range(20) :\n",
    "    net.train()\n",
    "\n",
    "    for Xm, ym in dl_train :\n",
    "        Xm = Xm.to(\"cuda:0\")\n",
    "        ym = ym.to(\"cuda:0\")\n",
    "        \n",
    "        netout = net(Xm)\n",
    "        loss = loss_fn(netout, ym)\n",
    "        loss.backward()\n",
    "        optimizr.step()\n",
    "        optimizr.zero_grad()\n",
    "\n",
    "    net.eval()\n",
    "\n",
    "    s = 0\n",
    "    \n",
    "    for Xm, ym in dl_train :\n",
    "        Xm = Xm.to(\"cuda:0\")\n",
    "        ym = ym.to(\"cuda:0\")\n",
    "        s += (net(Xm).argmax(axis = 1) == ym.argmax(axis = 1)).sum().item()\n",
    "\n",
    "    acc = s/len(y)\n",
    "    print(f\"epoch : {epoc},\\tloss = {loss:.4f},\\ttrain_acc = {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b6b508a2-4f6c-4128-8e60-428f679d755f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc = 0.9667\n"
     ]
    }
   ],
   "source": [
    "s = 0\n",
    "\n",
    "for XXm, yym in dl_test :\n",
    "    XXm = XXm.to(\"cuda:0\")\n",
    "    yym = yym.to(\"cuda:0\")\n",
    "\n",
    "    s += (net(XXm).argmax(axis = 1) == yym.argmax(axis = 1)).sum()\n",
    "\n",
    "acc = s/len(yy)\n",
    "print(f\"test_acc = {acc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
