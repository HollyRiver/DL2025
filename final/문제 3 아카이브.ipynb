{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7a83be6-7501-4817-8281-94349664bfe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce36ccc-3598-41b1-8454-69175af51f24",
   "metadata": {},
   "source": [
    "# 3. `Human_Numbers`\n",
    "\n",
    "`HUMAN_NUMBERS_train.txt` 사람이 읽을 수 있는 형식으로 숫자가 나열된\n",
    "텍스트 파일이다. 이 텍스트 파일을 이용하여 “현재 단어가 주어졌을 때 다음\n",
    "단어를 예측하는” 신경망을 설계하고 학습시킬 것이다. 아래는 해당 파일을\n",
    "불러와 단어 단위로 나눈 결과를 확인하는 코드이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e03d605-86e2-4662-b09a-ee03922e0102",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['seven', 'thousand', 'nine', 'hundred', 'ninety', 'eight', 'seven', 'thousand', 'nine', 'hundred', 'ninety', 'nine']\n"
     ]
    }
   ],
   "source": [
    "with open('HUMAN_NUMBERS_train.txt') as f:\n",
    "    words = f.read().split()\n",
    "print(words[-12:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95dcb808-671e-4474-b67c-3c20ca8f8d54",
   "metadata": {},
   "source": [
    "이 텍스트 파일에는 예를 들어 “… seven, thousand, nine, hundred, ninety,\n",
    "eight, …” 등과 같은 사람이 읽는 숫자 표현이 단어 단위로 나열된 시퀀스\n",
    "형태로 저장되어 있다.\n",
    "\n",
    "이러한 데이터에서 “현재 단어가 주어졌을 때 다음 단어를 예측하는” 자연어\n",
    "처리 모델을 학습하라. 즉 아래와 같은 맵핑을 학습하라.\n",
    "\n",
    "-   … seven, thousand, nine, hundred, ninety, eight $\\to$ seven\n",
    "-   … seven, thousand, nine, hundred, ninety, eight, seven $\\to$\n",
    "    thousand\n",
    "-   … seven, thousand, nine, hundred, ninety, eight, seven, thousand\n",
    "    $\\to$ nine\n",
    "\n",
    "**제약사항**\n",
    "\n",
    "-   one-hot 전처리 코드를 포함할 것\n",
    "-   `torch.nn.RNN`, `torch.nn.RNNCell`, `torch.nn.LSTM` 중 하나를 이용할\n",
    "    것\n",
    "-   처음 12개의 단어와 마지막 12개의 단어에 대한 적합값(fitted value)을\n",
    "    제시할 것"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5daf8cbc-3312-4fe9-8b17-07bcebff33bd",
   "metadata": {},
   "source": [
    "`(풀이)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794c6231-cb04-443b-bdc5-3687f0864578",
   "metadata": {},
   "source": [
    "`-` 데이터 불러오기 및 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e066ad60-8fe0-48b3-aae0-94a41614e9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('HUMAN_NUMBERS_train.txt') as f:\n",
    "    words = f.read().split()\n",
    "words[:10]\n",
    "df_train = pd.DataFrame({'x': words[:-1], 'y': words[1:]})\n",
    "\n",
    "# 전체 vocab 기준으로 맵핑\n",
    "vocab = sorted(set(words))\n",
    "dct= {w: i for i, w in enumerate(vocab)}\n",
    "# train 데이터셋\n",
    "x = torch.tensor(df_train.x.map(dct))\n",
    "y = torch.tensor(df_train.y.map(dct))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b6f9e6a-912d-4771-baae-5716ba2fd69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot 전처리\n",
    "X = torch.nn.functional.one_hot(x).float()\n",
    "y = torch.nn.functional.one_hot(y).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "195b1a09-069b-479d-b631-64a16c636393",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('HUMAN_NUMBERS_valid.txt') as f:\n",
    "    words = f.read().split()\n",
    "words[:10]\n",
    "df_valid = pd.DataFrame({'x': words[:-1], 'y': words[1:]})\n",
    "\n",
    "# valid 데이터셋\n",
    "xx = torch.tensor(df_valid.x.map(dct))\n",
    "yy = torch.tensor(df_valid.y.map(dct))\n",
    "\n",
    "# one-hot 전처리\n",
    "XX = torch.nn.functional.one_hot(xx).float()\n",
    "yy = torch.nn.functional.one_hot(yy).float()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802e4709-5b0e-4059-9822-ae7cbacdfee8",
   "metadata": {},
   "source": [
    "`-` 모형 적합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5787bc66-f3d2-4b86-b987-5ea21e38f3fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 100\ttrain acc = 0.1711\tvalid acc = 0.1636\n",
      "epoch : 200\ttrain acc = 0.3613\tvalid acc = 0.3514\n",
      "epoch : 300\ttrain acc = 0.3979\tvalid acc = 0.3623\n",
      "epoch : 400\ttrain acc = 0.4507\tvalid acc = 0.4012\n",
      "epoch : 500\ttrain acc = 0.5112\tvalid acc = 0.4119\n",
      "epoch : 600\ttrain acc = 0.6222\tvalid acc = 0.4485\n",
      "epoch : 700\ttrain acc = 0.7563\tvalid acc = 0.4909\n",
      "epoch : 800\ttrain acc = 0.8980\tvalid acc = 0.5305\n",
      "epoch : 900\ttrain acc = 0.9602\tvalid acc = 0.5478\n",
      "epoch : 1000\ttrain acc = 0.9810\tvalid acc = 0.5657\n",
      "epoch : 1100\ttrain acc = 0.9892\tvalid acc = 0.5855\n",
      "epoch : 1200\ttrain acc = 0.9929\tvalid acc = 0.5936\n"
     ]
    }
   ],
   "source": [
    "lstm = torch.nn.LSTM(29, 64)\n",
    "cook = torch.nn.Sequential(\n",
    "    torch.nn.Linear(64, 64),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(64, 29)\n",
    ")\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizr = torch.optim.Adam(list(lstm.parameters()) + list(cook.parameters()))\n",
    "\n",
    "#---#\n",
    "for epoc in range(1, 2001) :\n",
    "    cook.train()\n",
    "    h, _ = lstm(X)\n",
    "    netout = cook(h)\n",
    "\n",
    "    loss = loss_fn(netout, y)\n",
    "    loss.backward()\n",
    "\n",
    "    optimizr.step()\n",
    "    optimizr.zero_grad()\n",
    "\n",
    "    if epoc % 100 == 0 :\n",
    "        cook.eval()\n",
    "        h, _ = lstm(X)\n",
    "        hh, _ = lstm(XX)\n",
    "        yhat = torch.nn.functional.softmax(cook(h), dim = 1)\n",
    "        yyhat = torch.nn.functional.softmax(cook(hh), dim = 1)\n",
    "        acc = (yhat.argmax(axis = 1) == y.argmax(axis = 1)).float().mean().item()\n",
    "        valid_acc = (yyhat.argmax(axis = 1) == yy.argmax(axis = 1)).float().mean().item()\n",
    "        print(f\"epoch : {epoc}\\ttrain acc = {acc:.4f}\\tvalid acc = {valid_acc:.4f}\")\n",
    "\n",
    "        if acc > 0.992 :\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "535fc3fa-56af-4b06-a8d0-54dbf42695c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1300\ttrain acc = 0.9947\tvalid acc = 0.6014\n",
      "epoch : 1400\ttrain acc = 0.9962\tvalid acc = 0.6050\n",
      "epoch : 1500\ttrain acc = 0.9971\tvalid acc = 0.6069\n",
      "epoch : 1600\ttrain acc = 0.7265\tvalid acc = 0.5282\n",
      "epoch : 1700\ttrain acc = 0.9283\tvalid acc = 0.6413\n",
      "epoch : 1800\ttrain acc = 0.9725\tvalid acc = 0.6563\n",
      "epoch : 1900\ttrain acc = 0.9856\tvalid acc = 0.6564\n",
      "epoch : 2000\ttrain acc = 0.9903\tvalid acc = 0.6554\n",
      "epoch : 2100\ttrain acc = 0.9926\tvalid acc = 0.6544\n",
      "epoch : 2200\ttrain acc = 0.9941\tvalid acc = 0.6565\n",
      "epoch : 2300\ttrain acc = 0.9954\tvalid acc = 0.6559\n",
      "epoch : 2400\ttrain acc = 0.9961\tvalid acc = 0.6561\n",
      "epoch : 2500\ttrain acc = 0.9968\tvalid acc = 0.6556\n",
      "epoch : 2600\ttrain acc = 0.9976\tvalid acc = 0.6559\n",
      "epoch : 2700\ttrain acc = 0.9981\tvalid acc = 0.6556\n",
      "epoch : 2800\ttrain acc = 0.9984\tvalid acc = 0.6564\n",
      "epoch : 2900\ttrain acc = 0.9986\tvalid acc = 0.6578\n",
      "epoch : 3000\ttrain acc = 0.9989\tvalid acc = 0.6586\n"
     ]
    }
   ],
   "source": [
    "for epoc in range(1201, 3001) :\n",
    "    cook.train()\n",
    "    h, _ = lstm(X)\n",
    "    netout = cook(h)\n",
    "\n",
    "    loss = loss_fn(netout, y)\n",
    "    loss.backward()\n",
    "\n",
    "    optimizr.step()\n",
    "    optimizr.zero_grad()\n",
    "\n",
    "    if epoc % 100 == 0 :\n",
    "        cook.eval()\n",
    "        h, _ = lstm(X)\n",
    "        hh, _ = lstm(XX)\n",
    "        yhat = torch.nn.functional.softmax(cook(h), dim = 1)\n",
    "        yyhat = torch.nn.functional.softmax(cook(hh), dim = 1)\n",
    "        acc = (yhat.argmax(axis = 1) == y.argmax(axis = 1)).float().mean().item()\n",
    "        valid_acc = (yyhat.argmax(axis = 1) == yy.argmax(axis = 1)).float().mean().item()\n",
    "        print(f\"epoch : {epoc}\\ttrain acc = {acc:.4f}\\tvalid acc = {valid_acc:.4f}\")\n",
    "\n",
    "        if acc > 0.9999 :\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162dc98f-97ef-4289-8550-096780dba6ce",
   "metadata": {},
   "source": [
    "`-` 결과 제시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f62213a4-d988-46b2-97b9-9e893bfa950f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "처음 12개 단어 적합값 : tensor([ 6,  6, 18, 18, 18, 14, 27, 11,  6,  3, 26, 22])\n",
      "인덱스별 단어 변환 : ['five', 'five', 'six', 'six', 'six', 'one', 'twenty', 'nine', 'five', 'eleven', 'twelve', 'thirteen']\n",
      "---------------------------------------------------------------------------------\n",
      "마지막 12개 단어 적합값 : tensor([15, 24, 11, 10, 13,  0, 15, 24, 11, 10, 13, 11])\n",
      "인덱스별 단어 변환 : ['seven', 'thousand', 'nine', 'hundred', 'ninety', 'eight', 'seven', 'thousand', 'nine', 'hundred', 'ninety', 'nine']\n"
     ]
    }
   ],
   "source": [
    "inv_dct = {v:k for k, v in dct.items()}\n",
    "\n",
    "print(\n",
    "    f\"처음 12개 단어 적합값 : {yhat.argmax(axis = 1)[:12]}\\n\"\n",
    "    f\"인덱스별 단어 변환 : {[inv_dct[t.item()] for t in yhat.argmax(axis = 1)[:12]]}\\n\"\n",
    "    \"---------------------------------------------------------------------------------\\n\"\n",
    "    f\"마지막 12개 단어 적합값 : {yhat.argmax(axis = 1)[-12:]}\\n\"\n",
    "    f\"인덱스별 단어 변환 : {[inv_dct[t.item()] for t in yhat.argmax(axis = 1)[-12:]]}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b046e5d-3bef-4be3-9ebb-dddf1e0032f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
