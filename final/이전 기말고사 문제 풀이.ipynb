{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "60574de2-01b8-4e8c-9f40-a938ed2e3361",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77b42ac-4988-4c08-8357-28e707896430",
   "metadata": {},
   "source": [
    "## 1. hi?hello!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bff9c09b-2f98-4b5c-9c4c-864eab4ba5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = list('hi?hello!!')*100 \n",
    "txt_x = txt[:-1]\n",
    "txt_y = txt[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43721530-94f6-4734-9f6f-9d2a78b90056",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['h', 'i', '?', 'h', 'e'], ['i', '?', 'h', 'e', 'l'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt_x[:5], txt_y[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aac162f-e87e-4b37-91c2-d1277e718346",
   "metadata": {},
   "source": [
    "`txt_x`와 `txt_y`를 이용하여 아래와 같은 순서로 다음문자를 예측하고 싶은 신경망을 설계하고 싶다.\n",
    "\n",
    "`h` $\\to$ `i` $\\to$ `?` $\\to$ `h` $\\to$ `e` $\\to$ `l` $\\to$ `l` $\\to$ `o`\n",
    "$\\to$ `!` $\\to$ `!`\n",
    "$\\to$ `h` $\\to$ `i` $\\to$ `?` $\\to$ `h` $\\to$ `e` \n",
    " \n",
    "\n",
    "***(1)-(6)*** 의 풀이에 공통적으로 필요한 과정 정리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b054f0d4-c3ff-4122-bac9-fcbcf869ac92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(txt,mapping):\n",
    "    return [mapping[key] for key in txt] \n",
    "\n",
    "sig = torch.nn.Sigmoid()\n",
    "soft = torch.nn.Softmax(dim=1)\n",
    "tanh = torch.nn.Tanh()\n",
    "mapping = {'!':0, '?':1,'h':2,'i':3,'e':4,'l':5,'o':6} \n",
    "x= torch.nn.functional.one_hot(torch.tensor(f(txt_x,mapping))).float().to(\"cuda:0\")\n",
    "y= torch.nn.functional.one_hot(torch.tensor(f(txt_y,mapping))).float().to(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262b6eba-41ab-4356-8caa-15f3a8975ae3",
   "metadata": {},
   "source": [
    "`(1)` `torch.nn.RNN()`을 이용하여 다음 문자를 예측하는 신경망을 설계하고 학습하라."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "757e5dce-6488-4f9a-be19-299a0c6a9fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "rnn = torch.nn.RNN(7, 4).to(\"cuda:0\")\n",
    "cook = torch.nn.Linear(4, 7).to(\"cuda:0\")\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizr = torch.optim.Adam(list(rnn.parameters()) + list(cook.parameters()), lr = 0.1)\n",
    "\n",
    "#---#\n",
    "for epoc in range(100) :\n",
    "    h, _ = rnn(x)\n",
    "    netout = cook(h)\n",
    "    loss = loss_fn(netout, y)\n",
    "    loss.backward()\n",
    "    optimizr.step()\n",
    "    optimizr.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "cd43899d-689c-4519-9fb3-b6df67f28047",
   "metadata": {},
   "outputs": [],
   "source": [
    "h, _ = rnn(x)\n",
    "netout = cook(h)\n",
    "\n",
    "yhat = torch.nn.functional.softmax(netout, dim = 1).argmax(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "4b8634c9-59e1-4811-9a67-31e1a8caf165",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " '?',\n",
       " 'h',\n",
       " 'e',\n",
       " 'l',\n",
       " 'l',\n",
       " 'o',\n",
       " '!',\n",
       " '!',\n",
       " 'h',\n",
       " 'i',\n",
       " '?',\n",
       " 'h',\n",
       " 'e',\n",
       " 'l',\n",
       " 'l',\n",
       " 'o',\n",
       " '!',\n",
       " '!',\n",
       " 'h']"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_mapping = {v:k for v, k in zip(mapping.values(), mapping.keys())}\n",
    "[inv_mapping[i.item()] for i in yhat][:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "039ff23f-4e83-4281-8e46-c72c936ebb4d",
   "metadata": {},
   "source": [
    "`(2)` `torch.nn.RNNCell()`을 이용하여 다음 문자를 예측하는 신경망을 설계하고 학습하라."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "de4cad25-1f78-4586-947e-85869ac2274c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "rnncell = torch.nn.RNNCell(7, 4).to(\"cuda:0\")\n",
    "linr = torch.nn.Linear(4, 7).to(\"cuda:0\")\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizr = torch.optim.Adam(list(rnncell.parameters()) + list(linr.parameters()), lr = 0.1)\n",
    "\n",
    "#---#\n",
    "L = len(x)\n",
    "for epoc in range(100) :\n",
    "    ht = torch.zeros(4).to(\"cuda:0\")\n",
    "    loss = 0\n",
    "\n",
    "    for t in range(L) :\n",
    "        ht = rnncell(x[t], ht)\n",
    "        ot = linr(ht)\n",
    "        \n",
    "        loss += loss_fn(ot, y[t])\n",
    "\n",
    "    loss = loss/L\n",
    "    loss.backward()\n",
    "    \n",
    "    optimizr.step()\n",
    "    optimizr.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "e2ee88f9-0d12-4f08-963c-8bc90496b847",
   "metadata": {},
   "outputs": [],
   "source": [
    "h = torch.zeros((L, 4)).to(\"cuda:0\")\n",
    "h0 = torch.zeros(4).to(\"cuda:0\")\n",
    "h[0] = rnncell(x[0], h0)\n",
    "\n",
    "for t in range(1, L) :\n",
    "    h[t] = rnncell(x[t], h[t-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "2367de1d-a283-45b3-a2b7-7057de88a6a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[9.8811e-04, 4.8676e-05, 5.8596e-03,  ..., 6.1763e-02, 5.9356e-03,\n",
       "         5.9702e-05],\n",
       "        [1.4041e-02, 9.7211e-01, 2.4805e-04,  ..., 8.9972e-10, 1.3568e-02,\n",
       "         2.0693e-06],\n",
       "        [5.0399e-06, 3.7461e-04, 9.9567e-01,  ..., 6.5292e-04, 7.9580e-05,\n",
       "         2.6547e-03],\n",
       "        ...,\n",
       "        [4.7723e-03, 2.3609e-06, 2.5208e-04,  ..., 2.0636e-03, 2.9616e-04,\n",
       "         9.9261e-01],\n",
       "        [9.9584e-01, 3.5457e-04, 5.0169e-05,  ..., 1.5502e-06, 1.3792e-04,\n",
       "         3.6100e-03],\n",
       "        [9.9120e-01, 4.4400e-03, 2.6194e-03,  ..., 7.3197e-07, 1.7851e-05,\n",
       "         1.6988e-03]], device='cuda:0', grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat = soft(linr(h))\n",
    "yhat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51297cee-4551-4355-b492-0cadf056fe45",
   "metadata": {},
   "source": [
    "`(3)` `torch.nn.Module`을 상속받은 클래스를 정의하고 (2)의 결과와 동일한 적합값이 나오는 신경망을 설계한 뒤 학습하라. (초기값을 적절하게 설정할 것)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "519ae8a4-ef74-49ff-b0a6-812549a773a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class rNNCell(torch.nn.Module) :\n",
    "    def __init__(self) :\n",
    "        super().__init__()\n",
    "        self.i2h = torch.nn.Linear(7, 4)\n",
    "        self.h2h = torch.nn.Linear(4, 4)\n",
    "        self.tanh = torch.nn.Tanh()\n",
    "\n",
    "    def forward(self, xt, ht) :\n",
    "        ht = self.tanh(self.i2h(xt) + self.h2h(ht))\n",
    "\n",
    "        return ht"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "bda3ebba-a4ab-4cb5-8e39-30b5568d3818",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "rnncell = torch.nn.RNNCell(7, 4).to(\"cuda:0\")\n",
    "linr = torch.nn.Linear(4, 7).to(\"cuda:0\")\n",
    "\n",
    "rnncell2 = rNNCell()\n",
    "rnncell2.i2h.weight.data = rnncell.weight_ih.data\n",
    "rnncell2.h2h.weight.data = rnncell.weight_hh.data\n",
    "rnncell2.i2h.bias.data = rnncell.bias_ih.data\n",
    "rnncell2.h2h.bias.data = rnncell.bias_hh.data\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizr = torch.optim.Adam(list(rnncell2.parameters()) + list(linr.parameters()), lr = 0.1)\n",
    "\n",
    "#---#\n",
    "L = len(x)\n",
    "for epoc in range(100) :\n",
    "    ht = torch.zeros(4).to(\"cuda:0\")\n",
    "    loss = 0\n",
    "\n",
    "    for t in range(L) :\n",
    "        ht = rnncell(x[t], ht)\n",
    "        ot = linr(ht)\n",
    "        \n",
    "        loss += loss_fn(ot, y[t])\n",
    "\n",
    "    loss = loss/L\n",
    "    loss.backward()\n",
    "    \n",
    "    optimizr.step()\n",
    "    optimizr.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "a990c8b6-ce5d-4759-8eac-71068bd6a161",
   "metadata": {},
   "outputs": [],
   "source": [
    "h = torch.zeros((L, 4)).to(\"cuda:0\")\n",
    "h0 = torch.zeros(4).to(\"cuda:0\")\n",
    "h[0] = rnncell(x[0], h0)\n",
    "\n",
    "for t in range(1, L) :\n",
    "    h[t] = rnncell(x[t], h[t-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "9682ff00-601d-40e7-93d5-9aad9aebe9fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4.0261e-02, 4.3250e-05, 1.4219e-04,  ..., 4.2759e-01, 4.0815e-02,\n",
       "         1.8438e-03],\n",
       "        [4.0991e-02, 7.0688e-01, 6.0200e-02,  ..., 9.9645e-05, 1.8883e-01,\n",
       "         5.9180e-04],\n",
       "        [5.3898e-02, 1.1380e-01, 6.0440e-01,  ..., 5.8943e-04, 1.3457e-01,\n",
       "         9.1508e-02],\n",
       "        ...,\n",
       "        [1.3807e-01, 2.1008e-03, 1.7078e-01,  ..., 1.5848e-02, 3.9910e-02,\n",
       "         6.2809e-01],\n",
       "        [8.9304e-01, 1.6627e-04, 4.7126e-04,  ..., 7.7563e-03, 8.3060e-02,\n",
       "         1.4001e-02],\n",
       "        [6.5835e-01, 1.3594e-02, 2.2517e-01,  ..., 1.0799e-02, 1.4963e-02,\n",
       "         5.3452e-02]], device='cuda:0', grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat = soft(linr(h))\n",
    "yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "ea8176fe-4a51-44fc-a0e4-b218d56522b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "n1 = torch.nn.Embedding(2, 1)\n",
    "n2 = torch.nn.Linear(1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0131c24d-a401-4346-a96b-10d73daf7c92",
   "metadata": {},
   "source": [
    "## 2. O/X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef427b3-eb0b-4dc1-83af-beab57d4fc1f",
   "metadata": {},
   "source": [
    "(1) LSTM은 RNN보다 장기기억에 유리하다. (True)\n",
    "\n",
    "(2) torch.nn.Embedding(num_embeddings=2,embedding_dim=1)와 torch.nn.Linear(in_features=1,out_features=1)의 학습가능한 파라메터수는 같다. (True)\n",
    "\n",
    "(3) 아래와 같은 네트워크를 고려하자.\n",
    "\n",
    "net = torch.nn.Linear(1,1)\n",
    "\n",
    "차원이 (n,1) 인 임의의 텐서에 대하여 net(x)와 net.forward(x)의 출력결과는 같다. (True)\n",
    "\n",
    "(4) 아래와 같이 a,b,c,d 가 반복되는 문자열이 반복되는 자료에서 다음문자열을 맞추는 과업을 수행하기 위해서는 반드시 순환신경망의 형태로 설계해야만 한다. (False) –> 오타로인하여 문제삭제\n",
    "\n",
    "a,b,c,d,a,b,c,d,...\n",
    "(5) RNN 혹은 LSTM 으로 신경망을 설계할 시 손실함수는 항상 torch.nn.CrossEntropyLoss 를 사용해야 한다. (False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44cc5fe2-6ede-422c-878d-190bd483d013",
   "metadata": {},
   "source": [
    "(1) Dropout Layer를 추가하면 layer의 추가로 인해 모형이 더 복잡해지며 그 결과 모형이 과적합될 수 있다.\n",
    "\n",
    "(2) CNN에서 torch.nn.Conv2d() 로 만들어지는 레이어는 입력이미지의 특징을 추출하는 역할을 하며, 훈련과정에서 학습되지 않는다.\n",
    "\n",
    "(3) MF-based 추천 시스템에서는 사용자의 성향과 항목의 성향을 내적하여 궁합을 계산한다.\n",
    "\n",
    "(4) LSTM은 RNN과 비교할때 장기기억에 강점을 보인다.\n",
    "\n",
    "(5) 강화 학습에서 에이전트가 현재 상태에서 취하는 행동은 ’리워드(Reward)’라고 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64985043-5d4e-447a-a9ed-db4092f12269",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
