{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d0e48fb4-93b1-4543-a2d3-67779b84bc03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "#---#\n",
    "import numpy as np\n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "import IPython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "c650b394-ca7e-4840-8be1-255d8a1f89dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GridWorld :\n",
    "    def __init__(self) :\n",
    "        self.a2d = {\n",
    "            0: np.array([0,1]),  # →\n",
    "            1: np.array([0,-1]), # ←  \n",
    "            2: np.array([1,0]),  # ↓\n",
    "            3: np.array([-1,0])  # ↑\n",
    "        }\n",
    "\n",
    "        self.states_space = gym.spaces.MultiDiscrete([4, 4])\n",
    "        self.state = np.array([0, 0])\n",
    "        self.reward = None\n",
    "        self.terminated = False\n",
    "\n",
    "    def step(self, action) :\n",
    "        self.state = self.state + self.a2d[action] ## 여기서 깊은복사 이슈 나는듯\n",
    "        s1, s2 = self.state\n",
    "\n",
    "        if (s1 == 3) and (s2 == 3) :\n",
    "            self.reward = 100\n",
    "            self.terminated = True\n",
    "        \n",
    "        elif self.state in self.states_space :\n",
    "            self.reward = -1\n",
    "\n",
    "        else :\n",
    "            self.reward = -10\n",
    "            self.terminated = True\n",
    "\n",
    "        return self.state, self.reward, self.terminated\n",
    "\n",
    "    def reset(self) :\n",
    "        self.state = np.array([0, 0])\n",
    "        self.terminated = False\n",
    "        \n",
    "        return self.state\n",
    "\n",
    "\n",
    "class RandomAgent :\n",
    "    def __init__(self) :\n",
    "        self.state = np.array([0, 0])\n",
    "        self.action = None\n",
    "        self.reward = None\n",
    "        self.next_state = None\n",
    "        self.terminated = None\n",
    "\n",
    "        self.states = collections.deque(maxlen = 500000)\n",
    "        self.actions = collections.deque(maxlen = 500000)\n",
    "        self.rewards = collections.deque(maxlen = 500000)\n",
    "        self.next_states = collections.deque(maxlen = 500000)\n",
    "        self.terminations = collections.deque(maxlen = 500000)\n",
    "\n",
    "        self.action_space = gym.spaces.Discrete(4)\n",
    "        self.n_experience = 0\n",
    "\n",
    "    def act(self) :\n",
    "        \"\"\"\n",
    "        Before Learning : Random Action\n",
    "        \"\"\"\n",
    "        self.action = self.action_space.sample()\n",
    "\n",
    "    def save_experience(self) :\n",
    "        self.states.append(self.state)\n",
    "        self.actions.append(self.action)\n",
    "        self.rewards.append(self.reward)\n",
    "        self.next_states.append(self.next_state)\n",
    "        self.terminations.append(self.terminated)\n",
    "        self.n_experience += 1\n",
    "\n",
    "    def learn(self) :\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "3960edf3-28b1-43c9-9158-2cbfc2638716",
   "metadata": {},
   "outputs": [],
   "source": [
    "player = RandomAgent()\n",
    "env = GridWorld()\n",
    "\n",
    "scores = []\n",
    "score = 0\n",
    "\n",
    "\n",
    "for e in range(1, 100000) :\n",
    "    #---에피소드 시작---#\n",
    "    while True :\n",
    "        ## step 1 : Choice Action\n",
    "        player.act()\n",
    "        ## step 2 : Environment\n",
    "        player.next_state, player.reward, player.terminated = env.step(player.action)\n",
    "        ## step 3 : Save & Learn\n",
    "        player.save_experience()\n",
    "        player.learn()\n",
    "        ## step 4 : Exit\n",
    "        score += player.reward\n",
    "        scores.append(score)\n",
    "\n",
    "        if player.terminated :\n",
    "            score = 0\n",
    "            player.state = env.reset()\n",
    "            break\n",
    "        else :\n",
    "            player.state = player.next_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "b4cb3ad4-bd76-4b0c-a78d-8a533e2efb1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "327434"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "player.n_experience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "a2dcb527-25c2-4de0-a5a2-763697ecaa94",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_table = np.zeros([4, 4, 4])\n",
    "count = np.zeros([4, 4, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "1e46dd7b-5248-4927-ad7d-a3b87e498f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "for (s1, s2), a, r in zip(player.states, player.actions, player.rewards) :\n",
    "    q_table[s1, s2, a] += r\n",
    "    count[s1, s2, a] += 1\n",
    "\n",
    "count[count == 0] = 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "c5d3b6af-435e-4cfb-91cc-2e401a51ca45",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_table = q_table/count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "3c7b7bc8-64c3-446e-921e-67b8e9eb0acd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-10., -10., -10., -10.],\n",
       "       [ -1.,  -1.,  -1.,  -1.],\n",
       "       [ -1.,  -1.,  -1.,  -1.],\n",
       "       [ -1.,  -1.,  -1.,   0.]])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_table[:, :, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "e1ad7c78-cc72-4e3e-8db4-114272890907",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_table = np.zeros([4, 4, 4])\n",
    "\n",
    "for (s1, s2), a, r in zip(player.states, player.actions, player.rewards) :\n",
    "    qhat = q_table[s1, s2, a]\n",
    "    q = r\n",
    "    diff = q - qhat\n",
    "\n",
    "    q_table[s1, s2, a] += 0.01*diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "50a92c56-1ac1-4e14-b09c-5f4276c40aee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -1.  ,  -1.  ,  -1.  , -10.  ],\n",
       "       [ -1.  ,  -1.  ,  -1.  , -10.  ],\n",
       "       [ -1.  ,  -1.  ,  -1.  , -10.  ],\n",
       "       [ -1.  ,  -1.  ,  99.99,   0.  ]])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_table[:, :, 0].round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "0a612877-da05-4803-8fbb-8b8d9a8f9ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "def act(s1, s2) :\n",
    "    action = q_table[s1, s2].argmax()\n",
    "    return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "4945e58b-deec-4360-8aea-c371842d8808",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = 0\n",
    "\n",
    "for t in range(1, 50) :\n",
    "    ## step1 : Action\n",
    "    s1, s2 = player.state\n",
    "    action = act(s1, s2)\n",
    "    ## step2 : Environment\n",
    "    player.next_state, player.reward, player.terminated = env.step(action)\n",
    "    ## step3 : Save & Learn\n",
    "    player.save_experience()\n",
    "    player.learn()\n",
    "    ## step4 : Terminate\n",
    "    score += player.reward\n",
    "    \n",
    "    if player.terminated :\n",
    "        player.state = env.reset()\n",
    "        break\n",
    "    else :\n",
    "        player.state = player.next_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "f14bcc21-07db-4b73-90d4-833c134eb4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "states = np.concat([np.array(player.states)[-t:], np.array([[3, 3]])], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "828caad4-907c-4008-a9e4-85bd7fbc2dcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1],\n",
       "       [0, 2],\n",
       "       [0, 3],\n",
       "       [1, 3],\n",
       "       [2, 3],\n",
       "       [3, 3]])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(player.next_states)[-t:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa3637b-37a5-4408-a479-7748496b67eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041d6c52-90cf-48e6-b00f-d4cdd8c433f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62e1400-70f9-4479-8cc0-cf7cfd82b085",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_table = np.zeros([4, 4, 4])\n",
    "memory = zip(player.states, player.actions, player.rewards, player.next_states, player.terminations)\n",
    "\n",
    "for (s1, s2), a, r, (ss1, ss2), tmd in memory :\n",
    "    qhat = q_table[s1, s2, a]\n",
    "\n",
    "    if tmd :\n",
    "        ## 현재 받는 rewards만 고려 -> 상황이 종결됐으므로\n",
    "        q = r\n",
    "    else :\n",
    "        ## 다음 스텝으로 이동할 수 있음 -> 미래의 리워드에 감가율을 반영하여 갱신\n",
    "        future_r = q_table[ss1, ss2, :].max()\n",
    "        q = r + 0.95*future_r\n",
    "\n",
    "    diff = q-qhat\n",
    "    q_table[s1, s2, a] += 0.01*diff"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
