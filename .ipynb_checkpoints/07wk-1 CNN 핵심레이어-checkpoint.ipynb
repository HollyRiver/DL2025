{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9bac18bf",
   "metadata": {},
   "source": [
    "# 07wk-1: (합성곱신경망) – CNN 자랑, CNN 핵심레이어"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a20c324",
   "metadata": {},
   "source": [
    "## 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6caaef90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "611fd427-c549-468d-838c-8329d96a9f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (4.5, 3.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77e86b8",
   "metadata": {},
   "source": [
    "## 2. 주요 코드 등"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ad065c-6c49-4001-a64c-249bf33c18d8",
   "metadata": {},
   "source": [
    "```Python\n",
    "net = torch.nn.Sequential(\n",
    "    ## 1 layer - 이미지를 펴지 않고도 할 수 있음\n",
    "    torch.nn.Conv2d(in_channels = 1, out_channels = 64, kernel_size = 5, stride = 1), ## 1은 흑백, 3은 컬러, kernel_size는 작게 잡을수록 세세하게 봄\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.MaxPool2d(kernel_size = 3), ## 특징을 추림, 작게 잡을수록 원본을 유지함\n",
    "\n",
    "    ## transform\n",
    "    torch.nn.Flatten(),\n",
    "    torch.nn.Linear(???, p) ## Flatten까지만 살펴보고 직접 집어넣어야 함 -> 그냥 클래스 하나 만들어서 shape 찍어도 됨\n",
    ").to(\"cuda:0\")\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizr = torch.optim.Adam(net.parameters())\n",
    "\n",
    "##---##\n",
    "for epoc in range(1, 200) :\n",
    "    \"\"\"epoches\"\"\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae807142",
   "metadata": {},
   "source": [
    "## 3. CNN 자랑"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7078a606-3d51-428f-b87b-3cf01f020a11",
   "metadata": {},
   "source": [
    "* SoftMax : 다항분류에서 로짓이 여러 개 나왔을 때 취하는 것. 지수함수 먹이고 상대비율로 확률 추정\n",
    "> 세 개 이상의 분류별 추정 로짓 -> 지수 먹임 -> 전체합으로 나눔\n",
    "\n",
    "* Sigmoid : 한개의 로짓\n",
    "> 한 개의 로짓과 0을 비교 -> 오즈, 1 -> 1일 확률 / 0일 확률로 분리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83fc2c77-2f2e-44c5-83aa-06be085ec0df",
   "metadata": {},
   "source": [
    "### A. 성능 좋음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "386781f5-917b-433c-9e04-6ddf46b77c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torchvision.datasets.FashionMNIST(root='./data', train=True, download=True)\n",
    "test_dataset = torchvision.datasets.FashionMNIST(root='./data', train=False, download=True)\n",
    "train_dataset = torch.utils.data.Subset(train_dataset, range(5000))\n",
    "test_dataset = torch.utils.data.Subset(test_dataset, range(1000))\n",
    "to_tensor = torchvision.transforms.ToTensor()\n",
    "X = torch.stack([to_tensor(img) for img, lbl in train_dataset]).to(\"cuda:0\")\n",
    "y = torch.tensor([lbl for img, lbl in train_dataset])\n",
    "y = torch.nn.functional.one_hot(y).float().to(\"cuda:0\")\n",
    "XX = torch.stack([to_tensor(img) for img, lbl in test_dataset]).to(\"cuda:0\")\n",
    "yy = torch.tensor([lbl for img, lbl in test_dataset])\n",
    "yy = torch.nn.functional.one_hot(yy).float().to(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ea16643-f33a-4497-90ff-3129d2eb2593",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5000, 1, 28, 28])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape ## 너무 많아서 좀 자름"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2201f7d1-c94b-4de3-bfa4-0313f2731bfe",
   "metadata": {},
   "source": [
    "*개억지 발악딜 신경망*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88958d0c-f536-45ab-81e8-fbd74b7a6fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = torch.nn.Sequential(\n",
    "    torch.nn.Flatten(), ## 다차원 데이터 펴버림\n",
    "    torch.nn.Linear(784,2048),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(2048,10)\n",
    ").to(\"cuda\")\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizr = torch.optim.Adam(net.parameters())\n",
    "\n",
    "for epoc in range(1,500):\n",
    "    #1\n",
    "    logits = net(X)\n",
    "    #2\n",
    "    loss = loss_fn(logits, y) \n",
    "    #3\n",
    "    loss.backward()\n",
    "    #4 \n",
    "    optimizr.step()\n",
    "    optimizr.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7e40f5b-9f25-40c0-9bcc-06e4b840d99e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1., device='cuda:0')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(net(X).argmax(axis=1) == y.argmax(axis=1)).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c0ffce0-ea24-432b-823a-7f14a9623d9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8460, device='cuda:0')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(net(XX).argmax(axis=1) == yy.argmax(axis=1)).float().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4182c61b-be57-4e23-983f-de5abedfc366",
   "metadata": {},
   "source": [
    "***대충 설계한 합성곱***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "142323a7-a730-458e-af23-59bcf1d4d1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = torch.nn.Sequential(\n",
    "    torch.nn.Conv2d(1,16,2),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.MaxPool2d(2),\n",
    "    torch.nn.Flatten(),\n",
    "    torch.nn.Linear(2704,10), ## 왜 이렇게 됨???\n",
    ").to(\"cuda\")\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizr = torch.optim.Adam(net.parameters())\n",
    "\n",
    "for epoc in range(1,500):\n",
    "    #1\n",
    "    logits = net(X)\n",
    "    #2\n",
    "    loss = loss_fn(logits, y) \n",
    "    #3\n",
    "    loss.backward()\n",
    "    #4 \n",
    "    optimizr.step()\n",
    "    optimizr.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3f54636e-0216-4e6d-ab8d-f2eaa861e6bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9646, device='cuda:0')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(net(X).argmax(axis=1) == y.argmax(axis=1)).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "65c92005-1f2e-4481-9aed-51c662f46c7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8610, device='cuda:0')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(net(XX).argmax(axis=1) == yy.argmax(axis=1)).float().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f7fec1-a4f2-4c4e-84e3-3083433b918c",
   "metadata": {},
   "source": [
    "> 대충해도 더 잘됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "777c5eb5-63e6-4527-b778-de649ef49d31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5000, 2704])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[:-1](X).shape  ## 마지막 호출해서 직접 차원을 알아야 함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5a000c-e39a-4163-adc4-0cfb1323f562",
   "metadata": {},
   "source": [
    "### B. 파라메터 적음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "78077186-fde6-45d0-a1ef-f34a33524638",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 네트워크는 분할해서 올릴 수 없으므로 ㅈㄴ 비쌈\n",
    "net1 = torch.nn.Sequential(\n",
    "    torch.nn.Flatten(),\n",
    "    torch.nn.Linear(784,2048), ## 784*2048 + 2048\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(2048,10)   ## 2048*10 + 2048\n",
    ")\n",
    "\n",
    "## 파라미터 수가 훨씬 적은데도 성능도 좋음 -> 개사기\n",
    "net2 = torch.nn.Sequential(\n",
    "    torch.nn.Conv2d(1,16,2),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.MaxPool2d(2),\n",
    "    torch.nn.Flatten(),\n",
    "    torch.nn.Linear(2704,10),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a7454005-5df6-447c-9283-50329a7929fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2048, 784])\n",
      "torch.Size([2048])\n",
      "torch.Size([10, 2048])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "net1_params = list(net1.parameters())\n",
    "print(net1_params[0].shape) ## x에 대한 파라메터\n",
    "print(net1_params[1].shape) ## Bias\n",
    "print(net1_params[2].shape) ## x에 대한 파라메터 2\n",
    "print(net1_params[3].shape) ## Bias 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2a085828-1d9b-48ae-93fb-7d27774d88f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1628170"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2048*784 + 2048 + 10*2048 + 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cf9b6458-4199-44e9-9ca7-db1685f54a7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 1, 2, 2])\n",
      "torch.Size([16])\n",
      "torch.Size([10, 2704])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "net2_params = list(net2.parameters())\n",
    "print(net2_params[0].shape) ## x에 대한 파라메터\n",
    "print(net2_params[1].shape) ## Bias\n",
    "print(net2_params[2].shape) ## x에 대한 파라메터 2\n",
    "print(net2_params[3].shape) ## Bias 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c7b807b2-22aa-457f-a646-0415a49d246a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27130"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "16*1*2*2 + 16 + 10*2704 + 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff26242-804e-41f0-85c6-f91c35ecf37d",
   "metadata": {},
   "source": [
    "> 파라메터를 0.016만큼만 썼음에도 더 성능이 좋음, 대충대충 만들었음에도 성능이 좋음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a85fdb-a39e-4507-824d-67995144a8e0",
   "metadata": {},
   "source": [
    "### C. 유명함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b27265e-6e0d-4886-a9df-e726c151b440",
   "metadata": {},
   "source": [
    "`-` <https://brunch.co.kr/@hvnpoet/109>\n",
    "\n",
    "* 딥러닝 슈퍼스타\n",
    "> 힌튼, 르쿤, 벤지오, 응\n",
    ">\n",
    "> 힌튼 교수넴 -> DBN(사이언스지) -> 깊은신경망을 만들어도 학습할 수 있다, 성능도 좋다.\n",
    ">\n",
    "> 관심 없음 --- 휘하 대학원생 알렉스가 CIFAR10 데이터셋을 만들어서 분류 문제 증명하려고 함 -> 힘듦\n",
    ">\n",
    "> 다른대학원생 -> 콘테스트 나가서 입증해보자 -> 컴퓨터 느림, 오버피팅 생김, 국지적 최소값, 기울기 소멸\n",
    ">\n",
    "> ---> GPU 쓰자, 드랍아웃 쓰자, 렐루를 활성화함수로 쓰자 ---> ㅈㄴ 잘함, 혁신"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b6fd82-67c3-485b-93a6-390e51552a77",
   "metadata": {},
   "source": [
    "## 4. CNN 핵심레이어"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5847a19-6c28-4638-a453-451b7f4fa9b7",
   "metadata": {},
   "source": [
    "```Python\n",
    "torch.nn.Conv2d(),\n",
    "torch.nn.ReLU(),\n",
    "torch.nn.MaxPool2d()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841e4299-f385-415b-a191-43454a6e37ec",
   "metadata": {},
   "source": [
    "### A. `torch.nn.ReLU`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8492b89-9e17-4671-a207-2234cf9e71f3",
   "metadata": {},
   "source": [
    "**(예시1) 연산방법, kernel_size의 의미**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c7168576-84ea-4840-b0cb-cb2947c3f8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = torch.randn(1, 1, 4, 4) ## (4, 4) 흑백 이미지 한장\n",
    "relu = torch.nn.ReLU()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f6059c32-17b8-4458-99db-f38284ceae30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 1.4084,  1.1233,  0.7891, -2.4956],\n",
       "          [ 0.0470, -1.2522, -0.6157, -0.4172],\n",
       "          [ 0.1714,  0.5501,  0.9884, -0.9269],\n",
       "          [ 0.7274, -0.8939,  0.9855, -0.8834]]]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ed9c6052-f997-44b4-b3bf-038d7e8dff5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[1.4084, 1.1233, 0.7891, 0.0000],\n",
       "          [0.0470, 0.0000, 0.0000, 0.0000],\n",
       "          [0.1714, 0.5501, 0.9884, 0.0000],\n",
       "          [0.7274, 0.0000, 0.9855, 0.0000]]]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relu(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844d058d-85f1-48bb-9129-eaf670b6478e",
   "metadata": {},
   "source": [
    "> 그냥 똑같음. 음수이면 0으로 올림"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c185f233-c0ad-4886-83db-f5114f995cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = torch.randn(1, 1, 4, 4)\n",
    "mp = torch.nn.MaxPool2d(kernel_size = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7a68d2de-4a83-40e6-bde5-572959ab10e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.3012,  0.2972,  0.1387, -0.1596],\n",
       "          [ 0.6020,  0.3204,  0.0589, -1.3579],\n",
       "          [ 0.4615, -1.1834, -1.0951, -0.8815],\n",
       "          [ 0.5930,  0.3248,  0.4900, -0.8284]]]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ac974265-4232-4416-81b7-cdd90fbf1e4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.6020, 0.1387],\n",
       "          [0.5930, 0.4900]]]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mp(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43ee904-d002-4a49-bf89-08be06a91cb8",
   "metadata": {},
   "source": [
    "> (4, 4)의 이미지를 크기가 2인 정방 윈도우로 쪼개어 각 윈도우의 Max값을 추출함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea711d11-22aa-42b7-9a8c-51a484b4d9e2",
   "metadata": {},
   "source": [
    "**(예시2) 이미지크기와 딱 맞지 않는 커널일 경우?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3d17fcfe-2307-40f9-bf1d-43693eb18c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = torch.randn(1, 1, 5, 5)\n",
    "mp = torch.nn.MaxPool2d(kernel_size = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c4e8e16b-7d12-476e-b246-d08103a64f41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-0.7601, -0.3066, -0.5217, -0.6908, -0.5589],\n",
       "          [-0.7216,  0.4627,  0.1489, -0.2923, -0.6556],\n",
       "          [ 0.5201, -0.5569, -0.9285, -1.2374,  0.0843],\n",
       "          [-1.0531, -0.8987, -0.5979,  1.1153, -0.3969],\n",
       "          [-1.7311, -0.4479,  0.5167, -0.7048,  1.3095]]]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "25921f8d-ba1c-4612-944b-f8837c17f83e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.4627, 0.1489],\n",
       "          [0.5201, 1.1153]]]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mp(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0629e122-901f-477b-ab7d-0839de44837b",
   "metadata": {},
   "source": [
    "> **파이토치** : 남는 차원은 그냥 가차없이 버림"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68983016-322c-474c-843d-af32d02d4c84",
   "metadata": {},
   "source": [
    "**(예시3) 정사각형이 아닌 커널** <- 잘 안씀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a5f47098-ee7e-4de8-898d-9c70f30e4fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = torch.rand(1, 1, 4, 4)\n",
    "mp = torch.nn.MaxPool2d(kernel_size = (2, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d19159c8-8500-4975-9a4d-a83b10f9e273",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.0845, 0.4076, 0.0115, 0.3949],\n",
       "          [0.1350, 0.9975, 0.1458, 0.1850],\n",
       "          [0.0292, 0.5169, 0.6951, 0.8657],\n",
       "          [0.1442, 0.3767, 0.5413, 0.3423]]]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0726f45d-48b9-4b1a-9341-46bb9f1ae5ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.9975],\n",
       "          [0.8657]]]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mp(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee9e991f-af48-479f-abfa-0b06a6f9b68d",
   "metadata": {},
   "source": [
    "### C. `torch.nn.Conv2d`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d614b2f-6c28-4d37-9345-6a4d975ac7d8",
   "metadata": {},
   "source": [
    "**(예시1) 연산방법, stride = 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1295ad07-57e1-42ac-b047-0de956c406b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = torch.rand(1, 1, 4, 4) ## input channel : 1과 3. 이미지 형태\n",
    "conv = torch.nn.Conv2d(in_channels = 1, out_channels = 1, kernel_size = 2, stride = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2f8e26d8-3f34-4f8b-b1ed-950ee2c607e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.1054, 0.0379, 0.1375, 0.0127],\n",
       "          [0.6344, 0.0410, 0.4574, 0.8073],\n",
       "          [0.1375, 0.3647, 0.3059, 0.3496],\n",
       "          [0.7166, 0.1335, 0.2234, 0.9699]]]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b62e80a1-718b-4db3-910d-f5fc36ceb613",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-0.5347, -0.7454],\n",
       "          [-0.5788, -0.7303]]]], grad_fn=<ConvolutionBackward0>)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41be98b1-1192-485b-a4cd-5a6e370d1bf6",
   "metadata": {},
   "source": [
    "???"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf63346-5259-4719-b86e-0e93ff346f1c",
   "metadata": {},
   "source": [
    "`-` 도출과정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7865a6bf-57e2-4132-8e59-fec327553574",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.1054, 0.0379],\n",
       "          [0.6344, 0.0410]]]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img[:, :, :2, :2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e1e7bf88-360c-4c9b-a53b-ad750edc00e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.1375, 0.0127],\n",
       "          [0.4574, 0.8073]]]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img[:, :, :2, 2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f0d27264-def7-4fd4-bc1d-c9a1694f2d1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.1375, 0.3647],\n",
       "          [0.7166, 0.1335]]]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img[:, :, 2:, :2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "bb0b2548-2e1a-43eb-9cef-6f843105aef0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.3059, 0.3496],\n",
       "          [0.2234, 0.9699]]]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img[:, :, 2:, 2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "71cee8bb-28d5-44b9-9eae-4a2e25cd10f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Parameter containing:\n",
       " tensor([[[[ 0.1550, -0.0092],\n",
       "           [-0.1932, -0.3263]]]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.4148], requires_grad=True))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv.weight, conv.bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9585bd1c-0d8c-4578-95c1-c0fcd2333c98",
   "metadata": {},
   "source": [
    "> 파라미터가 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "aa343518-3b8b-4926-baf4-9595ab3ae445",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.5347])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(img[:, :, :2, :2]*conv.weight.data).sum() + conv.bias.data ## 첫 번째 원소 나옴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2759bb80-af8f-4d06-ba99-7802d0ef86dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.7454])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(img[:, :, :2, 2:]*conv.weight.data).sum() + conv.bias.data ## (1, 2) 원소"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "92366ade-49d7-4bcb-9ea3-9b454537c8aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.5788])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(img[:, :, 2:, :2]*conv.weight.data).sum() + conv.bias.data ## (2, 1) 원소"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f0965100-ec80-487a-94c5-e5adebbbf48a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.7303])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(img[:, :, 2:, 2:]*conv.weight.data).sum() + conv.bias.data ## (2, 2) 원소"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4022eb-fe39-4408-8d0f-d682b00d213e",
   "metadata": {},
   "source": [
    "> `conv.weight.data`의 값과 동일한 위치의 값을 곱하여(행렬곱 아님) 싹 더함 --> 가중평균 느낌\n",
    ">\n",
    "> 거기다가 bias 더해줌\n",
    ">\n",
    "> 약간 스무딩하는 느낌으로다가 생각하면 될듯"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
