{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9bac18bf",
   "metadata": {},
   "source": [
    "# 06wk-2: (신경망) – 다항분류, 합성곱신경망"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a20c324",
   "metadata": {},
   "source": [
    "## 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6caaef90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "611fd427-c549-468d-838c-8329d96a9f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (4.5, 3.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77e86b8",
   "metadata": {},
   "source": [
    "## 2. 주요 코드 등"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae807142",
   "metadata": {},
   "source": [
    "## 3. 다항분류"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4f610c-33c3-46a5-9b9a-f1105d21216d",
   "metadata": {},
   "source": [
    "* 이항분류 - 실패 / 성공 $\\to ~ y \\in \\{0, 1\\}$\n",
    "* 다항분류 - 3개 이상의 범주로 분류"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa2c95f1-070e-4df2-9845-20d1e7607f50",
   "metadata": {},
   "source": [
    "### A. 이항분류와 `BCEWithLogitsLoss`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32967000-30a7-4a45-a443-10ee6ddeb981",
   "metadata": {},
   "source": [
    "`-` 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3510e31-5c11-48c8-9f36-1bb00b70fcf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True)\n",
    "to_tensor = torchvision.transforms.ToTensor()\n",
    "X0_train = torch.stack([to_tensor(Xi) for Xi, yi in train_dataset if yi==0])\n",
    "X1_train = torch.stack([to_tensor(Xi) for Xi, yi in train_dataset if yi==1])\n",
    "X = torch.concat([X0_train,X1_train],axis=0).reshape(-1,784)\n",
    "y = torch.tensor([0.0]*len(X0_train) + [1.0]*len(X1_train)).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48be26dc-34b5-4913-8587-8bf87d58f622",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12665, 784])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e11927a-95a0-4054-9033-e0a75fba1bb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12665, 1])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "60824ee2-d9c4-43bc-8bcc-57e574b23e91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 1\t acc = 0.4689\n",
      "epoch = 2\t acc = 0.6385\n",
      "epoch = 3\t acc = 0.8711\n",
      "epoch = 4\t acc = 0.9457\n",
      "epoch = 5\t acc = 0.9677\n",
      "epoch = 6\t acc = 0.9765\n",
      "epoch = 7\t acc = 0.9809\n",
      "epoch = 8\t acc = 0.9848\n",
      "epoch = 9\t acc = 0.9863\n",
      "epoch = 10\t acc = 0.9878\n",
      "epoch = 11\t acc = 0.9887\n",
      "epoch = 12\t acc = 0.9893\n",
      "epoch = 13\t acc = 0.9904\n",
      "epoch = 14\t acc = 0.9909\n",
      "epoch = 15\t acc = 0.9918\n",
      "epoch = 16\t acc = 0.9923\n",
      "epoch = 17\t acc = 0.9926\n",
      "epoch = 18\t acc = 0.9931\n",
      "epoch = 19\t acc = 0.9935\n",
      "epoch = 20\t acc = 0.9938\n",
      "epoch = 21\t acc = 0.9939\n",
      "epoch = 22\t acc = 0.9940\n",
      "epoch = 23\t acc = 0.9945\n",
      "epoch = 24\t acc = 0.9946\n",
      "epoch = 25\t acc = 0.9948\n",
      "epoch = 26\t acc = 0.9946\n",
      "epoch = 27\t acc = 0.9948\n",
      "epoch = 28\t acc = 0.9951\n",
      "epoch = 29\t acc = 0.9953\n",
      "epoch = 30\t acc = 0.9956\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(43052)\n",
    "\n",
    "net = torch.nn.Sequential(\n",
    "    torch.nn.Linear(784, 32),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(32, 1)\n",
    "    # torch.nn.Sigmoid()\n",
    ")\n",
    "\n",
    "sig = torch.nn.Sigmoid()\n",
    "\n",
    "# sig(net(X)) ## 똑같은 결과...긴함\n",
    "# 1/(1+torch.exp(-net(X))) ## 그냥 수식 직접 때려박아도 똑같음... 일단은\n",
    "\n",
    "loss_fn = torch.nn.BCELoss()\n",
    "optimizr = torch.optim.Adam(net.parameters())\n",
    "\n",
    "##---##\n",
    "for epoc in range(1, 31) :\n",
    "    # 1\n",
    "    netout = net(X)\n",
    "    yhat = sig(netout)\n",
    "    # 2\n",
    "    loss = loss_fn(yhat, y)\n",
    "    # 3\n",
    "    loss.backward()\n",
    "    # 4\n",
    "    optimizr.step()\n",
    "    optimizr.zero_grad()\n",
    "    #----------에폭 이후 코드----------#\n",
    "    acc = ((net(X).data > 0.0) == y).float().mean()  ## 로짓\n",
    "    print(f\"epoch = {epoc}\\t acc = {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ce117b5f-b383-47cd-8ae6-d594230ba9b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0179],\n",
       "        [0.0205],\n",
       "        [0.1106],\n",
       "        ...,\n",
       "        [0.8751],\n",
       "        [0.8740],\n",
       "        [0.8033]], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sig(net(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "64d073d4-af59-4a1f-8f5b-bf9e67921d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.manual_seed(43052)\n",
    "\n",
    "# net = torch.nn.Sequential(\n",
    "#     torch.nn.Linear(784, 32),\n",
    "#     torch.nn.ReLU(),\n",
    "#     torch.nn.Linear(32, 1),\n",
    "#     torch.nn.Sigmoid()\n",
    "# )\n",
    "\n",
    "# loss_fn = torch.nn.BCELoss()\n",
    "# optimizr = torch.optim.Adam(net.parameters())\n",
    "\n",
    "# ##---##\n",
    "# for epoc in range(1, 31) :\n",
    "#     # 1\n",
    "#     yhat = net(X)\n",
    "#     # 2\n",
    "#     loss = loss_fn(yhat, y)\n",
    "#     # 3\n",
    "#     loss.backward()\n",
    "#     # 4\n",
    "#     optimizr.step()\n",
    "#     optimizr.zero_grad()\n",
    "\n",
    "# net(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03c6648-ba2c-4872-a39e-6c1cc2b14769",
   "metadata": {},
   "source": [
    "> 어차피 네트워크에 들어가는 파라미터가 없고, 손실함수에만 적용되었기 때문에 똑같음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9ba70f29-ca52-44ef-8b3e-622616240d19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0179],\n",
       "        [0.0205],\n",
       "        [0.1106],\n",
       "        ...,\n",
       "        [0.8751],\n",
       "        [0.8740],\n",
       "        [0.8033]], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sig(net(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1bbeb6-902f-446f-895e-585b970c213d",
   "metadata": {},
   "source": [
    "`-` 로짓"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a5b00220-a6c4-447d-b8f9-1d2cc3c2f622",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = netout = net(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "94315a47-776b-450a-8812-be3686531531",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0179],\n",
       "        [0.0205],\n",
       "        [0.1106],\n",
       "        ...,\n",
       "        [0.8751],\n",
       "        [0.8740],\n",
       "        [0.8033]], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sig(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "998e4419-5d50-47d4-84c6-de58eaeff17d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0179],\n",
       "        [0.0205],\n",
       "        [0.1106],\n",
       "        ...,\n",
       "        [0.8751],\n",
       "        [0.8740],\n",
       "        [0.8033]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1/(1+torch.exp(-logits))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "907ec0a5-8a2b-46f8-863b-8f9ce59c48d6",
   "metadata": {},
   "source": [
    "`#` netout(logits)의 특징\n",
    "\n",
    "* $\\text{netout} > 0 \\Leftrightarrow \\text{sig(netout)} > 0.5$\n",
    "* $\\text{netout} < 0 \\Leftrightarrow \\text{sig(netout)} < 0.5$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543bc8c0-5502-4e1d-a16c-1230b102f0c2",
   "metadata": {},
   "source": [
    "> 둘다 동일하게 사용할 수 있다. logits을 이용하여 네트워크의 정확도를 파악할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3f43f465-bbb8-48c1-8066-b1e7b8d88cc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9956)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((sig(net(X)) > 0.5) == y).float().mean() ## 확률값을 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bcae52c0-3ebf-40ac-9f2b-51711c158ccb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9956)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((net(X) > 0.0) == y).float().mean() ## 로짓 자체를 비교"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e15126-638c-4b86-b0bf-c9d2431b0ce6",
   "metadata": {},
   "source": [
    "`-` 그런데 이건 위랑 같은 코드임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "98e8e135-16ad-4bad-8203-89c8ad09b5fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 1\t acc = 0.4689\n",
      "epoch = 2\t acc = 0.6385\n",
      "epoch = 3\t acc = 0.8711\n",
      "epoch = 4\t acc = 0.9457\n",
      "epoch = 5\t acc = 0.9677\n",
      "epoch = 6\t acc = 0.9765\n",
      "epoch = 7\t acc = 0.9809\n",
      "epoch = 8\t acc = 0.9848\n",
      "epoch = 9\t acc = 0.9863\n",
      "epoch = 10\t acc = 0.9878\n",
      "epoch = 11\t acc = 0.9887\n",
      "epoch = 12\t acc = 0.9893\n",
      "epoch = 13\t acc = 0.9904\n",
      "epoch = 14\t acc = 0.9909\n",
      "epoch = 15\t acc = 0.9918\n",
      "epoch = 16\t acc = 0.9923\n",
      "epoch = 17\t acc = 0.9926\n",
      "epoch = 18\t acc = 0.9931\n",
      "epoch = 19\t acc = 0.9935\n",
      "epoch = 20\t acc = 0.9938\n",
      "epoch = 21\t acc = 0.9939\n",
      "epoch = 22\t acc = 0.9940\n",
      "epoch = 23\t acc = 0.9945\n",
      "epoch = 24\t acc = 0.9946\n",
      "epoch = 25\t acc = 0.9948\n",
      "epoch = 26\t acc = 0.9946\n",
      "epoch = 27\t acc = 0.9948\n",
      "epoch = 28\t acc = 0.9951\n",
      "epoch = 29\t acc = 0.9953\n",
      "epoch = 30\t acc = 0.9956\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(43052)\n",
    "net = torch.nn.Sequential(\n",
    "    torch.nn.Linear(784,32),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(32,1)\n",
    ")\n",
    "loss_fn = torch.nn.BCEWithLogitsLoss() # <--- 여기를 바꾸고 \n",
    "optimizr = torch.optim.Adam(net.parameters())\n",
    "#---#\n",
    "for epoc in range(1,31):\n",
    "    # step1 \n",
    "    netout = net(X) # netout = logits \n",
    "    # yhat = torch.exp(netout) / (1 + torch.exp(netout))  # yhat = prob  ## 바로 비교해서 필요 없음\n",
    "    # step2\n",
    "    loss = loss_fn(netout,y) ## logits이랑 loss를 바로 비교하고 싶어...\n",
    "    # step3     \n",
    "    loss.backward()\n",
    "    # step4 \n",
    "    optimizr.step()\n",
    "    optimizr.zero_grad()\n",
    "    #----------에폭 이후 코드----------#\n",
    "    acc = ((net(X).data > 0.0) == y).float().mean()\n",
    "    print(f\"epoch = {epoc}\\t acc = {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5aa7ab9b-c796-49b2-b7a5-9cd61e9970fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0179],\n",
       "        [0.0205],\n",
       "        [0.1106],\n",
       "        ...,\n",
       "        [0.8751],\n",
       "        [0.8740],\n",
       "        [0.8033]], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sig(net(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f742cb-580c-4afc-aa85-5b02c6e9dbc6",
   "metadata": {},
   "source": [
    "> 컴퓨터공학적인 사유로 더 좋음. 그리고 시그모이드를 취하지 않은 실수 범위의 값에서 모델을 학습시키는게 더 도움이 됨"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e19f78-5a38-4ef2-a926-dd6f9ebc727e",
   "metadata": {},
   "source": [
    "### B. 범주형 자료의 변환\n",
    "\n",
    "`-` 범주형 자료를 숫자로 어떻게 바꿀까?\n",
    "\n",
    "* 실패 / 성공 -> 0 / 1\n",
    "* 숫자0그림 / 숫자1그림 -> 0 / 1\n",
    "* 강아지그림 / 고양이그림 -> 0 / 1\n",
    "* 강아지그림 / 고양이그림 / 토끼그림 -> 0 / 1 / 2 ???\n",
    "\n",
    "`-` 주입식교육\n",
    "\n",
    "* 올바른방식 : 강아지그림 = $[1, 0, 0]$, 고양이그림 = $[0, 1, 0]$, 토끼그림 = $[0, 0, 1]$\n",
    "> 더미변수 하나 제거 안함...\n",
    "\n",
    "`-` 왜?\n",
    "\n",
    "* 서열측도가 아닌 명목척도임. 그래서 범주를 숫자화하면 평균 등의 의미가 없음\n",
    "* 범주형은 그냥 원핫인코딩 해야 함\n",
    "* 다항분포의 실현값은 벡터로 나오므로 당연히 $y_i$도 해당 실현값의 형태를 가진다고 가정하는 게 바람직함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eff2aec-d134-474c-a6bb-4415088ba1f6",
   "metadata": {},
   "source": [
    "### C. 실습 : 3개의 데이터를 구분"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc00fdd-c5b2-49e3-86f1-c0ac4d1c1c33",
   "metadata": {},
   "source": [
    "`-` 데이터 준비 : 3개의 이미지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "423ddb8c-4e44-479a-8300-801442595226",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True)\n",
    "to_tensor = torchvision.transforms.ToTensor()\n",
    "X0 = torch.stack([to_tensor(Xi) for Xi, yi in train_dataset if yi==0])\n",
    "X1 = torch.stack([to_tensor(Xi) for Xi, yi in train_dataset if yi==1])\n",
    "X2 = torch.stack([to_tensor(Xi) for Xi, yi in train_dataset if yi==2])\n",
    "X = torch.concat([X0,X1,X2]).reshape(-1,1*28*28)\n",
    "y = torch.tensor([0]*len(X0) + [1]*len(X1)+ [2]*len(X2)).reshape(-1,1).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "88cdb86f-54c9-47d6-bd65-5385dd6d7df0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<matplotlib.image.AxesImage at 0x7f7f565be1f0>, tensor([0.]))"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 450x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X[0].reshape(28, 28), cmap = \"gray\"), y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "5b79c1af-6e25-4f62-96e6-65b8752ab879",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 2])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([1.0, 1.2, 2.9]).long() ## 롱폼으로 넣어야 함. 그냥 내림 시켜버리는듯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "951fd50e-20bc-4c5d-b7ce-411f1a8f555a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.nn.functional.one_hot(y.reshape(-1).long()).float()  ## 포맷도 맞춰줘야 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "315af1a2-3b03-48a9-9da6-608a2f66fee7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2445, -0.2006,  0.2036],\n",
       "        [-0.1615, -0.1641,  0.2457],\n",
       "        [-0.2522, -0.2821,  0.1476],\n",
       "        ...,\n",
       "        [-0.1001, -0.1585,  0.1373],\n",
       "        [-0.1158, -0.2489,  0.0921],\n",
       "        [-0.1562, -0.2348,  0.0666]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "0006bd46-c703-4984-b169-f0d07ed01150",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.]])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "c9a8f430-f94e-4f57-a217-a38bda258ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = torch.nn.Sequential(\n",
    "    torch.nn.Linear(784, 32),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(32, 3)\n",
    ")\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss() ## Binary가 아님. 그리고 LogitsLoss를 사용함...\n",
    "optimizr = torch.optim.Adam(net.parameters())\n",
    "\n",
    "\n",
    "for epoc in range(1, 31) :\n",
    "    # 1\n",
    "    netout = net(X) ## 시그모이드 필요없음\n",
    "    # 2\n",
    "    loss = loss_fn(netout, y)\n",
    "    # 3\n",
    "    loss.backward()\n",
    "    # 4\n",
    "    optimizr.step()\n",
    "    optimizr.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "1e7072b8-cee9-4c28-913d-db7120c11867",
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = [[v/torch.sum(l) for v in l] for l in torch.exp(net(X))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0993714e-8dac-426e-925d-13162742d428",
   "metadata": {},
   "source": [
    "> 약간 이런 느낌으로 확률 만들어낸 다음에 비교함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "b958eac8-4b9f-436e-8fe6-589ff43c6947",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[tensor(0.9543, grad_fn=<DivBackward0>),\n",
       "  tensor(0.0214, grad_fn=<DivBackward0>),\n",
       "  tensor(0.0243, grad_fn=<DivBackward0>)],\n",
       " [tensor(0.9620, grad_fn=<DivBackward0>),\n",
       "  tensor(0.0223, grad_fn=<DivBackward0>),\n",
       "  tensor(0.0157, grad_fn=<DivBackward0>)],\n",
       " [tensor(0.7642, grad_fn=<DivBackward0>),\n",
       "  tensor(0.1418, grad_fn=<DivBackward0>),\n",
       "  tensor(0.0940, grad_fn=<DivBackward0>)],\n",
       " [tensor(0.9284, grad_fn=<DivBackward0>),\n",
       "  tensor(0.0320, grad_fn=<DivBackward0>),\n",
       "  tensor(0.0396, grad_fn=<DivBackward0>)],\n",
       " [tensor(0.9889, grad_fn=<DivBackward0>),\n",
       "  tensor(0.0039, grad_fn=<DivBackward0>),\n",
       "  tensor(0.0072, grad_fn=<DivBackward0>)]]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "e7048ab8-d39f-403d-a145-a17807265d5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9671)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(net(X).argmax(axis = 1) == y.argmax(axis = 1)).float().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "981413c2-6f4b-4396-b9b1-1f864aa3aab8",
   "metadata": {},
   "source": [
    "### D. 결론 - 외우세여ㅕㅕㅕㅕㅕㅕㅕㅕㅕㅕㅕㅕ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80fe6a11-2170-4025-be69-c4400c1a9486",
   "metadata": {},
   "source": [
    "`-` 파이토치버전 // 코딩용\n",
    "\n",
    "|   분류   | netout의 의미 |      손실함수       |\n",
    "|:--------:|:-------------:|:-------------------:|\n",
    "| 이항분류 |     prob      |      `BCELoss`      |\n",
    "| 이항분류 |    logits     | `BCEWithLogitsLoss` |\n",
    "| 다항분류 |     probs     |   NA(그런거 없음)   |\n",
    "| 다항분류 |    logits     | `CrossEntropyLoss`  |\n",
    "\n",
    "> `CrossEntropyLoss` 이거 이름이 완전 마음에 안들어요..\n",
    "> `CEWithLogitsLoss` 라고 하는게 더 좋을 것 같습니다.\n",
    "\n",
    "`-` 일반적개념 // 이론용\n",
    "\n",
    "|   분류   | 오차항의가정 | 마지막활성화함수 |       손실함수       |\n",
    "|:--------:|:------------:|:----------------:|:--------------------:|\n",
    "| 이항분류 |   이항분포   |    sigmoid[1]    | Binary Cross Entropy |\n",
    "| 다항분류 |   다항분포   |    softmax[2]    |    Cross Entropy     |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b86fe9f-7e35-4e75-aeed-1f8c558c3c0d",
   "metadata": {},
   "source": [
    "## 4. FashionMNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "306cb2ee-7ee3-4624-b560-b54d92447753",
   "metadata": {},
   "source": [
    "### A. 데이터\n",
    "\n",
    "\n",
    "<https://arxiv.org/abs/1708.07747> (Xiao, Rasul, and Vollgraf 2017)\n",
    "\n",
    "[1] prob=sig(logit)\n",
    "\n",
    "[2] probs=soft(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "a479bfeb-a531-439b-8699-9d565c35c41c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n",
      "100.0%\n",
      "100.0%\n",
      "100.0%\n"
     ]
    }
   ],
   "source": [
    "train_dataset = torchvision.datasets.FashionMNIST(root='./data', train=True, download=True)\n",
    "test_dataset = torchvision.datasets.FashionMNIST(root='./data', train=False, download=True)\n",
    "to_tensor = torchvision.transforms.ToTensor()\n",
    "X = torch.stack([to_tensor(img) for img, lbl in train_dataset])\n",
    "y = torch.tensor([lbl for img, lbl in train_dataset])\n",
    "y = torch.nn.functional.one_hot(y).float()\n",
    "XX = torch.stack([to_tensor(img) for img, lbl in test_dataset])\n",
    "yy = torch.tensor([lbl for img, lbl in test_dataset])\n",
    "yy = torch.nn.functional.one_hot(yy).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "bf06c8cb-e690-489d-ad80-80ebb246a51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = torch.utils.data.TensorDataset(X,y)\n",
    "dl_train = torch.utils.data.DataLoader(ds_train,batch_size=256,shuffle=True)\n",
    "ds_test = torch.utils.data.TensorDataset(XX,yy)\n",
    "dl_test = torch.utils.data.DataLoader(ds_test,batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "902b6d2d-7f21-4dbd-968c-aa642fe6dfe9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([60000, 1, 28, 28]),\n",
       " torch.Size([60000, 10]),\n",
       " torch.Size([10000, 1, 28, 28]),\n",
       " torch.Size([10000, 10]))"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape, XX.shape, yy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "68879247-1e15-461a-b901-a7b5691bb56e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 450x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "obs_idx = 42\n",
    "\n",
    "plt.imshow(X[obs_idx,0,:,:], cmap = \"gray\")\n",
    "plt.title(train_dataset.classes[y[obs_idx].argmax().item()])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "d23f6645-6017-475d-ae1d-72b97a19ab5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
       "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y ## 이미 원-핫 인코딩 되어있음. 10개 범주"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "f8648426-59b0-474c-a8d8-a835d9860936",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T-shirt/top',\n",
       " 'Trouser',\n",
       " 'Pullover',\n",
       " 'Dress',\n",
       " 'Coat',\n",
       " 'Sandal',\n",
       " 'Shirt',\n",
       " 'Sneaker',\n",
       " 'Bag',\n",
       " 'Ankle boot']"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.classes ## 각 라벨이 의미하는 것"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35104f14-13af-4de9-bc99-067da8195420",
   "metadata": {},
   "source": [
    "> 어차피 모형 구성하는 데에는 별다른 의미는 없음./.."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c82833-abf5-4b7a-9030-2780f20eaa3d",
   "metadata": {},
   "source": [
    "### B. 간단한 신경망"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "125efac2-77d8-463e-815a-26172609293f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "28*28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "160834b3-09a2-44fd-a563-f2e5bbc3714b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 1, 28, 28])"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "c6cc7c78-e092-488d-9f7f-1da66da4ab59",
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "class Flatten(torch.nn.Module):\n",
    "    def __init__(self) :\n",
    "        super().__init__()\n",
    "    def forward(self, ipt) :\n",
    "        out = ipt.reshape(-1, 784)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "85ad6380-b154-401c-80ed-be47f5ee72e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = torch.nn.Sequential(\n",
    "    Flatten(),\n",
    "    torch.nn.Linear(784, 32),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(32, 10)\n",
    ")\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizr = torch.optim.Adam(net.parameters())\n",
    "\n",
    "##---##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "e17b2900-5764-4bd7-952d-505e0a3ddb08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1095,  0.0599, -0.2448,  ..., -0.1533,  0.2131, -0.0300],\n",
       "        [-0.0772,  0.0177, -0.1851,  ..., -0.2153, -0.0031, -0.0431],\n",
       "        [-0.1638, -0.0720, -0.1709,  ..., -0.1506,  0.0121, -0.0105],\n",
       "        ...,\n",
       "        [-0.1242,  0.0944, -0.2923,  ..., -0.2200,  0.0352, -0.1012],\n",
       "        [-0.1311, -0.0851, -0.1209,  ..., -0.1525,  0.0598,  0.0646],\n",
       "        [-0.1940, -0.1228, -0.1014,  ..., -0.1262,  0.1344,  0.0667]],\n",
       "       grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3a6d03-bc4d-4544-8000-e9603cd7952e",
   "metadata": {},
   "source": [
    "`-` 파이토치에서도 이정도는 해줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "d3acf48d-8711-4610-96ad-cee30e52c181",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = torch.nn.Sequential(\n",
    "    torch.nn.Flatten(), ## 이미지 포맷인 경우 해줌 : (n, 3, w, h)\n",
    "    torch.nn.Linear(784, 32),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(32, 10)\n",
    ")\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizr = torch.optim.Adam(net.parameters())\n",
    "\n",
    "##---##\n",
    "for epoc in range(1, 301) :\n",
    "    # 1\n",
    "    yhat = net(X)\n",
    "    # 2\n",
    "    loss = loss_fn(yhat, y)\n",
    "    # 3\n",
    "    loss.backward()\n",
    "    # 4\n",
    "    optimizr.step()\n",
    "    optimizr.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "0e4377f8-223f-4ada-aedc-5155ee8a103c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8575)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(net(X).argmax(axis = 1) == y.argmax(axis = 1)).float().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e5b2aa-c209-468f-85cd-7c599eaf25c7",
   "metadata": {},
   "source": [
    "> 잘 안되는 것 같음... -> 에폭별로 상황 파악"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "48c4bca7-653b-4447-88e8-7748fc86fa96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 acc 0.7404\n",
      "100 acc 0.8044\n",
      "150 acc 0.8295\n",
      "200 acc 0.8423\n",
      "250 acc 0.8505\n",
      "300 acc 0.8565\n"
     ]
    }
   ],
   "source": [
    "net = torch.nn.Sequential(\n",
    "    torch.nn.Flatten(), ## 이미지 포맷인 경우 해줌 : (n, 3, w, h)\n",
    "    torch.nn.Linear(784, 32),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(32, 10)\n",
    ")\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizr = torch.optim.Adam(net.parameters())\n",
    "\n",
    "##---##\n",
    "for epoc in range(1, 301) :\n",
    "    # 1\n",
    "    yhat = net(X)\n",
    "    # 2\n",
    "    loss = loss_fn(yhat, y)\n",
    "    # 3\n",
    "    loss.backward()\n",
    "    # 4\n",
    "    optimizr.step()\n",
    "    optimizr.zero_grad()\n",
    "    #-----에폭 끝-----#\n",
    "    if epoc % 50 == 0 :\n",
    "        logits = net(X).data\n",
    "        acc = (logits.argmax(axis = 1) == y.argmax(axis = 1)).float().mean()\n",
    "        print(f\"{epoc} acc {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "72244d51-a277-4075-bfb3-cba2d556bd31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8565)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(net(X).argmax(axis = 1) == y.argmax(axis = 1)).float().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73db7b20-61fc-4b99-b20a-86d372931ace",
   "metadata": {},
   "source": [
    "> 에폭을 높여도 정확도가 드라마틱하게 올라가진 않을 것 같음. 게다가 이건 train acc임..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "9b1a8954-78e4-4ce3-b9f8-282f1f97607e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of epochs = 50, \t train acc 0.7334\n",
      "# test acc = 0.7245\n",
      "# of epochs = 100, \t train acc 0.8052\n",
      "# test acc = 0.7925\n",
      "# of epochs = 150, \t train acc 0.8295\n",
      "# test acc = 0.8181\n",
      "# of epochs = 200, \t train acc 0.8398\n",
      "# test acc = 0.8283\n",
      "# of epochs = 250, \t train acc 0.8488\n",
      "# test acc = 0.8344\n",
      "# of epochs = 300, \t train acc 0.8556\n",
      "# test acc = 0.8383\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(43052)\n",
    "net = torch.nn.Sequential(\n",
    "    torch.nn.Flatten(), ## 이미지 포맷인 경우 해줌 : (n, 3, w, h)\n",
    "    torch.nn.Linear(784, 32),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(32, 10)\n",
    ")\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizr = torch.optim.Adam(net.parameters())\n",
    "\n",
    "##---##\n",
    "for epoc in range(1, 301) :\n",
    "    # 1\n",
    "    yhat = net(X)\n",
    "    # 2\n",
    "    loss = loss_fn(yhat, y)\n",
    "    # 3\n",
    "    loss.backward()\n",
    "    # 4\n",
    "    optimizr.step()\n",
    "    optimizr.zero_grad()\n",
    "    #-----에폭 끝-----#\n",
    "    if epoc % 50 == 0 :\n",
    "        logits = net(X).data\n",
    "        acc = (logits.argmax(axis = 1) == y.argmax(axis = 1)).float().mean()\n",
    "        print(f\"# of epochs = {epoc}, \\t train acc {acc:.4f}\")\n",
    "\n",
    "        logits = net(XX).data\n",
    "        acc = (logits.argmax(axis = 1) == yy.argmax(axis = 1)).float().mean()\n",
    "        print(f\"# test acc = {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da630292-dc8d-4285-8b39-508761a272b2",
   "metadata": {},
   "source": [
    "GPU에 올리고 에폭을 때려박아보자..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190e0411-54d1-4f2b-9370-3edc0714b4b8",
   "metadata": {},
   "source": [
    "`-` step 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "95efc8f7-8750-4efe-a92d-15ddfacc67a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = torch.utils.data.TensorDataset(X, y)\n",
    "train_dl = torch.utils.data.DataLoader(train_ds, batch_size = 256, shuffle = True)\n",
    "\n",
    "test_ds = torch.utils.data.TensorDataset(XX, yy)\n",
    "test_dl = torch.utils.data.DataLoader(test_ds, batch_size = 256, shuffle = False) ## 얘는 평가용이니 필요 X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422cfa65-7029-4624-b21e-731b90aa7b93",
   "metadata": {},
   "source": [
    "`-` step 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "9409d6b6-6574-472e-816e-728f9067e27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = torch.nn.Sequential(\n",
    "    torch.nn.Flatten(),\n",
    "    torch.nn.Linear(784, 32),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(32, 10)\n",
    ").to(\"cuda:0\")\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizr = torch.optim.Adam(net.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c46fda-dfe2-4598-9a8c-615ddfc0437f",
   "metadata": {},
   "source": [
    "`-` step 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "85243772-191a-4484-abe0-9813be25ea41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of epochs = 5\t train_acc = 0.8938\n",
      "# of epochs = 10\t train_acc = 0.8983\n",
      "# of epochs = 15\t train_acc = 0.8994\n",
      "# of epochs = 20\t train_acc = 0.9016\n",
      "# of epochs = 25\t train_acc = 0.9036\n",
      "# of epochs = 30\t train_acc = 0.9070\n"
     ]
    }
   ],
   "source": [
    "for epoc in range(1, 31) :\n",
    "    net.train()\n",
    "    #-----에폭 시작----#\n",
    "    for Xm, ym in train_dl :\n",
    "        Xm = Xm.to(\"cuda:0\")\n",
    "        ym = ym.to(\"cuda:0\")\n",
    "\n",
    "        # 1\n",
    "        netout = net(Xm)\n",
    "        # 2\n",
    "        loss = loss_fn(netout, ym)\n",
    "        # 3\n",
    "        loss.backward()\n",
    "        # 4\n",
    "        optimizr.step()\n",
    "        optimizr.zero_grad()\n",
    "\n",
    "    #-----에폭 끝-----#\n",
    "    if epoc % 5 == 0 :\n",
    "        net.eval()\n",
    "        s = 0\n",
    "\n",
    "        for Xm, ym in train_dl :\n",
    "            Xm = Xm.to(\"cuda:0\")\n",
    "            ym = ym.to(\"cuda:0\")\n",
    "            s += (net(Xm).data.argmax(axis=1) == ym.argmax(axis=1)).float().sum().item()\n",
    "            \n",
    "        acc = s / len(X)\n",
    "        print(f\"# of epochs = {epoc}\\t train_acc = {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "b5f548b3-d25b-4c62-b6ac-d3a0953191d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc = 0.8712\n"
     ]
    }
   ],
   "source": [
    "net.eval()\n",
    "s = 0 \n",
    "for Xm,ym in test_dl :\n",
    "    Xm = Xm.to(\"cuda:0\")\n",
    "    ym = ym.to(\"cuda:0\")        \n",
    "    s = s+(net(Xm).data.argmax(axis=1) == ym.argmax(axis=1)).float().sum().item()\n",
    "acc = s / len(XX)\n",
    "print(f\"test_acc = {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "596b82ca-b590-497f-8aa5-309eb185e57c",
   "metadata": {},
   "source": [
    "### C. 복잡한 신경망"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "b617e1d4-c1d5-4371-8d1c-1666da1b1836",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of epochs = 5\t train_acc = 0.8843\n",
      "# of epochs = 10\t train_acc = 0.9020\n",
      "# of epochs = 15\t train_acc = 0.9176\n",
      "# of epochs = 20\t train_acc = 0.9265\n",
      "# of epochs = 25\t train_acc = 0.9345\n",
      "# of epochs = 30\t train_acc = 0.9388\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(43052)\n",
    "net = torch.nn.Sequential(\n",
    "    torch.nn.Flatten(),\n",
    "    torch.nn.Linear(784,256), ## 파라미터의 수를 늘림\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(256,10)\n",
    ").to(\"cuda:0\")\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizr = torch.optim.Adam(net.parameters())\n",
    "#---#\n",
    "for epoc in range(1,31):\n",
    "    #---에폭시작---#\n",
    "    net.train()\n",
    "    for Xm,ym in dl_train:\n",
    "        Xm = Xm.to(\"cuda:0\")\n",
    "        ym = ym.to(\"cuda:0\")\n",
    "        # Step1\n",
    "        netout = net(Xm)\n",
    "        # Step2\n",
    "        loss = loss_fn(netout,ym) \n",
    "        # Step3\n",
    "        loss.backward()\n",
    "        # Step4 \n",
    "        optimizr.step()\n",
    "        optimizr.zero_grad()\n",
    "    #---에폭끝---#\n",
    "    if epoc % 5 ==0:\n",
    "        net.eval()\n",
    "        s = 0 \n",
    "        for Xm,ym in dl_train:\n",
    "            Xm = Xm.to(\"cuda:0\")\n",
    "            ym = ym.to(\"cuda:0\")        \n",
    "            s = s+(net(Xm).data.argmax(axis=1) == ym.argmax(axis=1)).float().sum().item()\n",
    "        acc = s / len(X)\n",
    "        print(f\"# of epochs = {epoc}\\t train_acc = {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbce7d51-b909-487c-a936-23f21b89fe52",
   "metadata": {},
   "source": [
    "### D. 발악"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1978cf9-dbb7-47a9-81a8-1f306e7c86d8",
   "metadata": {},
   "source": [
    "`-` 차원을 아주 넓게... 노드를 개많이..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87cc73c3-a9a7-43f2-8fd5-cf44daa267c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(43052)\n",
    "net = torch.nn.Sequential(\n",
    "    torch.nn.Flatten(),\n",
    "    torch.nn.Linear(784,4096),\n",
    "    torch.nn.Dropout(0.5),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(4096,10),\n",
    ").to(\"cuda:0\")\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizr = torch.optim.Adam(net.parameters())\n",
    "#---#\n",
    "for epoc in range(1,31):\n",
    "    #---에폭시작---#\n",
    "    net.train()\n",
    "    for Xm,ym in dl_train:\n",
    "        Xm = Xm.to(\"cuda:0\")\n",
    "        ym = ym.to(\"cuda:0\")\n",
    "        # Step1\n",
    "        netout = net(Xm)\n",
    "        # Step2\n",
    "        loss = loss_fn(netout,ym) \n",
    "        # Step3\n",
    "        loss.backward()\n",
    "        # Step4 \n",
    "        optimizr.step()\n",
    "        optimizr.zero_grad()\n",
    "    #---에폭끝---#\n",
    "    if epoc % 5 ==0:\n",
    "        net.eval()\n",
    "        s = 0 \n",
    "        for Xm,ym in dl_train:\n",
    "            Xm = Xm.to(\"cuda:0\")\n",
    "            ym = ym.to(\"cuda:0\")        \n",
    "            s = s+(net(Xm).data.argmax(axis=1) == ym.argmax(axis=1)).float().sum().item()\n",
    "        acc = s / len(X)\n",
    "        print(f\"# of epochs = {epoc}\\t train_acc = {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc30d05-ed6a-4c38-bee7-36cda77012d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.eval()\n",
    "s = 0 \n",
    "for Xm,ym in dl_test:\n",
    "    Xm = Xm.to(\"cuda:0\")\n",
    "    ym = ym.to(\"cuda:0\")        \n",
    "    s = s+(net(Xm).data.argmax(axis=1) == ym.argmax(axis=1)).float().sum().item()\n",
    "acc = s / len(XX)\n",
    "print(f\"test_acc = {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f4648c-cda8-472f-bee3-34ed10f5c804",
   "metadata": {},
   "source": [
    "`-` 레이어를 많이..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb3e3e6-e7ce-4182-9c1b-0d679b30283c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(43052)\n",
    "net = torch.nn.Sequential(\n",
    "    torch.nn.Flatten(),\n",
    "    torch.nn.Linear(784,256),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(256,256),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(256,256),\n",
    "    torch.nn.Dropout(0.5),    \n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(256,256),\n",
    "    torch.nn.Dropout(0.5),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(256,10),\n",
    ").to(\"cuda:0\")\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizr = torch.optim.Adam(net.parameters())\n",
    "#---#\n",
    "for epoc in range(1,31):\n",
    "    #---에폭시작---#\n",
    "    net.train()\n",
    "    for Xm,ym in dl_train:\n",
    "        Xm = Xm.to(\"cuda:0\")\n",
    "        ym = ym.to(\"cuda:0\")\n",
    "        # Step1\n",
    "        netout = net(Xm)\n",
    "        # Step2\n",
    "        loss = loss_fn(netout,ym) \n",
    "        # Step3\n",
    "        loss.backward()\n",
    "        # Step4 \n",
    "        optimizr.step()\n",
    "        optimizr.zero_grad()\n",
    "    #---에폭끝---#\n",
    "    if epoc % 5 ==0:\n",
    "        net.eval()\n",
    "        s = 0 \n",
    "        for Xm,ym in dl_train:\n",
    "            Xm = Xm.to(\"cuda:0\")\n",
    "            ym = ym.to(\"cuda:0\")        \n",
    "            s = s+(net(Xm).data.argmax(axis=1) == ym.argmax(axis=1)).float().sum().item()\n",
    "        acc = s / len(X)\n",
    "        print(f\"# of epochs = {epoc}\\t train_acc = {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ab0847-e504-4e0a-8ad0-92d23d54a92b",
   "metadata": {},
   "source": [
    "> 결론 : 안됨"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca0b13e9-9a58-4e9b-9cfe-24b1e5439a9e",
   "metadata": {},
   "source": [
    "### F. 합성곱신경망"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "5c2b5780-7b31-44d3-9cb5-56d0c5ea0548",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = torch.nn.Sequential(\n",
    "    torch.nn.Conv2d(in_channels = 1, out_channels = 64, kernel_size = 5),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.MaxPool2d(kernel_size = 2),\n",
    "    torch.nn.Flatten(),\n",
    "    torch.nn.Linear(9216, 10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "ed833426-dbef-491c-9f40-8c84d57e742d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 10])"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net(X).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65cda3af-ca58-49bb-88e3-b4bcc237ea3f",
   "metadata": {},
   "source": [
    "`-` 이미지 자체를 처리함. 결과 잘나옴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04157fa8-aec5-4d06-910a-3a1b298f4cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = torch.nn.Sequential(\n",
    "    torch.nn.Conv2d(in_channels=1,out_channels=128,kernel_size=5),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.MaxPool2d(kernel_size=2),\n",
    "    torch.nn.Conv2d(in_channels=128,out_channels=128,kernel_size=5),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.MaxPool2d(kernel_size=2),\n",
    "    torch.nn.Flatten(),\n",
    "    torch.nn.Linear(2048,10),\n",
    ").to(\"cuda:0\")\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizr = torch.optim.Adam(net.parameters())\n",
    "#---#\n",
    "for epoc in range(1,31):\n",
    "    #---에폭시작---#\n",
    "    net.train()\n",
    "    for Xm,ym in dl_train:\n",
    "        Xm = Xm.to(\"cuda:0\")\n",
    "        ym = ym.to(\"cuda:0\")\n",
    "        # Step1\n",
    "        netout = net(Xm)\n",
    "        # Step2\n",
    "        loss = loss_fn(netout,ym) \n",
    "        # Step3\n",
    "        loss.backward()\n",
    "        # Step4 \n",
    "        optimizr.step()\n",
    "        optimizr.zero_grad()\n",
    "    #---에폭끝---#\n",
    "    if epoc % 5 ==0:\n",
    "        net.eval()\n",
    "        s = 0 \n",
    "        for Xm,ym in dl_train:\n",
    "            Xm = Xm.to(\"cuda:0\")\n",
    "            ym = ym.to(\"cuda:0\")        \n",
    "            s = s+(net(Xm).data.argmax(axis=1) == ym.argmax(axis=1)).float().sum().item()\n",
    "        acc = s / len(X)\n",
    "        print(f\"# of epochs = {epoc}\\t train_acc = {acc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
