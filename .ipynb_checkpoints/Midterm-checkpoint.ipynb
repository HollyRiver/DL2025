{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **중간고사 이전 내용 총 정리**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL\n",
    "\n",
    "import requests\n",
    "import io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Pre-Learning : 텐서**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **A. 벡터**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` Vector 선언"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor([1, 2, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` Vector 덧셈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor([1, 2, 3]) + torch.tensor([2]*3)\n",
    "torch.tensor([1, 2, 3]) + 2 ## 브로드캐스팅"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **B. 벡터와 매트릭스**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` 브로드 캐스팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 브로드 캐스팅\n",
    "torch.tensor([[1, 2],\n",
    "              [3, 4],\n",
    "              [5, 6]]) - 1\n",
    "\n",
    "## 다른 연산\n",
    "torch.tensor([[1, 2], [3, 4], [5, 6]])*0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 열별 브로드 캐스팅\n",
    "torch.tensor([[1, 2], [3, 4], [5, 6]]) + torch.tensor([[-1],\n",
    "                                                       [-3],\n",
    "                                                       [-5]])\n",
    "\n",
    "## 행별 브로드캐스팅\n",
    "torch.tensor([[1, 2], [3, 4], [5, 6]]) + torch.tensor([[-1, -2]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` 벡터와의 연산 : 열벡터로 취급"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 4],\n",
       "        [4, 6],\n",
       "        [6, 8]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([[1, 2], [3, 4], [5, 6]]) + torch.tensor([1, 2])\n",
    "torch.tensor([[1, 2], [3, 4], [5, 6]]) + torch.tensor([1, 2, 3]) ## 안됨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` 행렬곱"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 정상적인 행렬곱\n",
    "torch.tensor([[1, 2], [3, 4], [5, 6]]) @ torch.tensor([[1],\n",
    "                                                       [2]])\n",
    "torch.tensor([[1, 2], [3, 4], [5, 6]]) @ torch.tensor([1, 2]) ## 열벡터"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` 벡터는 행렬곱 연산에서 열벡터도로, 행벡터로도 취급할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor([[1, 2, 3]]) @ torch.tensor([[1, 2], [3, 4], [5, 6]])\n",
    "torch.tensor([1, 2, 3]) @ torch.tensor([[1, 2], [3, 4], [5, 6]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **C. transpose, reshape**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` 전치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 3],\n",
       "        [2, 4]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([[1, 2], [3, 4]]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor([[1,2],[3,4],[5,6]]).reshape(2,-1) ## [[1, 2, 3], [4, 5, 6]]\n",
    "torch.tensor([[1,2],[3,4],[5,6]]).reshape(-1,6)\n",
    "torch.tensor([[1,2],[3,4],[5,6]]).reshape(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **D. concat, stack**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` concat(차원 유지, 쉬움)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4],\n",
       "        [5, 5]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([[1], [3], [5]])\n",
    "b = torch.tensor([[2], [4], [5]])\n",
    "torch.concat([a, b], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` stack(차원 늘림, 어려움)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4],\n",
       "        [5, 6]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([1, 3, 5])\n",
    "b = torch.tensor([2, 4, 6])\n",
    "torch.stack([a, b], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4],\n",
       "        [5, 6]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.concat([a.reshape(3, 1), b.reshape(3, 1)], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1. 회귀**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **A. 내용**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` 단순선형회귀모형\n",
    "\n",
    "$$\\begin{align} y_i & = w_0 + w_1 x_i + \\epsilon, ~ i = 1, 2, \\cdots \\\\\n",
    "{\\bf y} & = {\\bf WX + \\epsilon}\n",
    "\\end{align}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 단순선형회귀에서 최적화하고자 하는 파라미터"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ loss(\\hat{w}_0,\\hat{w}_1) := loss(\\hat{\\bf W})=\\sum_{i=1}^{n}(y_i-(\\hat{w}_0+\\hat{w}_1x_i))^2=({\\bf y}-{\\bf X}{\\bf \\hat{W}})^\\top({\\bf y}-{\\bf X}{\\bf \\hat{W}})$$\n",
    "\n",
    "$$\\hat{\\bf W}^{LSE} = \\underset{\\bf \\hat{W}}{\\operatorname{argmin}} ~ loss(\\hat{\\bf W})$$\n",
    "\n",
    "> 위의 식은\n",
    "> $\\hat{\\bf W} = \\underset{\\bf W}{\\operatorname{argmin}} ~ loss({\\bf W})$\n",
    "> 로 생각해도 무방"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **B. 구현**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.arange(1, 10, 0.1)\n",
    "y = (2*x + torch.randn(90) + 5).reshape(-1, 1) ## 꼭 y 차원은 (n, k)로 맞춰줄 것"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` 쌩으로 구현(미분만 사용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "## data\n",
    "What = torch.tensor([[1.0], [2.0]], requires_grad = True) ## 매개변수 넣어야 미분 가능\n",
    "X = torch.stack([torch.ones(len(x)), x], axis = 1)\n",
    "\n",
    "##---##\n",
    "for epoc in range(1000) :\n",
    "    yhat = X@What\n",
    "    \n",
    "    loss = torch.mean((yhat-y)**2)\n",
    "    loss.backward()\n",
    "\n",
    "    What.data -= 0.01*What.grad ## learning rate == 0.01 -> nan 나오면 이걸 조정\n",
    "    What.grad = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` 네트워크, 손실함수, 옵티마이저 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# net = torch.nn.Linear(in_features = 1, out_features = 1, bias = True) ## 이쪽이 일반적\n",
    "net = torch.nn.Linear(in_features = 2, out_features = 1, bias = False)\n",
    "net.weight.data = torch.tensor([[1.0, 2.0]]) ## 행벡터로 삽입\n",
    "# net.bias.data = torch.tensor([1.0])\n",
    "\n",
    "loss_fn = torch.nn.MSELoss() ## calla회귀 문제에서 일반적으로 사용\n",
    "optimizr = torch.optim.SGD(net.parameters(), lr = 0.01) ## iterabla obj : 데이터와 그래디언트\n",
    "\n",
    "##---##\n",
    "for epoc in range(1000) :\n",
    "    yhat = net(X)\n",
    "    \n",
    "    loss = loss_fn(yhat, y)\n",
    "    loss.backward()\n",
    "\n",
    "    optimizr.step()\n",
    "    optimizr.zero_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> `bias`를 넣든, 안넣고 따로 설명변수 매트릭스를 넣든, 둘 다 하든지간에 `yhat`과 추정 결과는 동일함(다만 효율이랑 가시성이 좀 구리겠지...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. 로지스틱**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **A. 내용**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 이진 분류 문제를 해결하기 위한 가장 기초적인 모형\n",
    ">\n",
    "> 순방향 구조, 선형 구조만 제대로 설명할 수 있다는 점에서 모형의 표현력이 다소 낮음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   회귀모형: $y_i \\sim {\\cal N}(w_0+w_1x_i, \\sigma^2)$ -> 정규분포의 평균 예측\n",
    "\n",
    "-   로지스틱: $y_i \\sim {\\cal B}(\\pi_i),\\quad$ where $\\pi_i = \\frac{\\exp(w_0+w_1x_i)}{1+\\exp(w_0+w_1x_i)} = \\frac{1}{1+\\exp(-w_0-w_1x_i)}$\n",
    "> 베르누이의 평균(확률값)을 예측"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **B. 구현**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` 쌩으로 구현(미분만 이용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.randn((100, 1))\n",
    "prob = 1 / (1 + torch.exp(- X @ torch.tensor([[2.0]]) - 0.5))\n",
    "y = torch.bernoulli(prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "What = torch.tensor([[1.0],\n",
    "                     [1.0]], requires_grad = True) ## 절편 추가\n",
    "\n",
    "def sigmoid(x) :\n",
    "    return 1/(1+torch.exp(-(What[0] + What[1]*x)))\n",
    "\n",
    "for epoc in range(1000) :\n",
    "    yhat = sigmoid(X)\n",
    "\n",
    "    ## MLE니까 가능도가 가장 높은 -> -l이 가장 작은 것을 찾는 최적화 문제로 바꿈\n",
    "    loss = -torch.sum(y*torch.log(yhat) + (1-y)*torch.log(1-yhat)) ## 강의 노트엔 그냥 MSELoss 쓰긴 함...\n",
    "    loss.backward()\n",
    "    \n",
    "    What.data -= 0.1*What.grad\n",
    "    What.grad = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` 네트워크, BCELoss, Adam 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = torch.nn.Sequential(\n",
    "    torch.nn.Linear(1, 1), ## 이진 분류문제이므로 y의 차원은 1\n",
    "    torch.nn.Sigmoid()\n",
    ")\n",
    "net[0].weight.data = torch.tensor([[1.0]])\n",
    "net[0].bias.data = torch.tensor([1.0])\n",
    "\n",
    "loss_fn = torch.nn.BCELoss()\n",
    "\n",
    "## 지역 최소값에 잘 빠지지 않고, 최적화 속도가 빠름\n",
    "optimizr = torch.optim.Adam(net.parameters(), lr = 0.1)\n",
    "\n",
    "##---##\n",
    "for epoc in range(300) :\n",
    "    yhat = net(X)\n",
    "    \n",
    "    loss = loss_fn(yhat, y)\n",
    "    loss.backward()\n",
    "    \n",
    "    optimizr.step()\n",
    "    optimizr.zero_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3. 신경망, ReLU, 사용자 정의 네트워크**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **A. 내용**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 시그모이드에 넣기 전, 꺾인 그래프를 만들어 로지스틱의 표현력을 확보\n",
    "* 언더라잉이 로지스틱이라면 신경망의 성능이 더 안좋을 수 있음(Test dataset에서)\n",
    "* 신경망의 경우 회귀분석과 달리 여러 개의 최적값이 존재할 수 있음 -> 한 개의 global minimum만 가지지 않을 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` 신경망의 표현"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\underset{(n,784)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,32)}{\\boldsymbol u^{(1)}} \\overset{relu}{\\to} \\underset{(n,32)}{\\boldsymbol v^{(1)}} \\overset{l_2}{\\to} \\underset{(n,1)}{\\boldsymbol u^{(2)}} \\overset{sig}{\\to} \\underset{(n,1)}{\\boldsymbol v^{(2)}} =\\underset{(n,1)}{\\hat{\\boldsymbol y}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* $l_k$ : 선형 변환 -> 아래의 괄호로 변환된 차원 확인\n",
    "\n",
    "> 보통 $u$라고 표기하기도 함\n",
    "\n",
    "* $relu, ~ sig$ : 비선형 변환, 파라미터 없음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **B. 구현**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` `ReLU`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.arange(-10, 10).float()\n",
    "relu = torch.nn.ReLU()\n",
    "\n",
    "## v자 그래프\n",
    "relu(x) + relu(-x)\n",
    "\n",
    "## A자 그래프\n",
    "- relu(x) - relu(-x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 브로드캐스팅\n",
    "u = torch.stack([x, -x], axis = 1)\n",
    "v = relu(u)\n",
    "\n",
    "-4.5*v[:, [0]] - 9.0*v[:, [1]] + 4.5 ## 이 경우 [0]번 열이 뒤쪽, [1]번 열이 앞쪽 모양을 담당\n",
    "\n",
    "## 선형 결합\n",
    "l2 = torch.nn.Linear(2, 1, bias = True)\n",
    "l2.weight.data = torch.tensor([[-4.5, -9.0]])\n",
    "l2.bias.data = torch.tensor([4.5])\n",
    "\n",
    "l2(v)\n",
    "\n",
    "## 두 번의 선형 결합\n",
    "l1 = torch.nn.Linear(1, 2)\n",
    "l1.weight.data = torch.tensor([[1.0], [-1.0]]) ## 실제로 행벡터를 넣어야 하니 반대로...\n",
    "l1.bias.data = l1.bias.data*0\n",
    "\n",
    "l2(relu(l1(x.reshape(-1, 1))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` 기초적인 신경망(분류)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 회귀의 경우 시그모이드 빼고, `MSELoss`를 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = torch.nn.Sequential(\n",
    "    torch.nn.Linear(1, 2),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(2, 1),\n",
    "    torch.nn.Sigmoid()\n",
    ")\n",
    "\n",
    "loss_fn = torch.nn.BCELoss()\n",
    "optimizr = torch.optim.Adam(net.parameters())\n",
    "\n",
    "##---##\n",
    "for epoc in range(300) :\n",
    "    yhat = net(X)\n",
    "\n",
    "    loss = loss_fn(yhat, y)\n",
    "    loss.backward()\n",
    "\n",
    "    optimizr.step()\n",
    "    optimizr.zero_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **C. 사용자 정의 네트워크**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` `H`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "class H(torch.nn.Module) :\n",
    "    def __init__(self) :\n",
    "        super().__init__() ## 슈퍼 클래스의 __init__을 그대로 상속\n",
    "\n",
    "    def forward(self, u) :\n",
    "        ## 메소드 오버라이딩\n",
    "        h = lambda x : torch.sigmoid(200*(x+0.5)) + torch.sigmoid(-200*(x-0.5)) - 1.0\n",
    "        v = h(u)\n",
    "        return v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` `Flatten` : 이미 `torch.nn.Flatten()`이 있긴 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten(torch.nn.Module) :\n",
    "    '''\n",
    "    이미지를 DNN으로 분류할 때만 첫 레이어 이전에 사용\n",
    "    '''\n",
    "    def __init__(self) :\n",
    "        super().__init__()\n",
    "        \n",
    "    def forward(self, X) :\n",
    "        return X.reshape(-1, X.shape[1]*X.shape[2]*X.shape[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **4. 시벤코 정리**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 하나의 은닉층을 가지는 네트워크는 모든 보렐 가측함수 $f: {\\bf X}_{n \\times p} \\to {\\bf y}_{n\\times q}$를 원하는 정확도로 근사시킬 수 있음\n",
    ">\n",
    "> 이 때, 은닉층의 활성화함수는 어떤 것이여도 상관없음 (`ReLU`, `Sidmoid`, `H`, ...)\n",
    ">\n",
    "> 즉, 하나의 은닉층을 가진 신경망의 표현력은 거의 무한대라 볼 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` 그래도 혹시 모르니까 시그모이드로 계단 만드는 코드 실습..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 그냥 요즘은 데이터 structure를 따라가는 구조를 만드는 데에 너무 집중하지 않아도 되니까, 모양을 직접 구현하는 것까지는 안해도 될듯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.arange(-1.5, 1.5, 0.05).reshape(-1, 1).float()\n",
    "\n",
    "l1 = torch.nn.Linear(1, 3)\n",
    "a1 = torch.nn.Sigmoid()\n",
    "l2 = torch.nn.Linear(3, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1.weight.data = torch.tensor([[-50.0], [50.0], [-50.0]])\n",
    "l1.bias.data = torch.tensor([-50.0, 0.0, 50.0]) ## weight*(x - bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2.weight.data = torch.tensor([[1.0, 2.0, 1.0]])\n",
    "l2.bias.data = torch.tensor([-1.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x, l2(a1(l1(x))).data, '--');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **5. 평가, 오버피팅, Dropout**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 하나 이상의 은닉층을 가지는 네트워크의 표현력은 거의 무한대임. 그렇기 때문에 맞추지 말아야 할 오차항까지 맞출 수 있음.\n",
    ">\n",
    "> 네트워크가 학습하지 못한 자료에서도 신경망이 올바르게 작동한다는 보장은 없음."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **A. 스코어링**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 모형 훈련 시에는 `net.train()`을 사용하여 훈련 모드로 전환한다.\n",
    "* 스코어 산출 시에는 `net.eval()`을 사용하여 평가 모드로 전환한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` **MSE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.eval()\n",
    "\n",
    "train_mse = torch.mean((y - net(X).data)**2) ## loss_fn(net(X), y)\n",
    "test_mse = torch.mean((yy - net(XX).data)**2) ## loss_fn(net(XX), yy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` **Accuracy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.eval()\n",
    "\n",
    "## 확률을 비교하는 경우\n",
    "train_acc = ((net(X) > 0.5) == y).float().mean() ## loss_fn(net(X), y)\n",
    "test_acc = ((net(XX) > 0.5) == yy).float().mean() ## loss_fn(net(XX), yy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.eval()\n",
    "\n",
    "## 로짓을 비교하는 경우\n",
    "train_acc = ((net(X) > 0.0) == y).float().mean() ## loss_fn(net(X), y)\n",
    "test_acc = ((net(XX) > 0.0) == yy).float().mean() ## loss_fn(net(XX), yy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.eval()\n",
    "\n",
    "## 다항분류의 경우\n",
    "train_acc = (net(X).argmax(axis = 1) == y.argmax(axis = 1)).float().mean()\n",
    "test_acc = (net(XX).argmax(axis = 1) == yy.argmax(axis = 1)).float().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **B. `Dropout`**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 각 파라미터를 p 확률로 0을 만든다. 0이 아닌 파라미터들은 빠진만큼 대략 1/p의 가중치를 곱해준다.\n",
    "* 활성화함수 뒤에 사용하지만, `ReLU`의 경우 그 앞에 사용해도 동일한 효과를 제공한다. 해당 방법이 컴퓨팅 관점에서 더 효율적이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.linspace(0, 1, 100).reshape(-1, 1)\n",
    "y = torch.randn(100).reshape(-1, 1)\n",
    "\n",
    "xx = torch.randn((10, 1))*0.5 + 0.5\n",
    "yy = torch.randn((10, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test MSE = 0.8740\n",
      "test MSE = 0.8660\n",
      "test MSE = 0.9568\n",
      "test MSE = 0.8990\n",
      "test MSE = 0.9426\n",
      "test MSE = 0.9546\n"
     ]
    }
   ],
   "source": [
    "net = torch.nn.Sequential(\n",
    "    torch.nn.Linear(1, 256),\n",
    "    torch.nn.Dropout(0.9), ## 대략 절반의 파라미터를 0으로 날림.\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(256, 1)\n",
    ")\n",
    "\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "optimizr = torch.optim.Adam(net.parameters(), lr = 0.01)\n",
    "\n",
    "for epoc in range(300) :\n",
    "    net.train() ## training mode activate\n",
    "    yhat = net(x)\n",
    "    loss = loss_fn(yhat, y)\n",
    "    loss.backward()\n",
    "    optimizr.step()\n",
    "    optimizr.zero_grad()\n",
    "\n",
    "    if epoc % 50 == 0 :\n",
    "        net.eval() ## evaluation mode activate -> dropout 적용\n",
    "        yyhat = net(xx)\n",
    "        test_score = loss_fn(yyhat, yy).data\n",
    "        print(f\"test MSE = {test_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **6. 텐서 포맷 변환**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **A. 이미지 포맷**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` `matplotlib`에서의 이미지 텐서 포매팅 : `(h, w, c)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img, cmap = \"gray\") ## img 텐서의 자료형이 float이면 0~1로 먹임"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` 파이토치에서의 이미지 텐서 포매팅 : `(n, c, h, w)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` `PIL`(Python Image Library; pillow) 텐서 변환\n",
    "\n",
    "* 이미지 파일 크기 통일 및 텐서 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "compose = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize((512, 512)), ## 이미지 사이즈 통일\n",
    "    torchvision.transforms.ToTensor() ## 이미지를 텐서로 변환\n",
    "])\n",
    "\n",
    "X = torch.stack([compose(train_dataset[i][0]) for i in range(len(train_dataset))], axis = 0)\n",
    "XX = torch.stack([compose(test_dataset[i][0]) for i in range(len(test_dataset))], axis = 0)\n",
    "\n",
    "y = torch.tensor([train_dataset[i][1] for i in range(len(train_dataset))]).reshape(-1, 1).float()\n",
    "yy = torch.tensor([test_dataset[i][1] for i in range(len(test_dataset))]).reshape(-1, 1).float()\n",
    "\n",
    "## 이진분류가 아닐 때 - 정수형\n",
    "# y = torch.tensor([train_dataset[i][1] for i in range(len(train_dataset))]).reshape(-1, 1)\n",
    "# yy = torch.tensor([test_dataset[i][1] for i in range(len(test_dataset))]).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **B. 행렬 변환 도구**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 전치, 축변환 -> (h, w, c)로 변경\n",
    "torch.einsum(\"ochw -> hwc\", torch_img)\n",
    "torch_img.sqeuuze().permute(1, 2, 0)\n",
    "\n",
    "## 행렬곱 -> 곱해서 없어질 차원에 대한 문자열 동일하게 설정\n",
    "torch.einsum(\"ochw, kc -> khw\", torch_img, linr.weight.data) + linr.bias.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **7. GPU, 배치 사용법**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` 데이터셋 배치\n",
    "\n",
    "> 확률적 경사하강법 장점\n",
    ">\n",
    "> * GPU 메모리를 덜 사용함\n",
    "> * 에폭 별 학습에 데이터 전체를 사용하지 않아 오버피팅을 방지(배깅 느낌)\n",
    "> * 최적화 도중 로컬 미니멈에 빠져도 잘 빠져나옴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = torch.utils.data.TensorDataset(X, y)\n",
    "dl_train = torch.utils.data.DataLoader(ds_train, batch_size = 1024, shuffle = True)\n",
    "\n",
    "ds_test = torch.utils.data.TensorDataset(XX, yy)\n",
    "dl_test = torch.utils.data.DataLoarder(dl_test, batch_size = 1024) ## 테스트라 셔플 X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` GPU 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 간단한 신경망\n",
    "net = torch.nn.Sequential(\n",
    "    torch.nn.Linear(1, 1024),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(1024, 1)\n",
    ").to(\"cuda:0\") ## 얘는 to(\"cuda:0\") 하면 객체 자체가 바뀜\n",
    "\n",
    "loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "optimizr = torch.optim.Adam(net.parameters())\n",
    "\n",
    "##---## 에폭 수는 기존 에폭 / (len(X)/batch_size)\n",
    "for epoc in range(100) :\n",
    "    net.train()\n",
    "    \n",
    "    for Xm, ym in dl_train :\n",
    "        Xm = Xm.to(\"cuda:0\")\n",
    "        ym = ym.to(\"cuda:0\")\n",
    "        netout = net(Xm)\n",
    "\n",
    "        loss = loss_fn(netout, ym)\n",
    "        loss.backward()\n",
    "    \n",
    "        optimizr.step()\n",
    "        optimizr.zero_grad()\n",
    "\n",
    "    if epoc % 50 == 0 :\n",
    "        net.eval()\n",
    "    \n",
    "        s = 0\n",
    "        \n",
    "        for XXm, yym in dl_test :\n",
    "            XXm = XXm.to(\"cuda:0\")\n",
    "            yym = yym.to(\"cuda:0\")\n",
    "    \n",
    "            s += ((net(XXm) > 0.0) == yym).sum()\n",
    "    \n",
    "        test_acc = s/len(XX)\n",
    "        print(f\"epoch : {epoc},\\ttest_acc = {test_acc}\")\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **8. 다항분류**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` 분류별 이론\n",
    "\n",
    "|**분류**|**오차항의 가정**|**마지막 활성화함수**|**손실함수**|\n",
    "|:-:|:-:|:-:|:-:|\n",
    "|이항분류|이항분포|sigmoid|Binary Cross Entropy|\n",
    "|다항분류|다항분포|softmax|Cross Entropy|\n",
    "\n",
    "\n",
    "> 소프트 맥스 == 일반화 로짓 -> 나온 로짓 값에 지수함수 먹이고 상대비율로 추정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` 코딩용\n",
    "\n",
    "|**분류**|**netout의 의미**|**손실함수**|\n",
    "|:-:|:-:|:-:|\n",
    "|이항분류|prob|`BCELoss`|\n",
    "|이항분류|logit|`BCEWithLogitsLoss`|\n",
    "|다항분류|prob|그런거 없음|\n",
    "|다항분류|logits|`CrossEntropyLoss`|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` 원-핫 인코딩\n",
    "\n",
    "> `y`가 정수형일 경우 파이토치가 알아서 범주형으로 인식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.nn.functional.one_hot(y.reshape(-1).long()) ## 1차원 정수형이여야 함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **9. CNN**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **A. 사용법**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 다항 분류 및 이미지 처리가 뛰어남\n",
    "* 복잡한 구조의 DNN보다 더 빠르고, 성능이 좋고, 파라미터의 수가 적음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` 학습 과정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = torch.nn.Sequential(\n",
    "    ##-----layer 1 : 2d part-----##\n",
    "    ## 해당 파트에서 일반적으로 컴퓨팅 자원을 많이 할당. 레이어 많이 씀\n",
    "    torch.nn.Conv2d(1, 64, kernel_size = 5),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.MaxPool2d(kernel_size = 5),\n",
    "\n",
    "    torch.nn.Flatten(),\n",
    "\n",
    "    ##-----layer 2 : 1d part-----##\n",
    "    ## 해당 파트의 네트워크는 약하게 구성하는 경우가 많음\n",
    "    torch.nn.Linear(???, p) ## 아무 숫자나 넣어보고 오류가 생기면 해당 숫자만 수정\n",
    ")\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizr = torch.optim.Adam(net.parameters())\n",
    "\n",
    "##---##\n",
    "for epoc in range(300) :\n",
    "    netout = net(X)\n",
    "\n",
    "    loss = loss_fn(netout, y)\n",
    "    loss.backward()\n",
    "\n",
    "    optimizr.step()\n",
    "    optimizr.zero_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **B. CNN 핵심 레이어**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**특징을 추출하고 -> 다변화하고 -> 요약**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` `torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding = 0, bias = True)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 컨볼루션 커널\n",
    "* 텐서에 커널 사이즈만한 윈도우를 통과시키고, 각 원소에 `weight`의 값을 가중평균 해줌. 최종적으로 `bias`를 더함. `stride`만큼 이동하여 반복.\n",
    "* 각 원소에 행렬 원소를 곱하여 더한다는 측면에서 선형 변환\n",
    "* 패딩을 해주지 않으면 거의 필연적으로 텐서 사이즈가 줄어듦"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = torch.nn.Conv2d(1, 1, 3, bias = False)\n",
    "## 가중치 텐서가 4차원으로 들어감 -> 채널이나 obs별로도 가중치를 먹일 수 있는건가?\n",
    "conv.weight.data = torch.tensor([[0.0, 1.0, 2.0],\n",
    "                                 [2.0, 2.0, 0.0],\n",
    "                                 [0.0, 1.0, 2.0]]).reshape(1, 1, 3, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` `torch.nn.ReLU()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 특징을 더욱 다변화하기 위한 비선형 변환"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` `torch.nn.MaxPool2d(kernel_size, stride)`\n",
    "\n",
    "* 이미지에서 디테일은 버리고, 중요한 특징만 뽑아서 과장되게 요약\n",
    "* 컨볼루션은 그림을 뭉개는 경향이 있으나, MaxPooling은 중요한 정보를 손실시키지 않으려고 함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **10. 사전 구성 아키텍쳐**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `torchvision.models`에 들어있는 메소드들은, 인스턴스화되어 각각의 변환을 멤버변수 뽑듯이 뽑아쓸 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **A. AlexNet**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "torchvision.models.AlexNet()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://upload.wikimedia.org/wikipedia/commons/thumb/c/cc/Comparison_image_neural_networks.svg/960px-Comparison_image_neural_networks.svg.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` 알렉스넷 아키텍쳐\n",
    "\n",
    "* Conv : kernel_size = 11, stride = 4\n",
    "> 먼저 러프하게 보고 싶음 : 처음엔 큰 이미지를 대충대충 보고 싶음\n",
    "\n",
    "* Pool : kernel_size = 3, stride = 2\n",
    "> 처음엔 요약하고, 나중엔 요약하지 않고 싶음\n",
    "\n",
    "* Conv : kernel_size = 3\n",
    "> 조금 세밀하게 보고 싶음\n",
    "\n",
    "* 마지막 Pool\n",
    "> Flatten하기 직전이고, 데이터가 좀 많은 것 같아서 줄여줌\n",
    "\n",
    "* 신경망 설계 부분\n",
    "> ReLU : 1d part에서 표현력을 좀 더 얻어내고 싶다.\n",
    ">\n",
    "> 요약하고 싶었으면 Linear 한층만 받아도 충분했겠죠"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **B. resnet18**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = torch.nn.Sequential(\n",
    "    ## layer 0\n",
    "    torch.nn.Sequential(\n",
    "        resnet18.conv1,\n",
    "        resnet18.bn1, ## Batch Normalization : 컨볼루션 커널 결과를 정규화 / 비선형 성질 유지\n",
    "        resnet18.relu,\n",
    "        resnet18.maxpool\n",
    "    ),\n",
    "\n",
    "    resnet18.layer1,\n",
    "    resnet18.layer2,\n",
    "    resnet18.layer3,\n",
    "    resnet18.layer4,\n",
    "\n",
    "    ## head\n",
    "    resnet18.avgpool,\n",
    "    torch.nn.Flatten(), ## 원본 클래스의 forward에는 모듈이 아닌 torch.flatten()으로 들어감\n",
    "    resnet18.fc\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet18 = torchvision.models.resnet18(pretrained = True) ## 가중치 가져오기\n",
    "resnet18.fc = torch.nn.Linear(512, p) ## 몇개 범주로 구분할 것인지 설정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 총 18개의 레이어\n",
    "\n",
    "> 17개의 CNN 레이어 + 1개의 네트워크\n",
    ">\n",
    "> `downsample`은 네트워크가 아님(말그대로 다운 샘플링)\n",
    ">\n",
    "> 신경망이 깊기 때문에 레이어마다 배치 정규화를 해줌 -> 미분값이 0에 가까워지는 문제 해소\n",
    ">\n",
    "> `resnet18` 객체 자체는 subscriptable이 아님. 리스트로 호출할 수 없음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **11. CAM - Class Activation Map**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` **기존 `resnet18`의 마지막 레이어 네트워크**\n",
    "$$\\underset{(1,3,512,512)}{\\boldsymbol x} \\overset{stem}{\\to} \\left( \\underset{(1,512,16,16)}{\\tilde{\\boldsymbol x}} \\overset{ap}{\\to} \\underset{(1,512,1,1)}{{\\boldsymbol \\sharp}}\\overset{flattn}{\\to} \\underset{(1,512)}{{\\boldsymbol \\sharp}}\\overset{linr}{\\to} \\underset{(1,1)}{\\text{logit}}\\right) = [[-5.5613]]$$\n",
    "\n",
    "`-` **바꾸고 싶은 네트워크**\n",
    "$$\\underset{(1,3,224,224)}{\\boldsymbol x} \\overset{stem}{\\to} \\left( \\underset{(1,512,16,16)}{\\tilde{\\boldsymbol x}} \\overset{\\_linr}{\\to} \\underset{(1,1,16,16)}{{\\boldsymbol \\sharp}}\\overset{ap}{\\to} \\underset{(1,1,1,1)}{{\\boldsymbol \\sharp}}\\overset{flattn}{\\to} \\underset{(1,1)}{\\text{logit}}\\right) = [[-5.5613]]$$\n",
    "\n",
    "* `linr(flattn(ap(X)))` $\\to$ `flattn(ap(_linr(X)))`\n",
    "\n",
    "> `(1, c, h, w)` $\\to$ `(1, c, 1, 1)` : `ap` 먼저\n",
    ">\n",
    "> `(1, c, h, w)` $\\to$ `(1, 1, h, w)` : 선형결합으로 채널 통합 먼저 -> 러프 이미지 산출\n",
    "\n",
    "\n",
    "* CAM의 한계\n",
    "\n",
    "> head-part가 `ap`와 `linr`로만 구성되어 있어야 함. `AlexNet`과 같은 신경망은 헤드 파트를 임의로 바꿔줘야 함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Z. 데이터 준비**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 이미지와 라벨로 구성된 `train_dataset`, `test_dataset`이 필요함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "compose = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize((512, 512)), ## 이미지 사이즈 통일\n",
    "    torchvision.transforms.ToTensor() ## 이미지를 텐서로 변환\n",
    "])\n",
    "\n",
    "X = torch.stack([compose(train_dataset[i][0]) for i in range(len(train_dataset))], axis = 0)\n",
    "XX = torch.stack([compose(test_dataset[i][0]) for i in range(len(test_dataset))], axis = 0)\n",
    "\n",
    "y = torch.tensor([train_dataset[i][1] for i in range(len(train_dataset))]).reshape(-1, 1).float()\n",
    "yy = torch.tensor([test_dataset[i][1] for i in range(len(test_dataset))]).reshape(-1, 1).float()\n",
    "\n",
    "## 이진분류가 아닐 때 - 정수형\n",
    "# y = torch.tensor([train_dataset[i][1] for i in range(len(train_dataset))]).reshape(-1, 1)\n",
    "# yy = torch.tensor([test_dataset[i][1] for i in range(len(test_dataset))]).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **A. 이미지 분류 잘하는 네트워크 선택 후 학습**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **B. 마지막 1d 레이어 파트를 `_linr -> ap -> flatten` 형태로 바꿈**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## step 1 : 데이터 로드\n",
    "ds_train = torch.utils.data.TensorDataset(X, y)\n",
    "dl_train = torch.utils.data.DataLoader(ds_train, batch_size = 32, shuffle = True)\n",
    "\n",
    "ds_test = torch.utils.data.TensorDataset(XX, yy)\n",
    "dl_test = torch.utils.data.DataLoader(ds_test, batch_size = 32)\n",
    "\n",
    "\n",
    "## step 2 : 모델 및 가중치 불러오기\n",
    "resnet18 = torchvision.models.resnet18(pretrained = True)\n",
    "resnet18.fc = torch.nn.Linear(512, 1)\n",
    "\n",
    "loss_fn = torch.nn.BCEWithLogitsLoss() ## 최종 모델에 시그모이드 안들어가있음(못들어감)\n",
    "optimizr = torch.optim.Adam(resnet18.parameters(), lr = 1e-5) ## 세부조정만\n",
    "\n",
    "\n",
    "## step 3 : 사후 트레이닝\n",
    "resnet18.to(\"cuda:0\")\n",
    "\n",
    "for epoc in range(3) :\n",
    "    resnet18.train() ## dropout 있음\n",
    "\n",
    "    for Xm, ym in dl_train :\n",
    "        Xm = Xm.to(\"cuda:0\")\n",
    "        ym = ym.to(\"cuda:0\")\n",
    "\n",
    "        netout = resnet18(Xm)\n",
    "        \n",
    "        loss = loss_fn(netout, ym)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizr.step()\n",
    "        optimizr.zero_grad()\n",
    "\n",
    "    ## eval in epochs\n",
    "    resnet18.eval()\n",
    "    s = 0\n",
    "    \n",
    "    for Xm, ym in dl_train :\n",
    "        Xm = Xm.to(\"cuda:0\")\n",
    "        ym = ym.to(\"cuda:0\")\n",
    "\n",
    "        s += ((resnet18(Xm) > 0.0) == ym).sum().item()\n",
    "\n",
    "    train_acc = s/len(X)\n",
    "\n",
    "    print(f\"epoch : {epoc},\\ttrain_acc = {train_acc:.4f}\")\n",
    "\n",
    "\n",
    "## step 4 : 평가\n",
    "# resnet18.eval() ## 이미 평가모드임\n",
    "s = 0\n",
    "\n",
    "for XXm, yym in dl_test :\n",
    "    XXm = XXm.to(\"cuda:0\")\n",
    "    yym = yym.to(\"cuda:0\")\n",
    "\n",
    "    s += ((resnet18(XXm) > 0.0) == yym).sum().item()\n",
    "\n",
    "test_acc = s/len(XX)\n",
    "\n",
    "print(f\"test_acc = {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "stem = torch.nn.Sequential(\n",
    "    ## layer 0\n",
    "    torch.nn.Sequential(\n",
    "        resnet18.conv1,\n",
    "        resnet18.bn1,\n",
    "        resnet18.relu,\n",
    "        resnet18.maxpool\n",
    "    ),\n",
    "\n",
    "    resnet18.layer1,\n",
    "    resnet18.layer2,\n",
    "    resnet18.layer3,\n",
    "    resnet18.layer4\n",
    ")\n",
    "\n",
    "head = torch.nn.Sequential(\n",
    "    resnet18.avgpool,\n",
    "    torch.nn.Flatten(),\n",
    "    resnet18.fc\n",
    ")\n",
    "\n",
    "net = torch.nn.Sequential(\n",
    "    stem,\n",
    "    head\n",
    ")\n",
    "\n",
    "ap = head[0]\n",
    "flattn = head[1]\n",
    "linr = head[2]\n",
    "\n",
    "def _linr(X) :\n",
    "    return torch.einsum(\"ochw, kc -> okhw\", X, linr.weight.data) + linr.bias.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **C. 보간법을 활용하여 시각화**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(5, 5)\n",
    "\n",
    "#---#\n",
    "k = 0\n",
    "\n",
    "for i in range(5) :\n",
    "    for j in range(5) :\n",
    "        ##--------핵심 코드--------##\n",
    "        \n",
    "        x = XX[[k]].to(\"cuda:0\")\n",
    "        \n",
    "        if net(x) > 0 :\n",
    "            pred = \"dog\"\n",
    "            why = _linr(stem(x))\n",
    "        \n",
    "        else :\n",
    "            pred = \"cat\"\n",
    "            why = - _linr(stem(x))\n",
    "\n",
    "        ## 보간법으로 이미지 크기 조정\n",
    "        why_resized = torch.nn.functional.interpolate(\n",
    "            why, size = (512, 512), mode = \"bilinear\"\n",
    "        ) ## (1, 1, 512, 512)로 나옴\n",
    "\n",
    "        ax[i][j].imshow(x.squeeze().cpu().data.permute(1, 2, 0))\n",
    "        ax[i][j].imshow(why_resized.squeeze().cpu().data, cmap = \"magma\", alpha = 0.5)\n",
    "        \n",
    "        ##--------핵심 코드--------##\n",
    "\n",
    "        \n",
    "        ax[i][j].set_title(f\"prediction = {pred}\")\n",
    "        ax[i][j].set_xticks([])\n",
    "        ax[i][j].set_yticks([])\n",
    "\n",
    "        k += 50\n",
    "\n",
    "fig.set_figheight(16)\n",
    "fig.set_figwidth(16)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **12. 생성모형 GAN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
